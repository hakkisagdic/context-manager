Directory structure:
‚îî‚îÄ‚îÄ toon-format-toon/
    ‚îú‚îÄ‚îÄ README.md
    ‚îú‚îÄ‚îÄ eslint.config.mjs
    ‚îú‚îÄ‚îÄ LICENSE
    ‚îú‚îÄ‚îÄ package.json
    ‚îú‚îÄ‚îÄ pnpm-workspace.yaml
    ‚îú‚îÄ‚îÄ SPEC.md
    ‚îú‚îÄ‚îÄ tsconfig.json
    ‚îú‚îÄ‚îÄ .editorconfig
    ‚îú‚îÄ‚îÄ .npmrc
    ‚îú‚îÄ‚îÄ benchmarks/
    ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îú‚îÄ‚îÄ package.json
    ‚îÇ   ‚îú‚îÄ‚îÄ .env.example
    ‚îÇ   ‚îú‚îÄ‚îÄ data/
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ github-repos.json
    ‚îÇ   ‚îú‚îÄ‚îÄ results/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ retrieval-accuracy.md
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ token-efficiency.md
    ‚îÇ   ‚îú‚îÄ‚îÄ scripts/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ accuracy-benchmark.ts
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ fetch-github-repos.ts
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ token-efficiency-benchmark.ts
    ‚îÇ   ‚îî‚îÄ‚îÄ src/
    ‚îÇ       ‚îú‚îÄ‚îÄ constants.ts
    ‚îÇ       ‚îú‚îÄ‚îÄ datasets.ts
    ‚îÇ       ‚îú‚îÄ‚îÄ evaluate.ts
    ‚îÇ       ‚îú‚îÄ‚îÄ formatters.ts
    ‚îÇ       ‚îú‚îÄ‚îÄ questions.ts
    ‚îÇ       ‚îú‚îÄ‚îÄ report.ts
    ‚îÇ       ‚îú‚îÄ‚îÄ storage.ts
    ‚îÇ       ‚îú‚îÄ‚îÄ types.ts
    ‚îÇ       ‚îî‚îÄ‚îÄ utils.ts
    ‚îú‚îÄ‚îÄ packages/
    ‚îÇ   ‚îú‚îÄ‚îÄ cli/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ package.json
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tsdown.config.ts
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ src/
    ‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ index.ts
    ‚îÇ   ‚îî‚îÄ‚îÄ toon/
    ‚îÇ       ‚îú‚îÄ‚îÄ package.json
    ‚îÇ       ‚îú‚îÄ‚îÄ tsdown.config.ts
    ‚îÇ       ‚îú‚îÄ‚îÄ src/
    ‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ constants.ts
    ‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ index.ts
    ‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ types.ts
    ‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ decode/
    ‚îÇ       ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ decoders.ts
    ‚îÇ       ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ parser.ts
    ‚îÇ       ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ scanner.ts
    ‚îÇ       ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ validation.ts
    ‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ encode/
    ‚îÇ       ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ encoders.ts
    ‚îÇ       ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ normalize.ts
    ‚îÇ       ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ primitives.ts
    ‚îÇ       ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ writer.ts
    ‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ shared/
    ‚îÇ       ‚îÇ       ‚îú‚îÄ‚îÄ literal-utils.ts
    ‚îÇ       ‚îÇ       ‚îú‚îÄ‚îÄ string-utils.ts
    ‚îÇ       ‚îÇ       ‚îî‚îÄ‚îÄ validation.ts
    ‚îÇ       ‚îî‚îÄ‚îÄ test/
    ‚îÇ           ‚îú‚îÄ‚îÄ decode.test.ts
    ‚îÇ           ‚îú‚îÄ‚îÄ encode.test.ts
    ‚îÇ           ‚îî‚îÄ‚îÄ types.ts
    ‚îî‚îÄ‚îÄ .github/
        ‚îî‚îÄ‚îÄ workflows/
            ‚îú‚îÄ‚îÄ ci.yml
            ‚îî‚îÄ‚îÄ release.yml

================================================
FILE: README.md
================================================
![TOON logo with step‚Äëby‚Äëstep guide](./.github/og.png)

# Token-Oriented Object Notation (TOON)

[![CI](https://github.com/toon-format/toon/actions/workflows/ci.yml/badge.svg)](https://github.com/toon-format/toon/actions)
[![npm version](https://img.shields.io/npm/v/@toon-format/toon.svg)](https://www.npmjs.com/package/@toon-format/toon)
[![SPEC v1.3](https://img.shields.io/badge/spec-v1.3-lightgrey)](https://github.com/toon-format/spec)
[![npm downloads (total)](https://img.shields.io/npm/dt/@toon-format/toon.svg)](https://www.npmjs.com/package/@toon-format/toon)
[![License: MIT](https://img.shields.io/badge/license-MIT-blue.svg)](./LICENSE)

**Token-Oriented Object Notation** is a compact, human-readable serialization format designed for passing structured data to Large Language Models with significantly reduced token usage. It's intended for LLM input, not output.

TOON's sweet spot is **uniform arrays of objects** ‚Äì multiple fields per row, same structure across items. It borrows YAML's indentation-based structure for nested objects and CSV's tabular format for uniform data rows, then optimizes both for token efficiency in LLM contexts. For deeply nested or non-uniform data, JSON may be more efficient.

> [!TIP]
> Think of TOON as a translation layer: use JSON programmatically, convert to TOON for LLM input.

## Table of Contents

- [Why TOON?](#why-toon)
- [Key Features](#key-features)
- [Benchmarks](#benchmarks)
- [üìã Full Specification](https://github.com/toon-format/spec/blob/main/SPEC.md)
- [Installation & Quick Start](#installation--quick-start)
- [CLI](#cli)
- [Format Overview](#format-overview)
- [API](#api)
- [Using TOON in LLM Prompts](#using-toon-in-llm-prompts)
- [Notes and Limitations](#notes-and-limitations)
- [Syntax Cheatsheet](#syntax-cheatsheet)
- [Other Implementations](#other-implementations)

## Why TOON?

AI is becoming cheaper and more accessible, but larger context windows allow for larger data inputs as well. **LLM tokens still cost money** ‚Äì and standard JSON is verbose and token-expensive:

```json
{
  "users": [
    { "id": 1, "name": "Alice", "role": "admin" },
    { "id": 2, "name": "Bob", "role": "user" }
  ]
}
```

TOON conveys the same information with **fewer tokens**:

```
users[2]{id,name,role}:
  1,Alice,admin
  2,Bob,user
```

<details>
<summary><strong>Why create a new format?</strong></summary>

For small payloads, JSON/CSV/YAML work fine. TOON's value emerges at scale: when you're making hundreds of LLM calls with uniform tabular data, eliminating repeated keys compounds savings significantly. If token costs matter to your use case, TOON reduces them. If not, stick with what works.

</details>

## Key Features

- üí∏ **Token-efficient:** typically 30‚Äì60% fewer tokens than JSON
- ü§ø **LLM-friendly guardrails:** explicit lengths and fields enable validation
- üç± **Minimal syntax:** removes redundant punctuation (braces, brackets, most quotes)
- üìê **Indentation-based structure:** like YAML, uses whitespace instead of braces
- üß∫ **Tabular arrays:** declare keys once, stream data as rows

## Benchmarks

> [!TIP]
> Try the interactive [Format Tokenization Playground](https://www.curiouslychase.com/playground/format-tokenization-exploration) to compare token usage across CSV, JSON, YAML, and TOON with your own data.

The benchmarks test datasets that favor TOON's strengths (uniform tabular data). Real-world performance depends heavily on your data structure.

<!-- automd:file src="./benchmarks/results/token-efficiency.md" -->

### Token Efficiency

```
‚≠ê GitHub Repositories       ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë    8,745 tokens
                             vs JSON (-42.3%)           15,145
                             vs JSON compact (-23.7%)   11,455
                             vs YAML (-33.4%)           13,129
                             vs XML (-48.8%)            17,095

üìà Daily Analytics           ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë    4,507 tokens
                             vs JSON (-58.9%)           10,977
                             vs JSON compact (-35.7%)    7,013
                             vs YAML (-48.8%)            8,810
                             vs XML (-65.7%)            13,128

üõí E-Commerce Order          ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë      166 tokens
                             vs JSON (-35.4%)              257
                             vs JSON compact (-2.9%)       171
                             vs YAML (-15.7%)              197
                             vs XML (-38.7%)               271

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Total                        ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë   13,418 tokens
                             vs JSON (-49.1%)           26,379
                             vs JSON compact (-28.0%)   18,639
                             vs YAML (-39.4%)           22,136
                             vs XML (-56.0%)            30,494
```

<details>
<summary><strong>Show detailed examples</strong></summary>

#### ‚≠ê GitHub Repositories

**Configuration:** Top 100 GitHub repositories with stars, forks, and metadata

**Savings:** 6,400 tokens (42.3% reduction vs JSON)

**JSON** (15,145 tokens):

```json
{
  "repositories": [
    {
      "id": 28457823,
      "name": "freeCodeCamp",
      "repo": "freeCodeCamp/freeCodeCamp",
      "description": "freeCodeCamp.org's open-source codebase and curriculum. Learn math, programming,‚Ä¶",
      "createdAt": "2014-12-24T17:49:19Z",
      "updatedAt": "2025-10-28T11:58:08Z",
      "pushedAt": "2025-10-28T10:17:16Z",
      "stars": 430886,
      "watchers": 8583,
      "forks": 42146,
      "defaultBranch": "main"
    },
    {
      "id": 132750724,
      "name": "build-your-own-x",
      "repo": "codecrafters-io/build-your-own-x",
      "description": "Master programming by recreating your favorite technologies from scratch.",
      "createdAt": "2018-05-09T12:03:18Z",
      "updatedAt": "2025-10-28T12:37:11Z",
      "pushedAt": "2025-10-10T18:45:01Z",
      "stars": 430877,
      "watchers": 6332,
      "forks": 40453,
      "defaultBranch": "master"
    },
    {
      "id": 21737465,
      "name": "awesome",
      "repo": "sindresorhus/awesome",
      "description": "üòé Awesome lists about all kinds of interesting topics",
      "createdAt": "2014-07-11T13:42:37Z",
      "updatedAt": "2025-10-28T12:40:21Z",
      "pushedAt": "2025-10-27T17:57:31Z",
      "stars": 410052,
      "watchers": 8017,
      "forks": 32029,
      "defaultBranch": "main"
    }
  ]
}
```

**TOON** (8,745 tokens):

```
repositories[3]{id,name,repo,description,createdAt,updatedAt,pushedAt,stars,watchers,forks,defaultBranch}:
  28457823,freeCodeCamp,freeCodeCamp/freeCodeCamp,"freeCodeCamp.org's open-source codebase and curriculum. Learn math, programming,‚Ä¶","2014-12-24T17:49:19Z","2025-10-28T11:58:08Z","2025-10-28T10:17:16Z",430886,8583,42146,main
  132750724,build-your-own-x,codecrafters-io/build-your-own-x,Master programming by recreating your favorite technologies from scratch.,"2018-05-09T12:03:18Z","2025-10-28T12:37:11Z","2025-10-10T18:45:01Z",430877,6332,40453,master
  21737465,awesome,sindresorhus/awesome,üòé Awesome lists about all kinds of interesting topics,"2014-07-11T13:42:37Z","2025-10-28T12:40:21Z","2025-10-27T17:57:31Z",410052,8017,32029,main
```

---

#### üìà Daily Analytics

**Configuration:** 180 days of web metrics (views, clicks, conversions, revenue)

**Savings:** 6,470 tokens (58.9% reduction vs JSON)

**JSON** (10,977 tokens):

```json
{
  "metrics": [
    {
      "date": "2025-01-01",
      "views": 6890,
      "clicks": 401,
      "conversions": 23,
      "revenue": 6015.59,
      "bounceRate": 0.63
    },
    {
      "date": "2025-01-02",
      "views": 6940,
      "clicks": 323,
      "conversions": 37,
      "revenue": 9086.44,
      "bounceRate": 0.36
    },
    {
      "date": "2025-01-03",
      "views": 4390,
      "clicks": 346,
      "conversions": 26,
      "revenue": 6360.75,
      "bounceRate": 0.48
    },
    {
      "date": "2025-01-04",
      "views": 3429,
      "clicks": 231,
      "conversions": 13,
      "revenue": 2360.96,
      "bounceRate": 0.65
    },
    {
      "date": "2025-01-05",
      "views": 5804,
      "clicks": 186,
      "conversions": 22,
      "revenue": 2535.96,
      "bounceRate": 0.37
    }
  ]
}
```

**TOON** (4,507 tokens):

```
metrics[5]{date,views,clicks,conversions,revenue,bounceRate}:
  2025-01-01,6890,401,23,6015.59,0.63
  2025-01-02,6940,323,37,9086.44,0.36
  2025-01-03,4390,346,26,6360.75,0.48
  2025-01-04,3429,231,13,2360.96,0.65
  2025-01-05,5804,186,22,2535.96,0.37
```

</details>

<!-- /automd -->

> [!NOTE]
> Token savings are measured against formatted JSON (2-space indentation) as the primary baseline. Additional comparisons include compact JSON (minified), YAML, and XML to provide a comprehensive view across common data formats. Measured with [`gpt-tokenizer`](https://github.com/niieani/gpt-tokenizer) using `o200k_base` encoding (GPT-5 tokenizer). Actual savings vary by model and tokenizer.

<!-- automd:file src="./benchmarks/results/retrieval-accuracy.md" -->

### Retrieval Accuracy

Accuracy across **4 LLMs** on 154 data retrieval questions:

```
gpt-5-nano
‚Üí TOON           ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë    96.1% (148/154)
  CSV            ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë    91.6% (141/154)
  YAML           ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë    91.6% (141/154)
  JSON compact   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë    91.6% (141/154)
  XML            ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë    87.0% (134/154)
  JSON           ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë    86.4% (133/154)

claude-haiku-4-5-20251001
  JSON           ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë    50.0% (77/154)
  YAML           ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë    49.4% (76/154)
‚Üí TOON           ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë    48.7% (75/154)
  XML            ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë    48.1% (74/154)
  CSV            ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë    47.4% (73/154)
  JSON compact   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë    44.2% (68/154)

gemini-2.5-flash
  CSV            ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë    87.7% (135/154)
  XML            ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë    87.7% (135/154)
‚Üí TOON           ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë    86.4% (133/154)
  YAML           ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë    79.9% (123/154)
  JSON compact   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë    79.9% (123/154)
  JSON           ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë    76.6% (118/154)

grok-4-fast-non-reasoning
‚Üí TOON           ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë    49.4% (76/154)
  JSON           ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë    48.7% (75/154)
  XML            ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë    46.1% (71/154)
  YAML           ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë    46.1% (71/154)
  JSON compact   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë    45.5% (70/154)
  CSV            ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë    44.2% (68/154)
```

**Key tradeoff:** TOON achieves **70.1% accuracy** (vs JSON's 65.4%) while using **46.3% fewer tokens** on these datasets.

<details>
<summary><strong>Performance by dataset and model</strong></summary>

#### Performance by Dataset

##### Uniform employee records (TOON optimal format)

| Format | Accuracy | Tokens | Correct/Total |
| ------ | -------- | ------ | ------------- |
| `csv` | 65.5% | 2,337 | 131/200 |
| `toon` | 67.5% | 2,483 | 135/200 |
| `json-compact` | 65.5% | 3,943 | 131/200 |
| `yaml` | 68.5% | 4,969 | 137/200 |
| `xml` | 69.5% | 7,314 | 139/200 |
| `json-pretty` | 64.5% | 6,347 | 129/200 |

##### E-commerce orders with nested structures

| Format | Accuracy | Tokens | Correct/Total |
| ------ | -------- | ------ | ------------- |
| `toon` | 78.8% | 5,967 | 126/160 |
| `csv` | 76.3% | 6,735 | 122/160 |
| `json-compact` | 70.6% | 5,962 | 113/160 |
| `yaml` | 72.5% | 7,328 | 116/160 |
| `json-pretty` | 76.9% | 9,694 | 123/160 |
| `xml` | 73.1% | 10,992 | 117/160 |

##### Time-series analytics data

| Format | Accuracy | Tokens | Correct/Total |
| ------ | -------- | ------ | ------------- |
| `toon` | 68.4% | 1,515 | 93/136 |
| `csv` | 65.4% | 1,393 | 89/136 |
| `json-compact` | 64.7% | 2,341 | 88/136 |
| `yaml` | 66.2% | 2,938 | 90/136 |
| `json-pretty` | 64.7% | 3,665 | 88/136 |
| `xml` | 66.9% | 4,376 | 91/136 |

##### Top 100 GitHub repositories

| Format | Accuracy | Tokens | Correct/Total |
| ------ | -------- | ------ | ------------- |
| `toon` | 65.0% | 8,745 | 78/120 |
| `csv` | 62.5% | 8,513 | 75/120 |
| `json-compact` | 58.3% | 11,455 | 70/120 |
| `yaml` | 56.7% | 13,129 | 68/120 |
| `xml` | 55.8% | 17,095 | 67/120 |
| `json-pretty` | 52.5% | 15,145 | 63/120 |

#### Performance by Model

##### gpt-5-nano

| Format | Accuracy | Correct/Total |
| ------ | -------- | ------------- |
| `toon` | 96.1% | 148/154 |
| `csv` | 91.6% | 141/154 |
| `yaml` | 91.6% | 141/154 |
| `json-compact` | 91.6% | 141/154 |
| `xml` | 87.0% | 134/154 |
| `json-pretty` | 86.4% | 133/154 |

##### claude-haiku-4-5-20251001

| Format | Accuracy | Correct/Total |
| ------ | -------- | ------------- |
| `json-pretty` | 50.0% | 77/154 |
| `yaml` | 49.4% | 76/154 |
| `toon` | 48.7% | 75/154 |
| `xml` | 48.1% | 74/154 |
| `csv` | 47.4% | 73/154 |
| `json-compact` | 44.2% | 68/154 |

##### gemini-2.5-flash

| Format | Accuracy | Correct/Total |
| ------ | -------- | ------------- |
| `csv` | 87.7% | 135/154 |
| `xml` | 87.7% | 135/154 |
| `toon` | 86.4% | 133/154 |
| `yaml` | 79.9% | 123/154 |
| `json-compact` | 79.9% | 123/154 |
| `json-pretty` | 76.6% | 118/154 |

##### grok-4-fast-non-reasoning

| Format | Accuracy | Correct/Total |
| ------ | -------- | ------------- |
| `toon` | 49.4% | 76/154 |
| `json-pretty` | 48.7% | 75/154 |
| `xml` | 46.1% | 71/154 |
| `yaml` | 46.1% | 71/154 |
| `json-compact` | 45.5% | 70/154 |
| `csv` | 44.2% | 68/154 |

</details>

<details>
<summary><strong>How the benchmark works</strong></summary>

#### What's Being Measured

This benchmark tests **LLM comprehension and data retrieval accuracy** across different input formats. Each LLM receives formatted data and must answer questions about it (this does **not** test model's ability to generate TOON output).

#### Datasets Tested

Four datasets designed to test different structural patterns (all contain arrays of uniform objects, TOON's optimal format):

1. **Tabular** (100 employee records): Uniform objects with identical fields ‚Äì optimal for TOON's tabular format.
2. **Nested** (50 e-commerce orders): Complex structures with nested customer objects and item arrays.
3. **Analytics** (60 days of metrics): Time-series data with dates and numeric values.
4. **GitHub** (100 repositories): Real-world data from top GitHub repos by stars.

#### Question Types

154 questions are generated dynamically across three categories:

- **Field retrieval (40%)**: Direct value lookups or values that can be read straight off a record (including booleans and simple counts such as array lengths)
  - Example: "What is Alice's salary?" ‚Üí `75000`
  - Example: "How many items are in order ORD-0042?" ‚Üí `3`
  - Example: "What is the customer name for order ORD-0042?" ‚Üí `John Doe`

- **Aggregation (32%)**: Dataset-level totals and averages plus single-condition filters (counts, sums, min/max comparisons)
  - Example: "How many employees work in Engineering?" ‚Üí `17`
  - Example: "What is the total revenue across all orders?" ‚Üí `45123.50`
  - Example: "How many employees have salary > 80000?" ‚Üí `23`

- **Filtering (28%)**: Multi-condition queries requiring compound logic (AND constraints across fields)
  - Example: "How many employees in Sales have salary > 80000?" ‚Üí `5`
  - Example: "How many active employees have more than 10 years of experience?" ‚Üí `8`

#### Evaluation Process

1. **Format conversion**: Each dataset is converted to all 6 formats (TOON, CSV, XML, YAML, JSON, JSON compact).
2. **Query LLM**: Each model receives formatted data + question in a prompt and extracts the answer.
3. **Validate with LLM-as-judge**: `gpt-5-nano` validates if the answer is semantically correct (e.g., `50000` = `$50,000`, `Engineering` = `engineering`, `2025-01-01` = `January 1, 2025`).

#### Models & Configuration

- **Models tested**: `gpt-5-nano`, `claude-haiku-4-5-20251001`, `gemini-2.5-flash`, `grok-4-fast-non-reasoning`
- **Token counting**: Using `gpt-tokenizer` with `o200k_base` encoding (GPT-5 tokenizer)
- **Temperature**: Not set (models use their defaults)
- **Total evaluations**: 154 questions √ó 6 formats √ó 4 models = 3,696 LLM calls

</details>

<!-- /automd -->

## Installation & Quick Start

```bash
# npm
npm install @toon-format/toon

# pnpm
pnpm add @toon-format/toon

# yarn
yarn add @toon-format/toon
```

**Example usage:**

```ts
import { encode } from '@toon-format/toon'

const data = {
  users: [
    { id: 1, name: 'Alice', role: 'admin' },
    { id: 2, name: 'Bob', role: 'user' }
  ]
}

console.log(encode(data))
// users[2]{id,name,role}:
//   1,Alice,admin
//   2,Bob,user
```

## CLI

Command-line tool for converting between JSON and TOON formats.

### Usage

```bash
npx @toon-format/cli <input> [options]
```

**Auto-detection:** The CLI automatically detects the operation based on file extension (`.json` ‚Üí encode, `.toon` ‚Üí decode).

```bash
# Encode JSON to TOON (auto-detected)
npx @toon-format/cli input.json -o output.toon

# Decode TOON to JSON (auto-detected)
npx @toon-format/cli data.toon -o output.json

# Output to stdout
npx @toon-format/cli input.json
```

### Options

| Option | Description |
| ------ | ----------- |
| `-o, --output <file>` | Output file path (prints to stdout if omitted) |
| `-e, --encode` | Force encode mode (overrides auto-detection) |
| `-d, --decode` | Force decode mode (overrides auto-detection) |
| `--delimiter <char>` | Array delimiter: `,` (comma), `\t` (tab), `\|` (pipe) |
| `--indent <number>` | Indentation size (default: `2`) |
| `--length-marker` | Add `#` prefix to array lengths (e.g., `items[#3]`) |
| `--stats` | Show token count estimates and savings (encode only) |
| `--no-strict` | Disable strict validation when decoding |

### Examples

```bash
# Show token savings when encoding
npx @toon-format/cli data.json --stats -o output.toon

# Tab-separated output (often more token-efficient)
npx @toon-format/cli data.json --delimiter "\t" -o output.toon

# Pipe-separated with length markers
npx @toon-format/cli data.json --delimiter "|" --length-marker -o output.toon

# Lenient decoding (skip validation)
npx @toon-format/cli data.toon --no-strict -o output.json
```

## Format Overview

> [!NOTE]
> For precise formatting rules and implementation details, see the [full specification](https://github.com/toon-format/spec).

### Objects

Simple objects with primitive values:

```ts
encode({
  id: 123,
  name: 'Ada',
  active: true
})
```

```
id: 123
name: Ada
active: true
```

Nested objects:

```ts
encode({
  user: {
    id: 123,
    name: 'Ada'
  }
})
```

```
user:
  id: 123
  name: Ada
```

### Arrays

> [!TIP]
> TOON includes the array length in brackets (e.g., `items[3]`). When using comma delimiters (default), the delimiter is implicit. When using tab or pipe delimiters, the delimiter is explicitly shown in the header (e.g., `tags[2|]` or `[2	]`). This encoding helps LLMs identify the delimiter and track the number of elements, reducing errors when generating or validating structured output.

#### Primitive Arrays (Inline)

```ts
encode({
  tags: ['admin', 'ops', 'dev']
})
```

```
tags[3]: admin,ops,dev
```

#### Arrays of Objects (Tabular)

When all objects share the same primitive fields, TOON uses an efficient **tabular format**:

```ts
encode({
  items: [
    { sku: 'A1', qty: 2, price: 9.99 },
    { sku: 'B2', qty: 1, price: 14.5 }
  ]
})
```

```
items[2]{sku,qty,price}:
  A1,2,9.99
  B2,1,14.5
```

**Tabular formatting applies recursively:** nested arrays of objects (whether as object properties or inside list items) also use tabular format if they meet the same requirements.

```ts
encode({
  items: [
    {
      users: [
        { id: 1, name: 'Ada' },
        { id: 2, name: 'Bob' }
      ],
      status: 'active'
    }
  ]
})
```

```
items[1]:
  - users[2]{id,name}:
    1,Ada
    2,Bob
    status: active
```

#### Mixed and Non-Uniform Arrays

Arrays that don't meet the tabular requirements use list format:

```
items[3]:
  - 1
  - a: 1
  - text
```

When objects appear in list format, the first field is placed on the hyphen line:

```
items[2]:
  - id: 1
    name: First
  - id: 2
    name: Second
    extra: true
```

> [!NOTE]
> **Nested array indentation:** When the first field of a list item is an array (primitive, tabular, or nested), its contents are indented two spaces under the header line, and subsequent fields of the same object appear at that same indentation level. This remains unambiguous because list items begin with `"- "`, tabular arrays declare a fixed row count in their header, and object fields contain `":"`.

#### Arrays of Arrays

When you have arrays containing primitive inner arrays:

```ts
encode({
  pairs: [
    [1, 2],
    [3, 4]
  ]
})
```

```
pairs[2]:
  - [2]: 1,2
  - [2]: 3,4
```

#### Empty Arrays and Objects

Empty containers have special representations:

```ts
encode({ items: [] }) // items[0]:
encode([]) // [0]:
encode({}) // (empty output)
encode({ config: {} }) // config:
```

### Quoting Rules

TOON quotes strings **only when necessary** to maximize token efficiency:

- Inner spaces are allowed; leading or trailing spaces force quotes.
- Unicode and emoji are safe unquoted.
- Quotes and control characters are escaped with backslash.

> [!NOTE]
> When using alternative delimiters (tab or pipe), the quoting rules adapt automatically. Strings containing the active delimiter will be quoted, while other delimiters remain safe.

#### Object Keys and Field Names

Keys are unquoted if they match the identifier pattern: start with a letter or underscore, followed by letters, digits, underscores, or dots (e.g., `id`, `userName`, `user_name`, `user.name`, `_private`). All other keys must be quoted (e.g., `"user name"`, `"order-id"`, `"123"`, `"order:id"`, `""`).

#### String Values

String values are quoted when any of the following is true:

| Condition | Examples |
|---|---|
| Empty string | `""` |
| Leading or trailing spaces | `" padded "`, `"  "` |
| Contains active delimiter, colon, quote, backslash, or control chars | `"a,b"` (comma), `"a\tb"` (tab), `"a\|b"` (pipe), `"a:b"`, `"say \"hi\""`, `"C:\\Users"`, `"line1\\nline2"` |
| Looks like boolean/number/null | `"true"`, `"false"`, `"null"`, `"42"`, `"-3.14"`, `"1e-6"`, `"05"` |
| Starts with `"- "` (list-like) | `"- item"` |
| Looks like structural token | `"[5]"`, `"{key}"`, `"[3]: x,y"` |

**Examples of unquoted strings:** Unicode and emoji are safe (`hello üëã world`), as are strings with inner spaces (`hello world`).

> [!IMPORTANT]
> **Delimiter-aware quoting:** Unquoted strings never contain `:` or the active delimiter. This makes TOON reliably parseable with simple heuristics: split key/value on first `: `, and split array values on the delimiter declared in the array header. When using tab or pipe delimiters, commas don't need quoting ‚Äì only the active delimiter triggers quoting for both array values and object values.

### Type Conversions

Some non-JSON types are automatically normalized for LLM-safe output:

| Input | Output |
|---|---|
| Number (finite) | Decimal form, no scientific notation (e.g., `-0` ‚Üí `0`, `1e6` ‚Üí `1000000`) |
| Number (`NaN`, `¬±Infinity`) | `null` |
| `BigInt` | If within safe integer range: converted to number. Otherwise: quoted decimal string (e.g., `"9007199254740993"`) |
| `Date` | ISO string in quotes (e.g., `"2025-01-01T00:00:00.000Z"`) |
| `undefined` | `null` |
| `function` | `null` |
| `symbol` | `null` |

## API

### `encode(value: unknown, options?: EncodeOptions): string`

Converts any JSON-serializable value to TOON format.

**Parameters:**

- `value` ‚Äì Any JSON-serializable value (object, array, primitive, or nested structure). Non-JSON-serializable values (functions, symbols, undefined, non-finite numbers) are converted to `null`. Dates are converted to ISO strings, and BigInts are emitted as decimal integers (no quotes).
- `options` ‚Äì Optional encoding options:
  - `indent?: number` ‚Äì Number of spaces per indentation level (default: `2`)
  - `delimiter?: ',' | '\t' | '|'` ‚Äì Delimiter for array values and tabular rows (default: `','`)
  - `lengthMarker?: '#' | false` ‚Äì Optional marker to prefix array lengths (default: `false`)

**Returns:**

A TOON-formatted string with no trailing newline or spaces.

**Example:**

```ts
import { encode } from '@toon-format/toon'

const items = [
  { sku: 'A1', qty: 2, price: 9.99 },
  { sku: 'B2', qty: 1, price: 14.5 }
]

encode({ items })
```

**Output:**

```
items[2]{sku,qty,price}:
  A1,2,9.99
  B2,1,14.5
```

#### Delimiter Options

The `delimiter` option allows you to choose between comma (default), tab, or pipe delimiters for array values and tabular rows. Alternative delimiters can provide additional token savings in specific contexts.

##### Tab Delimiter (`\t`)

Using tab delimiters instead of commas can reduce token count further, especially for tabular data:

```ts
const data = {
  items: [
    { sku: 'A1', name: 'Widget', qty: 2, price: 9.99 },
    { sku: 'B2', name: 'Gadget', qty: 1, price: 14.5 }
  ]
}

encode(data, { delimiter: '\t' })
```

**Output:**

```
items[2	]{sku	name	qty	price}:
  A1	Widget	2	9.99
  B2	Gadget	1	14.5
```

**Benefits:**

- Tabs are single characters and often tokenize more efficiently than commas.
- Tabs rarely appear in natural text, reducing the need for quote-escaping.
- The delimiter is explicitly encoded in the array header, making it self-descriptive.

**Considerations:**

- Some terminals and editors may collapse or expand tabs visually.
- String values containing tabs will still require quoting.

##### Pipe Delimiter (`|`)

Pipe delimiters offer a middle ground between commas and tabs:

```ts
encode(data, { delimiter: '|' })
```

**Output:**

```
items[2|]{sku|name|qty|price}:
  A1|Widget|2|9.99
  B2|Gadget|1|14.5
```

#### Length Marker Option

The `lengthMarker` option adds an optional hash (`#`) prefix to array lengths to emphasize that the bracketed value represents a count, not an index:

```ts
const data = {
  tags: ['reading', 'gaming', 'coding'],
  items: [
    { sku: 'A1', qty: 2, price: 9.99 },
    { sku: 'B2', qty: 1, price: 14.5 },
  ],
}

console.log(
  encode(data, { lengthMarker: '#' })
)
// tags[#3]: reading,gaming,coding
// items[#2]{sku,qty,price}:
//   A1,2,9.99
//   B2,1,14.5

// Custom delimiter with length marker
console.log(
  encode(data, { lengthMarker: '#', delimiter: '|' })
)
// tags[#3|]: reading|gaming|coding
// items[#2|]{sku|qty|price}:
//   A1|2|9.99
//   B2|1|14.5
```

### `decode(input: string, options?: DecodeOptions): JsonValue`

Converts a TOON-formatted string back to JavaScript values.

**Parameters:**

- `input` ‚Äì A TOON-formatted string to parse
- `options` ‚Äì Optional decoding options:
  - `indent?: number` ‚Äì Expected number of spaces per indentation level (default: `2`)
  - `strict?: boolean` ‚Äì Enable strict validation (default: `true`)

**Returns:**

A JavaScript value (object, array, or primitive) representing the parsed TOON data.

**Example:**

```ts
import { decode } from '@toon-format/toon'

const toon = `
items[2]{sku,qty,price}:
  A1,2,9.99
  B2,1,14.5
`

const data = decode(toon)
// {
//   items: [
//     { sku: 'A1', qty: 2, price: 9.99 },
//     { sku: 'B2', qty: 1, price: 14.5 }
//   ]
// }
```

**Strict Mode:**

By default, the decoder validates input strictly:

- **Invalid escape sequences**: Throws on `"\x"`, unterminated strings.
- **Syntax errors**: Throws on missing colons, malformed headers.
- **Array length mismatches**: Throws when declared length doesn't match actual count.
- **Delimiter mismatches**: Throws when row delimiters don't match header.

## Notes and Limitations

- Format familiarity and structure matter as much as token count. TOON's tabular format requires arrays of objects with identical keys and primitive values only. When this doesn't hold (due to mixed types, non-uniform objects, or nested structures), TOON switches to list format where JSON can be more efficient at scale.
  - **TOON excels at:** Uniform arrays of objects (same fields, primitive values), especially large datasets with consistent structure.
  - **JSON is better for:** Non-uniform data, deeply nested structures, and objects with varying field sets.
- **Token counts vary by tokenizer and model.** Benchmarks use a GPT-style tokenizer (cl100k/o200k); actual savings will differ with other models (e.g., [SentencePiece](https://github.com/google/sentencepiece)).
- **TOON is designed for LLM input** where human readability and token efficiency matter. It's **not** a drop-in replacement for JSON in APIs or storage.

## Using TOON in LLM Prompts

TOON works best when you show the format instead of describing it. The structure is self-documenting ‚Äì models parse it naturally once they see the pattern.

### Sending TOON to LLMs (Input)

Wrap your encoded data in a fenced code block (label it \`\`\`toon for clarity). The indentation and headers are usually enough ‚Äì models treat it like familiar YAML or CSV. The explicit length markers (`[N]`) and field headers (`{field1,field2}`) help the model track structure, especially for large tables.

### Generating TOON from LLMs (Output)

For output, be more explicit. When you want the model to **generate** TOON:

- **Show the expected header** (`users[N]{id,name,role}:`). The model fills rows instead of repeating keys, reducing generation errors.
- **State the rules:** 2-space indent, no trailing spaces, `[N]` matches row count.

Here's a prompt that works for both reading and generating:

````
Data is in TOON format (2-space indent, arrays show length and fields).

```toon
users[3]{id,name,role,lastLogin}:
  1,Alice,admin,2025-01-15T10:30:00Z
  2,Bob,user,2025-01-14T15:22:00Z
  3,Charlie,user,2025-01-13T09:45:00Z
```

Task: Return only users with role "user" as TOON. Use the same header. Set [N] to match the row count. Output only the code block.
````

> [!TIP]
> For large uniform tables, use `encode(data, { delimiter: '\t' })` and tell the model "fields are tab-separated." Tabs often tokenize better than commas and reduce the need for quote-escaping.

## Syntax Cheatsheet

<details>
<summary><strong>Show format examples</strong></summary>

```
// Object
{ id: 1, name: 'Ada' }          ‚Üí id: 1
                                  name: Ada

// Nested object
{ user: { id: 1 } }             ‚Üí user:
                                    id: 1

// Primitive array (inline)
{ tags: ['foo', 'bar'] }        ‚Üí tags[2]: foo,bar

// Tabular array (uniform objects)
{ items: [                      ‚Üí items[2]{id,qty}:
  { id: 1, qty: 5 },                1,5
  { id: 2, qty: 3 }                 2,3
]}

// Mixed / non-uniform (list)
{ items: [1, { a: 1 }, 'x'] }   ‚Üí items[3]:
                                    - 1
                                    - a: 1
                                    - x

// Array of arrays
{ pairs: [[1, 2], [3, 4]] }     ‚Üí pairs[2]:
                                    - [2]: 1,2
                                    - [2]: 3,4

// Root array
['x', 'y']                      ‚Üí [2]: x,y

// Empty containers
{}                              ‚Üí (empty output)
{ items: [] }                   ‚Üí items[0]:

// Special quoting
{ note: 'hello, world' }        ‚Üí note: "hello, world"
{ items: ['true', true] }       ‚Üí items[2]: "true",true
```

</details>

## Other Implementations

> [!NOTE]
> When implementing TOON in other languages, please follow the [specification](https://github.com/toon-format/spec/blob/main/SPEC.md) (currently v1.3) to ensure compatibility across implementations. The [conformance tests](https://github.com/toon-format/spec/tree/main/tests) provide language-agnostic test fixtures that validate implementations across any language.

- **.NET:** [ToonSharp](https://github.com/0xZunia/ToonSharp)
- **Crystal:** [toon-crystal](https://github.com/mamantoha/toon-crystal)
- **Dart:** [toon](https://github.com/wisamidris77/toon)
- **Elixir:** [toon_ex](https://github.com/kentaro/toon_ex)
- **Gleam:** [toon_codec](https://github.com/axelbellec/toon_codec)
- **Go:** [gotoon](https://github.com/alpkeskin/gotoon)
- **Java:** [JToon](https://github.com/felipestanzani/JToon)
- **OCaml:** [ocaml-toon](https://github.com/davesnx/ocaml-toon)
- **PHP:** [toon-php](https://github.com/HelgeSverre/toon-php)
- **Python:** [python-toon](https://github.com/xaviviro/python-toon) or [pytoon](https://github.com/bpradana/pytoon)
- **Ruby:** [toon-ruby](https://github.com/andrepcg/toon-ruby)
- **Rust:** [rtoon](https://github.com/shreyasbhat0/rtoon)
- **Swift:** [TOONEncoder](https://github.com/mattt/TOONEncoder)

## License

[MIT](./LICENSE) License ¬© 2025-PRESENT [Johann Schopplich](https://github.com/johannschopplich)



================================================
FILE: eslint.config.mjs
================================================
// @ts-check
import antfu from '@antfu/eslint-config'

export default antfu().append({
  files: ['README.md', 'SPEC.md'],
  rules: {
    'style/no-tabs': 'off',
  },
})



================================================
FILE: LICENSE
================================================
MIT License

Copyright (c) 2025-PRESENT Johann Schopplich

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.



================================================
FILE: package.json
================================================
{
  "name": "@toon-format/monorepo",
  "type": "module",
  "version": "0.7.0",
  "private": true,
  "packageManager": "pnpm@10.20.0",
  "scripts": {
    "build": "pnpm -r --filter=./packages/** run build",
    "automd": "automd",
    "lint": "eslint .",
    "lint:fix": "eslint . --fix",
    "test": "pnpm -r test",
    "test:types": "tsc --noEmit",
    "release": "bumpp -r"
  },
  "devDependencies": {
    "@antfu/eslint-config": "^6.2.0",
    "@types/node": "^24.9.2",
    "automd": "^0.4.2",
    "bumpp": "^10.3.1",
    "eslint": "^9.39.0",
    "tsdown": "^0.15.12",
    "tsx": "^4.20.6",
    "typescript": "^5.9.3",
    "vitest": "^4.0.6"
  }
}



================================================
FILE: pnpm-workspace.yaml
================================================
packages:
  - benchmarks
  - packages/*

onlyBuiltDependencies:
  - '@parcel/watcher'
  - esbuild



================================================
FILE: SPEC.md
================================================
# TOON Specification

The TOON specification has moved to a dedicated repository: [github.com/toon-format/spec](https://github.com/toon-format/spec)

## Current Version

**Version 1.3** (2025-10-31)

## Quick Links

- **[Full Specification](https://github.com/toon-format/spec/blob/main/SPEC.md)** - Complete technical specification
- **[Changelog](https://github.com/toon-format/spec/blob/main/CHANGELOG.md)** - Version history
- **[Examples](https://github.com/toon-format/spec/tree/main/examples)** - Example TOON files
- **[Conformance Tests](https://github.com/toon-format/spec/tree/main/tests)** - Language-agnostic test fixtures for implementations
- **[Contributing](https://github.com/toon-format/spec/blob/main/CONTRIBUTING.md)** - How to propose spec changes

## Why a Separate Repo?

The specification has been moved to `toon-format/spec` to:

- Provide a canonical, language-agnostic source of truth
- Enable independent versioning of spec and implementations
- Support the growing community of TOON implementations across multiple languages
- Facilitate collaboration on spec evolution through a dedicated RFC process

## This Repository

This repository (`toon-format/toon`) remains the **reference implementation** in TypeScript/JavaScript. For specification discussions, issues, and contributions, please use the spec repository.



================================================
FILE: tsconfig.json
================================================
{
  "compilerOptions": {
    "target": "ESNext",
    "rootDir": ".",
    "module": "ESNext",
    "moduleResolution": "Bundler",
    "resolveJsonModule": true,
    "strict": true,
    "noUncheckedIndexedAccess": true,
    "declaration": true,
    "noEmit": true,
    "esModuleInterop": true,
    "isolatedDeclarations": true,
    "isolatedModules": true,
    "verbatimModuleSyntax": true,
    "erasableSyntaxOnly": true,
    "skipLibCheck": true
  }
}



================================================
FILE: .editorconfig
================================================
root = true

[*]
charset = utf-8
indent_style = space
indent_size = 2
end_of_line = lf
insert_final_newline = true
trim_trailing_whitespace = true



================================================
FILE: .npmrc
================================================
shamefully-hoist=true



================================================
FILE: benchmarks/README.md
================================================
# TOON Benchmarks

Benchmarks measuring TOON's **token efficiency** and **retrieval accuracy** compared to JSON, XML, YAML, and CSV.

> [!NOTE]
> Results are automatically embedded in the [main README](../README.md#benchmarks). This guide focuses on running the benchmarks locally.

## Quick Start

```bash
# Run token efficiency benchmark
pnpm benchmark:token-efficiency

# Run retrieval accuracy benchmark (requires API keys)
pnpm benchmark:accuracy
```

## Token Efficiency Benchmark

Measures token count reduction across JSON, XML, YAML, CSV, and TOON:

1. Generate datasets (GitHub repos, analytics, orders)
2. Convert to all formats (TOON, JSON, XML, YAML, CSV)
3. Tokenize using `gpt-tokenizer` (`o200k_base` encoding)
4. Calculate savings and generate report

```bash
pnpm benchmark:token-efficiency
```

Results are saved to `results/token-efficiency.md`.

## Retrieval Accuracy Benchmark

Tests how well LLMs can answer questions about data in different formats (TOON, JSON, JSON compact, XML, YAML, CSV):

1. Generate ~150-160 questions across 4 datasets
2. Convert each dataset to all 6 formats
3. Query each LLM with formatted data + question
4. Validate answers using `gpt-5-nano` as judge
5. Aggregate metrics and generate report

### Setup

1. Edit [`src/evaluate.ts`](./src/evaluate.ts) and add models to the exported `models` array:
   ```ts
   export const models: LanguageModelV2[] = [
     openai('gpt-5-nano'),
     anthropic('claude-haiku-4-5-20251001'),
     google('gemini-2.5-flash'),
     xai('grok-4-fast-non-reasoning'),
     // Add your models here
   ]
   ```
2. Duplicate `.env.example` to `.env` and add your API keys:
   ```bash
   cp .env.example .env
   ```

### Usage

```bash
# Full benchmark
pnpm benchmark:accuracy

# Dry run (10 questions only, for testing setup)
DRY_RUN=true pnpm benchmark:accuracy
```

Running the script will:

1. Prompt you to select which models to test.
2. Skip models with existing results (rerun to overwrite).
3. Show progress with rate limiting.
4. Save results to `results/accuracy/models/{model-id}.json`.
5. Generate report at `results/retrieval-accuracy.md`.

### Configuration

Edit [`src/constants.ts`](./src/constants.ts) to adjust:

- `MODEL_RPM_LIMITS` ‚Äì Rate limits per model
- `DEFAULT_CONCURRENCY` ‚Äì Parallel tasks (default: 10)
- `DRY_RUN_LIMITS` ‚Äì Questions per dry run (default: 10)

## Project Structure

```
scripts/
‚îú‚îÄ‚îÄ accuracy-benchmark.ts         # Retrieval accuracy benchmark
‚îú‚îÄ‚îÄ token-efficiency-benchmark.ts # Token counting benchmark
‚îî‚îÄ‚îÄ fetch-github-repos.ts         # Update GitHub dataset
src/
‚îú‚îÄ‚îÄ constants.ts                  # Configuration
‚îú‚îÄ‚îÄ datasets.ts                   # Test data generators
‚îú‚îÄ‚îÄ evaluate.ts                   # LLM evaluation
‚îú‚îÄ‚îÄ formatters.ts                 # Format converters
‚îú‚îÄ‚îÄ questions.ts                  # Question generation
‚îú‚îÄ‚îÄ report.ts                     # Markdown reports
‚îú‚îÄ‚îÄ storage.ts                    # Result caching
‚îî‚îÄ‚îÄ utils.ts                      # Helpers
data/
‚îî‚îÄ‚îÄ github-repos.json             # Top 100 GitHub repos
results/
‚îú‚îÄ‚îÄ token-efficiency.md           # Token savings report
‚îú‚îÄ‚îÄ retrieval-accuracy.md         # Accuracy report
‚îî‚îÄ‚îÄ accuracy/models/              # Per-model results (JSON)
```



================================================
FILE: benchmarks/package.json
================================================
{
  "name": "@toon/benchmarks",
  "type": "module",
  "private": true,
  "scripts": {
    "benchmark:token-efficiency": "tsx scripts/token-efficiency-benchmark.ts",
    "benchmark:accuracy": "tsx --env-file=.env scripts/accuracy-benchmark.ts",
    "fetch:github-repos": "tsx scripts/fetch-github-repos.ts"
  },
  "devDependencies": {
    "@ai-sdk/anthropic": "^2.0.40",
    "@ai-sdk/google": "^2.0.26",
    "@ai-sdk/openai": "^2.0.59",
    "@ai-sdk/provider": "^2.0.0",
    "@ai-sdk/xai": "^2.0.30",
    "@clack/prompts": "^0.11.0",
    "@faker-js/faker": "^10.1.0",
    "ai": "^5.0.86",
    "csv-stringify": "^6.6.0",
    "fast-xml-parser": "^5.3.0",
    "gpt-tokenizer": "^3.2.0",
    "ofetch": "^1.5.1",
    "p-map": "^7.0.3",
    "p-queue": "^9.0.0",
    "unstorage": "^1.17.2",
    "yaml": "^2.8.1"
  }
}



================================================
FILE: benchmarks/.env.example
================================================
# Add keys for the models you're testing
OPENAI_API_KEY=
ANTHROPIC_API_KEY=
GOOGLE_GENERATIVE_AI_API_KEY=
XAI_API_KEY=



================================================
FILE: benchmarks/data/github-repos.json
================================================
[
  {
    "id": 28457823,
    "name": "freeCodeCamp",
    "repo": "freeCodeCamp/freeCodeCamp",
    "description": "freeCodeCamp.org's open-source codebase and curriculum. Learn math, programming, and computer science for free.",
    "createdAt": "2014-12-24T17:49:19Z",
    "updatedAt": "2025-10-28T11:58:08Z",
    "pushedAt": "2025-10-28T10:17:16Z",
    "stars": 430886,
    "watchers": 8583,
    "forks": 42146,
    "defaultBranch": "main"
  },
  {
    "id": 132750724,
    "name": "build-your-own-x",
    "repo": "codecrafters-io/build-your-own-x",
    "description": "Master programming by recreating your favorite technologies from scratch.",
    "createdAt": "2018-05-09T12:03:18Z",
    "updatedAt": "2025-10-28T12:37:11Z",
    "pushedAt": "2025-10-10T18:45:01Z",
    "stars": 430877,
    "watchers": 6332,
    "forks": 40453,
    "defaultBranch": "master"
  },
  {
    "id": 21737465,
    "name": "awesome",
    "repo": "sindresorhus/awesome",
    "description": "üòé Awesome lists about all kinds of interesting topics",
    "createdAt": "2014-07-11T13:42:37Z",
    "updatedAt": "2025-10-28T12:40:21Z",
    "pushedAt": "2025-10-27T17:57:31Z",
    "stars": 410052,
    "watchers": 8017,
    "forks": 32029,
    "defaultBranch": "main"
  },
  {
    "id": 13491895,
    "name": "free-programming-books",
    "repo": "EbookFoundation/free-programming-books",
    "description": ":books: Freely available programming books",
    "createdAt": "2013-10-11T06:50:37Z",
    "updatedAt": "2025-10-28T12:16:59Z",
    "pushedAt": "2025-10-28T01:52:13Z",
    "stars": 375307,
    "watchers": 9786,
    "forks": 65199,
    "defaultBranch": "main"
  },
  {
    "id": 54346799,
    "name": "public-apis",
    "repo": "public-apis/public-apis",
    "description": "A collective list of free APIs",
    "createdAt": "2016-03-20T23:49:42Z",
    "updatedAt": "2025-10-28T12:33:14Z",
    "pushedAt": "2025-05-20T15:56:34Z",
    "stars": 374003,
    "watchers": 4400,
    "forks": 39473,
    "defaultBranch": "master"
  },
  {
    "id": 85077558,
    "name": "developer-roadmap",
    "repo": "kamranahmedse/developer-roadmap",
    "description": "Interactive roadmaps, guides and other educational content to help developers grow in their careers.",
    "createdAt": "2017-03-15T13:45:52Z",
    "updatedAt": "2025-10-28T12:31:02Z",
    "pushedAt": "2025-10-28T11:09:58Z",
    "stars": 342136,
    "watchers": 6886,
    "forks": 43234,
    "defaultBranch": "master"
  },
  {
    "id": 60493101,
    "name": "coding-interview-university",
    "repo": "jwasham/coding-interview-university",
    "description": "A complete computer science study plan to become a software engineer.",
    "createdAt": "2016-06-06T02:34:12Z",
    "updatedAt": "2025-10-28T12:21:02Z",
    "pushedAt": "2025-08-28T14:42:47Z",
    "stars": 331947,
    "watchers": 8511,
    "forks": 81057,
    "defaultBranch": "main"
  },
  {
    "id": 83222441,
    "name": "system-design-primer",
    "repo": "donnemartin/system-design-primer",
    "description": "Learn how to design large-scale systems. Prep for the system design interview.  Includes Anki flashcards.",
    "createdAt": "2017-02-26T16:15:28Z",
    "updatedAt": "2025-10-28T12:32:56Z",
    "pushedAt": "2025-05-21T11:13:33Z",
    "stars": 324409,
    "watchers": 6819,
    "forks": 52904,
    "defaultBranch": "master"
  },
  {
    "id": 177736533,
    "name": "996.ICU",
    "repo": "996icu/996.ICU",
    "description": "Repo for counting stars and contributing. Press F to pay respect to glorious developers.",
    "createdAt": "2019-03-26T07:31:14Z",
    "updatedAt": "2025-10-28T11:07:13Z",
    "pushedAt": "2025-08-22T06:01:29Z",
    "stars": 274706,
    "watchers": 4216,
    "forks": 21029,
    "defaultBranch": "master"
  },
  {
    "id": 21289110,
    "name": "awesome-python",
    "repo": "vinta/awesome-python",
    "description": "An opinionated list of awesome Python frameworks, libraries, software and resources.",
    "createdAt": "2014-06-27T21:00:06Z",
    "updatedAt": "2025-10-28T12:28:13Z",
    "pushedAt": "2025-10-16T13:40:58Z",
    "stars": 266661,
    "watchers": 6128,
    "forks": 26604,
    "defaultBranch": "master"
  },
  {
    "id": 36633370,
    "name": "awesome-selfhosted",
    "repo": "awesome-selfhosted/awesome-selfhosted",
    "description": "A list of Free Software network services and web applications which can be hosted on your own servers",
    "createdAt": "2015-06-01T02:33:17Z",
    "updatedAt": "2025-10-28T12:24:53Z",
    "pushedAt": "2025-10-27T21:40:26Z",
    "stars": 255143,
    "watchers": 2990,
    "forks": 11802,
    "defaultBranch": "master"
  },
  {
    "id": 88011908,
    "name": "project-based-learning",
    "repo": "practical-tutorials/project-based-learning",
    "description": "Curated list of project-based tutorials",
    "createdAt": "2017-04-12T05:07:46Z",
    "updatedAt": "2025-10-28T12:22:51Z",
    "pushedAt": "2024-08-15T05:33:54Z",
    "stars": 248050,
    "watchers": 3446,
    "forks": 32431,
    "defaultBranch": "master"
  },
  {
    "id": 10270250,
    "name": "react",
    "repo": "facebook/react",
    "description": "The library for web and native user interfaces.",
    "createdAt": "2013-05-24T16:15:54Z",
    "updatedAt": "2025-10-28T12:24:55Z",
    "pushedAt": "2025-10-28T01:25:20Z",
    "stars": 240100,
    "watchers": 6686,
    "forks": 49682,
    "defaultBranch": "main"
  },
  {
    "id": 63476337,
    "name": "Python",
    "repo": "TheAlgorithms/Python",
    "description": "All Algorithms implemented in Python",
    "createdAt": "2016-07-16T09:44:01Z",
    "updatedAt": "2025-10-28T12:25:22Z",
    "pushedAt": "2025-10-20T00:59:36Z",
    "stars": 212119,
    "watchers": 5975,
    "forks": 49025,
    "defaultBranch": "master"
  },
  {
    "id": 11730342,
    "name": "vue",
    "repo": "vuejs/vue",
    "description": "This is the repo for Vue 2. For Vue 3, go to https://github.com/vuejs/core",
    "createdAt": "2013-07-29T03:24:51Z",
    "updatedAt": "2025-10-28T10:39:45Z",
    "pushedAt": "2024-10-10T07:24:15Z",
    "stars": 209636,
    "watchers": 5786,
    "forks": 33795,
    "defaultBranch": "main"
  },
  {
    "id": 2325298,
    "name": "linux",
    "repo": "torvalds/linux",
    "description": "Linux kernel source tree",
    "createdAt": "2011-09-04T22:48:12Z",
    "updatedAt": "2025-10-28T12:39:23Z",
    "pushedAt": "2025-10-27T18:11:32Z",
    "stars": 205858,
    "watchers": 7743,
    "forks": 58047,
    "defaultBranch": "master"
  },
  {
    "id": 19415064,
    "name": "computer-science",
    "repo": "ossu/computer-science",
    "description": "üéì Path to a free self-taught education in Computer Science!",
    "createdAt": "2014-05-04T00:18:39Z",
    "updatedAt": "2025-10-28T12:41:20Z",
    "pushedAt": "2025-08-23T18:48:52Z",
    "stars": 196086,
    "watchers": 5936,
    "forks": 24474,
    "defaultBranch": "master"
  },
  {
    "id": 126577260,
    "name": "javascript-algorithms",
    "repo": "trekhleb/javascript-algorithms",
    "description": "üìù Algorithms and data structures implemented in JavaScript with explanations and links to further readings",
    "createdAt": "2018-03-24T07:47:04Z",
    "updatedAt": "2025-10-28T12:37:32Z",
    "pushedAt": "2025-10-22T15:03:29Z",
    "stars": 193744,
    "watchers": 4268,
    "forks": 30929,
    "defaultBranch": "master"
  },
  {
    "id": 45717250,
    "name": "tensorflow",
    "repo": "tensorflow/tensorflow",
    "description": "An Open Source Machine Learning Framework for Everyone",
    "createdAt": "2015-11-07T01:19:20Z",
    "updatedAt": "2025-10-28T11:56:54Z",
    "pushedAt": "2025-10-28T12:37:04Z",
    "stars": 192240,
    "watchers": 7431,
    "forks": 74932,
    "defaultBranch": "master"
  },
  {
    "id": 138393139,
    "name": "the-book-of-secret-knowledge",
    "repo": "trimstray/the-book-of-secret-knowledge",
    "description": "A collection of inspiring lists, manuals, cheatsheets, blogs, hacks, one-liners, cli/web tools and more.",
    "createdAt": "2018-06-23T10:43:14Z",
    "updatedAt": "2025-10-28T12:40:20Z",
    "pushedAt": "2024-11-19T14:00:38Z",
    "stars": 191487,
    "watchers": 2678,
    "forks": 11764,
    "defaultBranch": "master"
  },
  {
    "id": 14440270,
    "name": "You-Dont-Know-JS",
    "repo": "getify/You-Dont-Know-JS",
    "description": "A book series (2 published editions) on the JS language.",
    "createdAt": "2013-11-16T02:37:24Z",
    "updatedAt": "2025-10-28T11:34:43Z",
    "pushedAt": "2025-05-20T14:22:36Z",
    "stars": 183653,
    "watchers": 5803,
    "forks": 33671,
    "defaultBranch": "2nd-ed"
  },
  {
    "id": 121395510,
    "name": "CS-Notes",
    "repo": "CyC2018/CS-Notes",
    "description": ":books: ÊäÄÊúØÈù¢ËØïÂøÖÂ§áÂü∫Á°ÄÁü•ËØÜ„ÄÅLeetcode„ÄÅËÆ°ÁÆóÊú∫Êìç‰ΩúÁ≥ªÁªü„ÄÅËÆ°ÁÆóÊú∫ÁΩëÁªú„ÄÅÁ≥ªÁªüËÆæËÆ°",
    "createdAt": "2018-02-13T14:56:24Z",
    "updatedAt": "2025-10-28T11:56:57Z",
    "pushedAt": "2024-08-21T09:40:10Z",
    "stars": 182661,
    "watchers": 5249,
    "forks": 51249,
    "defaultBranch": "master"
  },
  {
    "id": 291137,
    "name": "ohmyzsh",
    "repo": "ohmyzsh/ohmyzsh",
    "description": "üôÉ   A delightful community-driven (with 2,400+ contributors) framework for managing your zsh configuration. Includes 300+ optional plugins (rails, git, macOS, hub, docker, homebrew, node, php, python, etc), 140+ themes to spice up your morning, and an auto-update tool that makes it easy to keep up with the latest updates from the community.",
    "createdAt": "2009-08-28T18:15:37Z",
    "updatedAt": "2025-10-28T12:39:19Z",
    "pushedAt": "2025-10-27T18:37:07Z",
    "stars": 182331,
    "watchers": 2620,
    "forks": 26261,
    "defaultBranch": "master"
  },
  {
    "id": 614765452,
    "name": "AutoGPT",
    "repo": "Significant-Gravitas/AutoGPT",
    "description": "AutoGPT is the vision of accessible AI for everyone, to use and to build on. Our mission is to provide the tools, so that you can focus on what matters.",
    "createdAt": "2023-03-16T09:21:07Z",
    "updatedAt": "2025-10-28T12:01:03Z",
    "pushedAt": "2025-10-28T11:50:06Z",
    "stars": 179337,
    "watchers": 1547,
    "forks": 46094,
    "defaultBranch": "master"
  },
  {
    "id": 41881900,
    "name": "vscode",
    "repo": "microsoft/vscode",
    "description": "Visual Studio Code",
    "createdAt": "2015-09-03T20:23:38Z",
    "updatedAt": "2025-10-28T12:22:53Z",
    "pushedAt": "2025-10-28T12:33:55Z",
    "stars": 177962,
    "watchers": 3366,
    "forks": 35810,
    "defaultBranch": "main"
  },
  {
    "id": 123458551,
    "name": "Python-100-Days",
    "repo": "jackfrued/Python-100-Days",
    "description": "Python - 100Â§©‰ªéÊñ∞ÊâãÂà∞Â§ßÂ∏à",
    "createdAt": "2018-03-01T16:05:52Z",
    "updatedAt": "2025-10-28T12:40:38Z",
    "pushedAt": "2025-03-28T10:29:23Z",
    "stars": 173818,
    "watchers": 6098,
    "forks": 54782,
    "defaultBranch": "master"
  },
  {
    "id": 2126244,
    "name": "bootstrap",
    "repo": "twbs/bootstrap",
    "description": "The most popular HTML, CSS, and JavaScript framework for developing responsive, mobile first projects on the web.",
    "createdAt": "2011-07-29T21:19:00Z",
    "updatedAt": "2025-10-28T12:25:19Z",
    "pushedAt": "2025-10-28T10:02:33Z",
    "stars": 173612,
    "watchers": 6680,
    "forks": 79159,
    "defaultBranch": "main"
  },
  {
    "id": 31792824,
    "name": "flutter",
    "repo": "flutter/flutter",
    "description": "Flutter makes it easy and fast to build beautiful apps for mobile and beyond",
    "createdAt": "2015-03-06T22:54:58Z",
    "updatedAt": "2025-10-28T12:35:50Z",
    "pushedAt": "2025-10-28T12:35:51Z",
    "stars": 173572,
    "watchers": 3481,
    "forks": 29419,
    "defaultBranch": "master"
  },
  {
    "id": 1062897,
    "name": "gitignore",
    "repo": "github/gitignore",
    "description": "A collection of useful .gitignore templates",
    "createdAt": "2010-11-08T20:17:14Z",
    "updatedAt": "2025-10-28T12:36:17Z",
    "pushedAt": "2025-09-10T18:42:03Z",
    "stars": 170327,
    "watchers": 3367,
    "forks": 82996,
    "defaultBranch": "main"
  },
  {
    "id": 35955666,
    "name": "the-art-of-command-line",
    "repo": "jlevy/the-art-of-command-line",
    "description": "Master the command line, in one page",
    "createdAt": "2015-05-20T15:11:03Z",
    "updatedAt": "2025-10-28T10:16:58Z",
    "pushedAt": "2024-06-25T18:13:44Z",
    "stars": 158603,
    "watchers": 2812,
    "forks": 14753,
    "defaultBranch": "master"
  },
  {
    "id": 527591471,
    "name": "stable-diffusion-webui",
    "repo": "AUTOMATIC1111/stable-diffusion-webui",
    "description": "Stable Diffusion web UI",
    "createdAt": "2022-08-22T14:05:26Z",
    "updatedAt": "2025-10-28T12:41:21Z",
    "pushedAt": "2025-10-07T20:06:10Z",
    "stars": 157629,
    "watchers": 1156,
    "forks": 29254,
    "defaultBranch": "master"
  },
  {
    "id": 21540759,
    "name": "awesome-go",
    "repo": "avelino/awesome-go",
    "description": "A curated list of awesome Go frameworks, libraries and software",
    "createdAt": "2014-07-06T13:42:15Z",
    "updatedAt": "2025-10-28T12:41:20Z",
    "pushedAt": "2025-10-22T12:15:14Z",
    "stars": 155912,
    "watchers": 2820,
    "forks": 12712,
    "defaultBranch": "main"
  },
  {
    "id": 658928958,
    "name": "ollama",
    "repo": "ollama/ollama",
    "description": "Get up and running with OpenAI gpt-oss, DeepSeek-R1, Gemma 3 and other models.",
    "createdAt": "2023-06-26T19:39:32Z",
    "updatedAt": "2025-10-28T12:05:06Z",
    "pushedAt": "2025-10-28T08:16:13Z",
    "stars": 154883,
    "watchers": 876,
    "forks": 13480,
    "defaultBranch": "main"
  },
  {
    "id": 233472199,
    "name": "Microsoft-Activation-Scripts",
    "repo": "massgravel/Microsoft-Activation-Scripts",
    "description": "Open-source Windows and Office activator featuring HWID, Ohook, TSforge, KMS38, and Online KMS activation methods, along with advanced troubleshooting.",
    "createdAt": "2020-01-12T23:03:34Z",
    "updatedAt": "2025-10-28T12:40:24Z",
    "pushedAt": "2025-09-30T22:22:59Z",
    "stars": 154022,
    "watchers": 1319,
    "forks": 14869,
    "defaultBranch": "master"
  },
  {
    "id": 132464395,
    "name": "JavaGuide",
    "repo": "Snailclimb/JavaGuide",
    "description": "„ÄåJavaÂ≠¶‰π†+Èù¢ËØïÊåáÂçó„Äç‰∏Ä‰ªΩÊ∂µÁõñÂ§ßÈÉ®ÂàÜ Java Á®ãÂ∫èÂëòÊâÄÈúÄË¶ÅÊéåÊè°ÁöÑÊ†∏ÂøÉÁü•ËØÜ„ÄÇÂáÜÂ§á Java Èù¢ËØïÔºåÈ¶ñÈÄâ JavaGuideÔºÅ",
    "createdAt": "2018-05-07T13:27:00Z",
    "updatedAt": "2025-10-28T12:01:53Z",
    "pushedAt": "2025-10-27T11:09:05Z",
    "stars": 152325,
    "watchers": 4469,
    "forks": 46021,
    "defaultBranch": "main"
  },
  {
    "id": 193215554,
    "name": "n8n",
    "repo": "n8n-io/n8n",
    "description": "Fair-code workflow automation platform with native AI capabilities. Combine visual building with custom code, self-host or cloud, 400+ integrations.",
    "createdAt": "2019-06-22T09:24:21Z",
    "updatedAt": "2025-10-28T12:41:23Z",
    "pushedAt": "2025-10-28T12:34:50Z",
    "stars": 152300,
    "watchers": 889,
    "forks": 48578,
    "defaultBranch": "master"
  },
  {
    "id": 155220641,
    "name": "transformers",
    "repo": "huggingface/transformers",
    "description": "ü§ó Transformers: the model-definition framework for state-of-the-art machine learning models in text, vision, audio, and multimodal models, for both inference and training. ",
    "createdAt": "2018-10-29T13:56:00Z",
    "updatedAt": "2025-10-28T12:41:10Z",
    "pushedAt": "2025-10-28T12:38:18Z",
    "stars": 151745,
    "watchers": 1167,
    "forks": 30971,
    "defaultBranch": "main"
  },
  {
    "id": 6498492,
    "name": "javascript",
    "repo": "airbnb/javascript",
    "description": "JavaScript Style Guide",
    "createdAt": "2012-11-01T23:13:50Z",
    "updatedAt": "2025-10-28T11:07:36Z",
    "pushedAt": "2025-09-17T18:12:44Z",
    "stars": 147700,
    "watchers": 3702,
    "forks": 26795,
    "defaultBranch": "master"
  },
  {
    "id": 1039520,
    "name": "youtube-dl",
    "repo": "ytdl-org/youtube-dl",
    "description": "Command-line program to download videos from YouTube.com and other video sites",
    "createdAt": "2010-10-31T14:35:07Z",
    "updatedAt": "2025-10-28T12:01:08Z",
    "pushedAt": "2025-10-18T10:02:28Z",
    "stars": 138581,
    "watchers": 2160,
    "forks": 10527,
    "defaultBranch": "master"
  },
  {
    "id": 599320067,
    "name": "langflow",
    "repo": "langflow-ai/langflow",
    "description": "Langflow is a powerful tool for building and deploying AI-powered agents and workflows.",
    "createdAt": "2023-02-08T22:28:03Z",
    "updatedAt": "2025-10-28T12:04:14Z",
    "pushedAt": "2025-10-28T11:44:40Z",
    "stars": 136336,
    "watchers": 454,
    "forks": 7859,
    "defaultBranch": "main"
  },
  {
    "id": 574523116,
    "name": "awesome-chatgpt-prompts",
    "repo": "f/awesome-chatgpt-prompts",
    "description": "This repo includes ChatGPT prompt curation to use ChatGPT and other LLM tools better.",
    "createdAt": "2022-12-05T13:54:13Z",
    "updatedAt": "2025-10-28T12:32:02Z",
    "pushedAt": "2025-10-14T17:23:13Z",
    "stars": 135843,
    "watchers": 1563,
    "forks": 18078,
    "defaultBranch": "main"
  },
  {
    "id": 70107786,
    "name": "next.js",
    "repo": "vercel/next.js",
    "description": "The React Framework",
    "createdAt": "2016-10-05T23:32:51Z",
    "updatedAt": "2025-10-28T12:19:30Z",
    "pushedAt": "2025-10-28T12:22:48Z",
    "stars": 135333,
    "watchers": 1495,
    "forks": 29693,
    "defaultBranch": "canary"
  },
  {
    "id": 307260205,
    "name": "yt-dlp",
    "repo": "yt-dlp/yt-dlp",
    "description": "A feature-rich command-line audio/video downloader",
    "createdAt": "2020-10-26T04:22:55Z",
    "updatedAt": "2025-10-28T12:38:42Z",
    "pushedAt": "2025-10-27T23:21:38Z",
    "stars": 132949,
    "watchers": 678,
    "forks": 10668,
    "defaultBranch": "master"
  },
  {
    "id": 58028038,
    "name": "HelloGitHub",
    "repo": "521xueweihan/HelloGitHub",
    "description": ":octocat: ÂàÜ‰∫´ GitHub ‰∏äÊúâË∂£„ÄÅÂÖ•Èó®Á∫ßÁöÑÂºÄÊ∫êÈ°πÁõÆ„ÄÇShare interesting, entry-level open source projects on GitHub.",
    "createdAt": "2016-05-04T06:24:11Z",
    "updatedAt": "2025-10-28T12:13:38Z",
    "pushedAt": "2025-10-28T00:14:25Z",
    "stars": 132365,
    "watchers": 4187,
    "forks": 10822,
    "defaultBranch": "master"
  },
  {
    "id": 62607227,
    "name": "tech-interview-handbook",
    "repo": "yangshun/tech-interview-handbook",
    "description": "üíØ Curated coding interview preparation materials for busy software engineers",
    "createdAt": "2016-07-05T05:00:48Z",
    "updatedAt": "2025-10-28T09:33:23Z",
    "pushedAt": "2025-08-27T00:17:33Z",
    "stars": 131430,
    "watchers": 2182,
    "forks": 15945,
    "defaultBranch": "main"
  },
  {
    "id": 23096959,
    "name": "go",
    "repo": "golang/go",
    "description": "The Go programming language",
    "createdAt": "2014-08-19T04:33:40Z",
    "updatedAt": "2025-10-28T11:52:10Z",
    "pushedAt": "2025-10-28T06:29:46Z",
    "stars": 130554,
    "watchers": 3347,
    "forks": 18419,
    "defaultBranch": "master"
  },
  {
    "id": 111583593,
    "name": "scrcpy",
    "repo": "Genymobile/scrcpy",
    "description": "Display and control your Android device",
    "createdAt": "2017-11-21T18:00:27Z",
    "updatedAt": "2025-10-28T12:05:50Z",
    "pushedAt": "2025-10-27T08:59:41Z",
    "stars": 130304,
    "watchers": 1322,
    "forks": 12194,
    "defaultBranch": "master"
  },
  {
    "id": 241576270,
    "name": "fucking-algorithm",
    "repo": "labuladong/fucking-algorithm",
    "description": "Âà∑ÁÆóÊ≥ïÂÖ®Èù†Â•óË∑ØÔºåËÆ§ÂáÜ labuladong Â∞±Â§ü‰∫ÜÔºÅEnglish version supported! Crack LeetCode, not only how, but also why. ",
    "createdAt": "2020-02-19T09:01:23Z",
    "updatedAt": "2025-10-28T08:35:53Z",
    "pushedAt": "2025-10-08T04:06:00Z",
    "stars": 129669,
    "watchers": 2283,
    "forks": 23452,
    "defaultBranch": "master"
  },
  {
    "id": 112507086,
    "name": "30-seconds-of-code",
    "repo": "Chalarangelo/30-seconds-of-code",
    "description": "Coding articles to level up your development skills",
    "createdAt": "2017-11-29T17:35:03Z",
    "updatedAt": "2025-10-28T09:14:02Z",
    "pushedAt": "2025-10-22T12:51:11Z",
    "stars": 125639,
    "watchers": 2594,
    "forks": 12362,
    "defaultBranch": "master"
  },
  {
    "id": 184456251,
    "name": "PowerToys",
    "repo": "microsoft/PowerToys",
    "description": "Microsoft PowerToys is a collection of utilities that help you customize Windows and streamline everyday tasks",
    "createdAt": "2019-05-01T17:44:02Z",
    "updatedAt": "2025-10-28T12:21:07Z",
    "pushedAt": "2025-10-28T10:55:13Z",
    "stars": 125271,
    "watchers": 1166,
    "forks": 7454,
    "defaultBranch": "main"
  },
  {
    "id": 29028775,
    "name": "react-native",
    "repo": "facebook/react-native",
    "description": "A framework for building native applications using React",
    "createdAt": "2015-01-09T18:10:16Z",
    "updatedAt": "2025-10-28T12:36:00Z",
    "pushedAt": "2025-10-28T12:25:56Z",
    "stars": 124334,
    "watchers": 3563,
    "forks": 24916,
    "defaultBranch": "main"
  },
  {
    "id": 9384267,
    "name": "electron",
    "repo": "electron/electron",
    "description": ":electron: Build cross-platform desktop apps with JavaScript, HTML, and CSS",
    "createdAt": "2013-04-12T01:47:36Z",
    "updatedAt": "2025-10-28T11:35:46Z",
    "pushedAt": "2025-10-28T09:28:32Z",
    "stars": 118860,
    "watchers": 2801,
    "forks": 16584,
    "defaultBranch": "main"
  },
  {
    "id": 552661142,
    "name": "langchain",
    "repo": "langchain-ai/langchain",
    "description": "ü¶úüîó Build context-aware reasoning applications",
    "createdAt": "2022-10-17T02:58:36Z",
    "updatedAt": "2025-10-28T12:37:33Z",
    "pushedAt": "2025-10-27T23:47:43Z",
    "stars": 118261,
    "watchers": 776,
    "forks": 19476,
    "defaultBranch": "master"
  },
  {
    "id": 20580498,
    "name": "kubernetes",
    "repo": "kubernetes/kubernetes",
    "description": "Production-Grade Container Scheduling and Management",
    "createdAt": "2014-06-06T22:56:04Z",
    "updatedAt": "2025-10-28T12:19:38Z",
    "pushedAt": "2025-10-28T10:29:37Z",
    "stars": 118246,
    "watchers": 3189,
    "forks": 41587,
    "defaultBranch": "master"
  },
  {
    "id": 561730219,
    "name": "hello-algo",
    "repo": "krahets/hello-algo",
    "description": "„ÄäHello ÁÆóÊ≥ï„ÄãÔºöÂä®ÁîªÂõæËß£„ÄÅ‰∏ÄÈîÆËøêË°åÁöÑÊï∞ÊçÆÁªìÊûÑ‰∏éÁÆóÊ≥ïÊïôÁ®ã„ÄÇÊîØÊåÅ Python, Java, C++, C, C#, JS, Go, Swift, Rust, Ruby, Kotlin, TS, Dart ‰ª£Á†Å„ÄÇÁÆÄ‰ΩìÁâàÂíåÁπÅ‰ΩìÁâàÂêåÊ≠•Êõ¥Êñ∞ÔºåEnglish version in translation",
    "createdAt": "2022-11-04T11:08:34Z",
    "updatedAt": "2025-10-28T12:30:36Z",
    "pushedAt": "2025-10-16T21:33:36Z",
    "stars": 118105,
    "watchers": 583,
    "forks": 14500,
    "defaultBranch": "main"
  },
  {
    "id": 626805178,
    "name": "dify",
    "repo": "langgenius/dify",
    "description": "Production-ready platform for agentic workflow development.",
    "createdAt": "2023-04-12T07:40:24Z",
    "updatedAt": "2025-10-28T12:18:46Z",
    "pushedAt": "2025-10-28T10:48:12Z",
    "stars": 117486,
    "watchers": 698,
    "forks": 18151,
    "defaultBranch": "main"
  },
  {
    "id": 14098069,
    "name": "free-programming-books-zh_CN",
    "repo": "justjavac/free-programming-books-zh_CN",
    "description": ":books: ÂÖçË¥πÁöÑËÆ°ÁÆóÊú∫ÁºñÁ®ãÁ±ª‰∏≠Êñá‰π¶Á±çÔºåÊ¨¢ËøéÊäïÁ®ø",
    "createdAt": "2013-11-04T01:59:19Z",
    "updatedAt": "2025-10-28T09:19:09Z",
    "pushedAt": "2024-07-15T08:55:20Z",
    "stars": 115543,
    "watchers": 5859,
    "forks": 28362,
    "defaultBranch": "main"
  },
  {
    "id": 32484381,
    "name": "free-for-dev",
    "repo": "ripienaar/free-for-dev",
    "description": "A list of SaaS, PaaS and IaaS offerings that have free tiers of interest to devops and infradev",
    "createdAt": "2015-03-18T21:06:26Z",
    "updatedAt": "2025-10-28T11:38:56Z",
    "pushedAt": "2025-10-23T04:49:00Z",
    "stars": 114128,
    "watchers": 1735,
    "forks": 11684,
    "defaultBranch": "master"
  },
  {
    "id": 27193779,
    "name": "node",
    "repo": "nodejs/node",
    "description": "Node.js JavaScript runtime ‚ú®üê¢üöÄ‚ú®",
    "createdAt": "2014-11-26T19:57:11Z",
    "updatedAt": "2025-10-28T12:34:32Z",
    "pushedAt": "2025-10-28T11:29:04Z",
    "stars": 114019,
    "watchers": 2963,
    "forks": 33580,
    "defaultBranch": "main"
  },
  {
    "id": 701547123,
    "name": "open-webui",
    "repo": "open-webui/open-webui",
    "description": "User-friendly AI Interface (Supports Ollama, OpenAI API, ...)",
    "createdAt": "2023-10-06T22:08:27Z",
    "updatedAt": "2025-10-28T12:22:47Z",
    "pushedAt": "2025-10-28T08:46:37Z",
    "stars": 113575,
    "watchers": 515,
    "forks": 15783,
    "defaultBranch": "main"
  },
  {
    "id": 808144141,
    "name": "FreeDomain",
    "repo": "DigitalPlatDev/FreeDomain",
    "description": "DigitalPlat FreeDomain: Free Domain For Everyone",
    "createdAt": "2024-05-30T13:23:00Z",
    "updatedAt": "2025-10-28T12:40:49Z",
    "pushedAt": "2025-09-25T12:12:01Z",
    "stars": 111985,
    "watchers": 120,
    "forks": 2068,
    "defaultBranch": "main"
  },
  {
    "id": 943149,
    "name": "d3",
    "repo": "d3/d3",
    "description": "Bring data to life with SVG, Canvas and HTML. :bar_chart::chart_with_upwards_trend::tada:",
    "createdAt": "2010-09-27T17:22:42Z",
    "updatedAt": "2025-10-28T09:47:08Z",
    "pushedAt": "2025-07-27T11:30:40Z",
    "stars": 111693,
    "watchers": 3558,
    "forks": 22850,
    "defaultBranch": "main"
  },
  {
    "id": 231283452,
    "name": "excalidraw",
    "repo": "excalidraw/excalidraw",
    "description": "Virtual whiteboard for sketching hand-drawn like diagrams",
    "createdAt": "2020-01-02T01:04:43Z",
    "updatedAt": "2025-10-28T12:38:34Z",
    "pushedAt": "2025-10-28T11:43:31Z",
    "stars": 109315,
    "watchers": 467,
    "forks": 11345,
    "defaultBranch": "master"
  },
  {
    "id": 576201,
    "name": "three.js",
    "repo": "mrdoob/three.js",
    "description": "JavaScript 3D Library.",
    "createdAt": "2010-03-23T18:58:01Z",
    "updatedAt": "2025-10-28T12:07:59Z",
    "pushedAt": "2025-10-28T12:13:11Z",
    "stars": 109143,
    "watchers": 2518,
    "forks": 36054,
    "defaultBranch": "dev"
  },
  {
    "id": 23088740,
    "name": "axios",
    "repo": "axios/axios",
    "description": "Promise based HTTP client for the browser and node.js",
    "createdAt": "2014-08-18T22:30:27Z",
    "updatedAt": "2025-10-28T12:10:56Z",
    "pushedAt": "2025-10-27T19:08:10Z",
    "stars": 108032,
    "watchers": 1169,
    "forks": 11371,
    "defaultBranch": "v1.x"
  },
  {
    "id": 724712,
    "name": "rust",
    "repo": "rust-lang/rust",
    "description": "Empowering everyone to build reliable and efficient software.",
    "createdAt": "2010-06-16T20:39:03Z",
    "updatedAt": "2025-10-28T12:40:15Z",
    "pushedAt": "2025-10-28T11:12:51Z",
    "stars": 107478,
    "watchers": 1468,
    "forks": 13900,
    "defaultBranch": "master"
  },
  {
    "id": 20929025,
    "name": "TypeScript",
    "repo": "microsoft/TypeScript",
    "description": "TypeScript is a superset of JavaScript that compiles to clean JavaScript output.",
    "createdAt": "2014-06-17T15:28:39Z",
    "updatedAt": "2025-10-28T12:19:23Z",
    "pushedAt": "2025-10-27T23:52:12Z",
    "stars": 106557,
    "watchers": 2148,
    "forks": 13086,
    "defaultBranch": "main"
  },
  {
    "id": 133442384,
    "name": "deno",
    "repo": "denoland/deno",
    "description": "A modern runtime for JavaScript and TypeScript.",
    "createdAt": "2018-05-15T01:34:26Z",
    "updatedAt": "2025-10-28T12:27:16Z",
    "pushedAt": "2025-10-28T09:10:45Z",
    "stars": 104939,
    "watchers": 1398,
    "forks": 5754,
    "defaultBranch": "main"
  },
  {
    "id": 103633984,
    "name": "nodebestpractices",
    "repo": "goldbergyoni/nodebestpractices",
    "description": ":white_check_mark:  The Node.js best practices list (July 2024)",
    "createdAt": "2017-09-15T08:33:19Z",
    "updatedAt": "2025-10-28T11:50:28Z",
    "pushedAt": "2025-04-15T21:52:42Z",
    "stars": 104455,
    "watchers": 1944,
    "forks": 10625,
    "defaultBranch": "master"
  },
  {
    "id": 63537249,
    "name": "create-react-app",
    "repo": "facebook/create-react-app",
    "description": "Set up a modern web app by running one command.",
    "createdAt": "2016-07-17T14:55:11Z",
    "updatedAt": "2025-10-28T12:35:24Z",
    "pushedAt": "2025-02-15T01:32:11Z",
    "stars": 103813,
    "watchers": 1891,
    "forks": 27148,
    "defaultBranch": "main"
  },
  {
    "id": 206462776,
    "name": "GitHub-Chinese-Top-Charts",
    "repo": "GrowingGit/GitHub-Chinese-Top-Charts",
    "description": ":cn: GitHub‰∏≠ÊñáÊéíË°åÊ¶úÔºåÂêÑËØ≠Ë®ÄÂàÜËÆæ„ÄåËΩØ‰ª∂ | ËµÑÊñô„ÄçÊ¶úÂçïÔºåÁ≤æÂáÜÂÆö‰Ωç‰∏≠ÊñáÂ•ΩÈ°πÁõÆ„ÄÇÂêÑÂèñÊâÄÈúÄÔºåÈ´òÊïàÂ≠¶‰π†„ÄÇ",
    "createdAt": "2019-09-05T03:01:56Z",
    "updatedAt": "2025-10-28T10:36:09Z",
    "pushedAt": "2024-10-12T06:51:36Z",
    "stars": 103358,
    "watchers": 2607,
    "forks": 13363,
    "defaultBranch": "master"
  },
  {
    "id": 15634981,
    "name": "godot",
    "repo": "godotengine/godot",
    "description": "Godot Engine ‚Äì Multi-platform 2D and 3D game engine",
    "createdAt": "2014-01-04T16:05:36Z",
    "updatedAt": "2025-10-28T11:39:26Z",
    "pushedAt": "2025-10-28T08:43:09Z",
    "stars": 102655,
    "watchers": 1493,
    "forks": 23457,
    "defaultBranch": "master"
  },
  {
    "id": 299354207,
    "name": "rustdesk",
    "repo": "rustdesk/rustdesk",
    "description": "An open-source remote desktop application designed for self-hosting, as an alternative to TeamViewer.",
    "createdAt": "2020-09-28T15:36:08Z",
    "updatedAt": "2025-10-28T12:27:03Z",
    "pushedAt": "2025-10-28T12:25:33Z",
    "stars": 101531,
    "watchers": 548,
    "forks": 14850,
    "defaultBranch": "master"
  },
  {
    "id": 655806940,
    "name": "generative-ai-for-beginners",
    "repo": "microsoft/generative-ai-for-beginners",
    "description": "21 Lessons, Get Started Building with Generative AI ",
    "createdAt": "2023-06-19T16:28:59Z",
    "updatedAt": "2025-10-28T12:25:17Z",
    "pushedAt": "2025-10-27T03:19:39Z",
    "stars": 101010,
    "watchers": 887,
    "forks": 53526,
    "defaultBranch": "main"
  },
  {
    "id": 100060912,
    "name": "terminal",
    "repo": "microsoft/terminal",
    "description": "The new Windows Terminal and the original Windows console host, all in the same place!",
    "createdAt": "2017-08-11T18:38:22Z",
    "updatedAt": "2025-10-28T12:08:57Z",
    "pushedAt": "2025-10-28T03:04:50Z",
    "stars": 100746,
    "watchers": 1334,
    "forks": 8879,
    "defaultBranch": "main"
  },
  {
    "id": 48378947,
    "name": "frp",
    "repo": "fatedier/frp",
    "description": "A fast reverse proxy to help you expose a local server behind a NAT or firewall to the internet.",
    "createdAt": "2015-12-21T15:24:59Z",
    "updatedAt": "2025-10-28T11:57:26Z",
    "pushedAt": "2025-10-28T09:52:35Z",
    "stars": 100048,
    "watchers": 1564,
    "forks": 14567,
    "defaultBranch": "dev"
  },
  {
    "id": 908531752,
    "name": "DeepSeek-V3",
    "repo": "deepseek-ai/DeepSeek-V3",
    "description": null,
    "createdAt": "2024-12-26T09:52:40Z",
    "updatedAt": "2025-10-28T12:11:53Z",
    "pushedAt": "2025-08-28T03:24:37Z",
    "stars": 100020,
    "watchers": 752,
    "forks": 16313,
    "defaultBranch": "main"
  },
  {
    "id": 55076063,
    "name": "Awesome-Hacking",
    "repo": "Hack-with-Github/Awesome-Hacking",
    "description": "A collection of various awesome lists for hackers, pentesters and security researchers",
    "createdAt": "2016-03-30T15:47:10Z",
    "updatedAt": "2025-10-28T12:11:25Z",
    "pushedAt": "2025-01-18T01:48:02Z",
    "stars": 99746,
    "watchers": 3932,
    "forks": 9633,
    "defaultBranch": "master"
  },
  {
    "id": 15204860,
    "name": "papers-we-love",
    "repo": "papers-we-love/papers-we-love",
    "description": "Papers from the computer science community to read and discuss.",
    "createdAt": "2013-12-15T14:31:41Z",
    "updatedAt": "2025-10-28T12:35:57Z",
    "pushedAt": "2025-10-10T15:35:14Z",
    "stars": 99660,
    "watchers": 3159,
    "forks": 6144,
    "defaultBranch": "main"
  },
  {
    "id": 24195339,
    "name": "angular",
    "repo": "angular/angular",
    "description": "Deliver web apps with confidence üöÄ",
    "createdAt": "2014-09-18T16:12:01Z",
    "updatedAt": "2025-10-28T11:07:05Z",
    "pushedAt": "2025-10-28T10:04:30Z",
    "stars": 99174,
    "watchers": 2980,
    "forks": 26730,
    "defaultBranch": "main"
  },
  {
    "id": 585146387,
    "name": "ui",
    "repo": "shadcn-ui/ui",
    "description": "A set of beautifully-designed, accessible components and a code distribution platform. Works with your favorite frameworks. Open Source. Open Code.",
    "createdAt": "2023-01-04T12:43:27Z",
    "updatedAt": "2025-10-28T12:32:30Z",
    "pushedAt": "2025-10-28T12:41:17Z",
    "stars": 98552,
    "watchers": 307,
    "forks": 7046,
    "defaultBranch": "main"
  },
  {
    "id": 196701619,
    "name": "tauri",
    "repo": "tauri-apps/tauri",
    "description": "Build smaller, faster, and more secure desktop and mobile applications with a web frontend.",
    "createdAt": "2019-07-13T09:09:37Z",
    "updatedAt": "2025-10-28T12:32:07Z",
    "pushedAt": "2025-10-28T10:29:35Z",
    "stars": 98262,
    "watchers": 530,
    "forks": 3139,
    "defaultBranch": "dev"
  },
  {
    "id": 157616880,
    "name": "iptv",
    "repo": "iptv-org/iptv",
    "description": "Collection of publicly available IPTV channels from all over the world",
    "createdAt": "2018-11-14T22:00:57Z",
    "updatedAt": "2025-10-28T12:32:18Z",
    "pushedAt": "2025-10-28T00:11:46Z",
    "stars": 98083,
    "watchers": 1952,
    "forks": 4199,
    "defaultBranch": "master"
  },
  {
    "id": 23083156,
    "name": "material-ui",
    "repo": "mui/material-ui",
    "description": "Material UI: Comprehensive React component library that implements Google's Material Design. Free forever.",
    "createdAt": "2014-08-18T19:11:54Z",
    "updatedAt": "2025-10-28T08:02:20Z",
    "pushedAt": "2025-10-28T06:08:34Z",
    "stars": 96887,
    "watchers": 1312,
    "forks": 32696,
    "defaultBranch": "master"
  },
  {
    "id": 34526884,
    "name": "ant-design",
    "repo": "ant-design/ant-design",
    "description": "An enterprise-class UI design language and React UI library",
    "createdAt": "2015-04-24T15:37:24Z",
    "updatedAt": "2025-10-28T11:00:38Z",
    "pushedAt": "2025-10-28T10:52:44Z",
    "stars": 96472,
    "watchers": 236,
    "forks": 53890,
    "defaultBranch": "master"
  },
  {
    "id": 243950408,
    "name": "HowToCook",
    "repo": "Anduin2017/HowToCook",
    "description": "Á®ãÂ∫èÂëòÂú®ÂÆ∂ÂÅöÈ•≠ÊñπÊ≥ïÊåáÂçó„ÄÇProgrammer's guide about how to cook at home (Simplified Chinese only).",
    "createdAt": "2020-02-29T10:43:49Z",
    "updatedAt": "2025-10-28T12:35:03Z",
    "pushedAt": "2025-10-28T11:30:11Z",
    "stars": 95425,
    "watchers": 488,
    "forks": 10651,
    "defaultBranch": "master"
  },
  {
    "id": 33614304,
    "name": "thefuck",
    "repo": "nvbn/thefuck",
    "description": "Magnificent app which corrects your previous console command.",
    "createdAt": "2015-04-08T15:08:04Z",
    "updatedAt": "2025-10-28T12:34:25Z",
    "pushedAt": "2024-07-19T14:56:13Z",
    "stars": 94497,
    "watchers": 825,
    "forks": 3792,
    "defaultBranch": "master"
  },
  {
    "id": 65600975,
    "name": "pytorch",
    "repo": "pytorch/pytorch",
    "description": "Tensors and Dynamic neural networks in Python with strong GPU acceleration",
    "createdAt": "2016-08-13T05:26:41Z",
    "updatedAt": "2025-10-28T12:25:28Z",
    "pushedAt": "2025-10-28T12:40:19Z",
    "stars": 94326,
    "watchers": 1770,
    "forks": 25678,
    "defaultBranch": "main"
  },
  {
    "id": 74791366,
    "name": "clean-code-javascript",
    "repo": "ryanmcdermott/clean-code-javascript",
    "description": "Clean Code concepts adapted for JavaScript",
    "createdAt": "2016-11-25T22:25:41Z",
    "updatedAt": "2025-10-28T08:55:17Z",
    "pushedAt": "2024-07-29T07:24:37Z",
    "stars": 93959,
    "watchers": 1744,
    "forks": 12495,
    "defaultBranch": "master"
  },
  {
    "id": 101296881,
    "name": "every-programmer-should-know",
    "repo": "mtdvio/every-programmer-should-know",
    "description": "A collection of (mostly) technical things every software developer should know about",
    "createdAt": "2017-08-24T13:18:26Z",
    "updatedAt": "2025-10-28T11:51:44Z",
    "pushedAt": "2025-10-22T15:21:18Z",
    "stars": 93832,
    "watchers": 2011,
    "forks": 8437,
    "defaultBranch": "master"
  },
  {
    "id": 16408992,
    "name": "neovim",
    "repo": "neovim/neovim",
    "description": "Vim-fork focused on extensibility and usability",
    "createdAt": "2014-01-31T13:39:22Z",
    "updatedAt": "2025-10-28T12:38:30Z",
    "pushedAt": "2025-10-28T08:45:46Z",
    "stars": 93768,
    "watchers": 972,
    "forks": 6376,
    "defaultBranch": "master"
  },
  {
    "id": 943398999,
    "name": "system-prompts-and-models-of-ai-tools",
    "repo": "x1xhlol/system-prompts-and-models-of-ai-tools",
    "description": "FULL Augment Code, Claude Code, Cluely, CodeBuddy, Comet, Cursor, Devin AI, Junie, Kiro, Leap.new, Lovable, Manus Agent Tools, NotionAI, Orchids.app, Perplexity, Poke, Qoder, Replit, Same.dev, Trae, Traycer AI, VSCode Agent, Warp.dev, Windsurf, Xcode, Z.ai Code, dia & v0. (And other Open Sourced) System Prompts, Internal Tools & AI Models",
    "createdAt": "2025-03-05T16:38:29Z",
    "updatedAt": "2025-10-28T12:37:42Z",
    "pushedAt": "2025-10-19T18:44:24Z",
    "stars": 93450,
    "watchers": 1183,
    "forks": 25250,
    "defaultBranch": "main"
  },
  {
    "id": 22790488,
    "name": "java-design-patterns",
    "repo": "iluwatar/java-design-patterns",
    "description": "Design patterns implemented in Java",
    "createdAt": "2014-08-09T16:45:18Z",
    "updatedAt": "2025-10-28T11:55:32Z",
    "pushedAt": "2025-10-21T21:30:34Z",
    "stars": 93230,
    "watchers": 3717,
    "forks": 27312,
    "defaultBranch": "master"
  },
  {
    "id": 90796663,
    "name": "puppeteer",
    "repo": "puppeteer/puppeteer",
    "description": "JavaScript API for Chrome and Firefox",
    "createdAt": "2017-05-09T22:16:13Z",
    "updatedAt": "2025-10-28T11:55:21Z",
    "pushedAt": "2025-10-28T11:35:29Z",
    "stars": 92732,
    "watchers": 1184,
    "forks": 9314,
    "defaultBranch": "main"
  },
  {
    "id": 311525798,
    "name": "Web-Dev-For-Beginners",
    "repo": "microsoft/Web-Dev-For-Beginners",
    "description": "24 Lessons, 12 Weeks, Get Started as a Web Developer",
    "createdAt": "2020-11-10T02:44:00Z",
    "updatedAt": "2025-10-28T12:11:24Z",
    "pushedAt": "2025-10-27T13:01:13Z",
    "stars": 92494,
    "watchers": 2690,
    "forks": 14334,
    "defaultBranch": "main"
  },
  {
    "id": 589831718,
    "name": "ComfyUI",
    "repo": "comfyanonymous/ComfyUI",
    "description": "The most powerful and modular diffusion model GUI, api and backend with a graph/nodes interface.",
    "createdAt": "2023-01-17T03:15:56Z",
    "updatedAt": "2025-10-28T12:38:44Z",
    "pushedAt": "2025-10-28T08:45:49Z",
    "stars": 92150,
    "watchers": 615,
    "forks": 10367,
    "defaultBranch": "master"
  },
  {
    "id": 63539055,
    "name": "awesome-mac",
    "repo": "jaywcjlove/awesome-mac",
    "description": "Ô£ø Now we have become very big, Different from the original idea. Collect premium software in various categories.",
    "createdAt": "2016-07-17T15:33:47Z",
    "updatedAt": "2025-10-28T12:29:52Z",
    "pushedAt": "2025-10-27T17:27:24Z",
    "stars": 91942,
    "watchers": 1517,
    "forks": 6956,
    "defaultBranch": "master"
  },
  {
    "id": 919443098,
    "name": "DeepSeek-R1",
    "repo": "deepseek-ai/DeepSeek-R1",
    "description": null,
    "createdAt": "2025-01-20T11:57:28Z",
    "updatedAt": "2025-10-28T12:33:45Z",
    "pushedAt": "2025-06-27T08:35:54Z",
    "stars": 91406,
    "watchers": 607,
    "forks": 11768,
    "defaultBranch": "main"
  },
  {
    "id": 160919119,
    "name": "fastapi",
    "repo": "fastapi/fastapi",
    "description": "FastAPI framework, high performance, easy to learn, fast to code, ready for production",
    "createdAt": "2018-12-08T08:21:47Z",
    "updatedAt": "2025-10-28T11:31:45Z",
    "pushedAt": "2025-10-28T07:50:29Z",
    "stars": 91252,
    "watchers": 721,
    "forks": 8135,
    "defaultBranch": "master"
  },
  {
    "id": 106017343,
    "name": "tailwindcss",
    "repo": "tailwindlabs/tailwindcss",
    "description": "A utility-first CSS framework for rapid UI development.",
    "createdAt": "2017-10-06T14:59:14Z",
    "updatedAt": "2025-10-28T12:25:13Z",
    "pushedAt": "2025-10-28T12:25:08Z",
    "stars": 90816,
    "watchers": 615,
    "forks": 4766,
    "defaultBranch": "main"
  }
]



================================================
FILE: benchmarks/results/retrieval-accuracy.md
================================================
### Retrieval Accuracy

Accuracy across **4 LLMs** on 154 data retrieval questions:

```
gpt-5-nano
‚Üí TOON           ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë    96.1% (148/154)
  CSV            ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë    91.6% (141/154)
  YAML           ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë    91.6% (141/154)
  JSON compact   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë    91.6% (141/154)
  XML            ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë    87.0% (134/154)
  JSON           ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë    86.4% (133/154)

claude-haiku-4-5-20251001
  JSON           ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë    50.0% (77/154)
  YAML           ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë    49.4% (76/154)
‚Üí TOON           ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë    48.7% (75/154)
  XML            ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë    48.1% (74/154)
  CSV            ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë    47.4% (73/154)
  JSON compact   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë    44.2% (68/154)

gemini-2.5-flash
  CSV            ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë    87.7% (135/154)
  XML            ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë    87.7% (135/154)
‚Üí TOON           ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë    86.4% (133/154)
  YAML           ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë    79.9% (123/154)
  JSON compact   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë    79.9% (123/154)
  JSON           ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë    76.6% (118/154)

grok-4-fast-non-reasoning
‚Üí TOON           ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë    49.4% (76/154)
  JSON           ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë    48.7% (75/154)
  XML            ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë    46.1% (71/154)
  YAML           ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë    46.1% (71/154)
  JSON compact   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë    45.5% (70/154)
  CSV            ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë    44.2% (68/154)
```

**Key tradeoff:** TOON achieves **70.1% accuracy** (vs JSON's 65.4%) while using **46.3% fewer tokens** on these datasets.

<details>
<summary><strong>Performance by dataset and model</strong></summary>

#### Performance by Dataset

##### Uniform employee records (TOON optimal format)

| Format | Accuracy | Tokens | Correct/Total |
| ------ | -------- | ------ | ------------- |
| `csv` | 65.5% | 2,337 | 131/200 |
| `toon` | 67.5% | 2,483 | 135/200 |
| `json-compact` | 65.5% | 3,943 | 131/200 |
| `yaml` | 68.5% | 4,969 | 137/200 |
| `xml` | 69.5% | 7,314 | 139/200 |
| `json-pretty` | 64.5% | 6,347 | 129/200 |

##### E-commerce orders with nested structures

| Format | Accuracy | Tokens | Correct/Total |
| ------ | -------- | ------ | ------------- |
| `toon` | 78.8% | 5,967 | 126/160 |
| `csv` | 76.3% | 6,735 | 122/160 |
| `json-compact` | 70.6% | 5,962 | 113/160 |
| `yaml` | 72.5% | 7,328 | 116/160 |
| `json-pretty` | 76.9% | 9,694 | 123/160 |
| `xml` | 73.1% | 10,992 | 117/160 |

##### Time-series analytics data

| Format | Accuracy | Tokens | Correct/Total |
| ------ | -------- | ------ | ------------- |
| `toon` | 68.4% | 1,515 | 93/136 |
| `csv` | 65.4% | 1,393 | 89/136 |
| `json-compact` | 64.7% | 2,341 | 88/136 |
| `yaml` | 66.2% | 2,938 | 90/136 |
| `json-pretty` | 64.7% | 3,665 | 88/136 |
| `xml` | 66.9% | 4,376 | 91/136 |

##### Top 100 GitHub repositories

| Format | Accuracy | Tokens | Correct/Total |
| ------ | -------- | ------ | ------------- |
| `toon` | 65.0% | 8,745 | 78/120 |
| `csv` | 62.5% | 8,513 | 75/120 |
| `json-compact` | 58.3% | 11,455 | 70/120 |
| `yaml` | 56.7% | 13,129 | 68/120 |
| `xml` | 55.8% | 17,095 | 67/120 |
| `json-pretty` | 52.5% | 15,145 | 63/120 |

#### Performance by Model

##### gpt-5-nano

| Format | Accuracy | Correct/Total |
| ------ | -------- | ------------- |
| `toon` | 96.1% | 148/154 |
| `csv` | 91.6% | 141/154 |
| `yaml` | 91.6% | 141/154 |
| `json-compact` | 91.6% | 141/154 |
| `xml` | 87.0% | 134/154 |
| `json-pretty` | 86.4% | 133/154 |

##### claude-haiku-4-5-20251001

| Format | Accuracy | Correct/Total |
| ------ | -------- | ------------- |
| `json-pretty` | 50.0% | 77/154 |
| `yaml` | 49.4% | 76/154 |
| `toon` | 48.7% | 75/154 |
| `xml` | 48.1% | 74/154 |
| `csv` | 47.4% | 73/154 |
| `json-compact` | 44.2% | 68/154 |

##### gemini-2.5-flash

| Format | Accuracy | Correct/Total |
| ------ | -------- | ------------- |
| `csv` | 87.7% | 135/154 |
| `xml` | 87.7% | 135/154 |
| `toon` | 86.4% | 133/154 |
| `yaml` | 79.9% | 123/154 |
| `json-compact` | 79.9% | 123/154 |
| `json-pretty` | 76.6% | 118/154 |

##### grok-4-fast-non-reasoning

| Format | Accuracy | Correct/Total |
| ------ | -------- | ------------- |
| `toon` | 49.4% | 76/154 |
| `json-pretty` | 48.7% | 75/154 |
| `xml` | 46.1% | 71/154 |
| `yaml` | 46.1% | 71/154 |
| `json-compact` | 45.5% | 70/154 |
| `csv` | 44.2% | 68/154 |

</details>

<details>
<summary><strong>How the benchmark works</strong></summary>

#### What's Being Measured

This benchmark tests **LLM comprehension and data retrieval accuracy** across different input formats. Each LLM receives formatted data and must answer questions about it (this does **not** test model's ability to generate TOON output).

#### Datasets Tested

Four datasets designed to test different structural patterns (all contain arrays of uniform objects, TOON's optimal format):

1. **Tabular** (100 employee records): Uniform objects with identical fields ‚Äì optimal for TOON's tabular format.
2. **Nested** (50 e-commerce orders): Complex structures with nested customer objects and item arrays.
3. **Analytics** (60 days of metrics): Time-series data with dates and numeric values.
4. **GitHub** (100 repositories): Real-world data from top GitHub repos by stars.

#### Question Types

154 questions are generated dynamically across three categories:

- **Field retrieval (40%)**: Direct value lookups or values that can be read straight off a record (including booleans and simple counts such as array lengths)
  - Example: "What is Alice's salary?" ‚Üí `75000`
  - Example: "How many items are in order ORD-0042?" ‚Üí `3`
  - Example: "What is the customer name for order ORD-0042?" ‚Üí `John Doe`

- **Aggregation (32%)**: Dataset-level totals and averages plus single-condition filters (counts, sums, min/max comparisons)
  - Example: "How many employees work in Engineering?" ‚Üí `17`
  - Example: "What is the total revenue across all orders?" ‚Üí `45123.50`
  - Example: "How many employees have salary > 80000?" ‚Üí `23`

- **Filtering (28%)**: Multi-condition queries requiring compound logic (AND constraints across fields)
  - Example: "How many employees in Sales have salary > 80000?" ‚Üí `5`
  - Example: "How many active employees have more than 10 years of experience?" ‚Üí `8`

#### Evaluation Process

1. **Format conversion**: Each dataset is converted to all 6 formats (TOON, CSV, XML, YAML, JSON, JSON compact).
2. **Query LLM**: Each model receives formatted data + question in a prompt and extracts the answer.
3. **Validate with LLM-as-judge**: `gpt-5-nano` validates if the answer is semantically correct (e.g., `50000` = `$50,000`, `Engineering` = `engineering`, `2025-01-01` = `January 1, 2025`).

#### Models & Configuration

- **Models tested**: `gpt-5-nano`, `claude-haiku-4-5-20251001`, `gemini-2.5-flash`, `grok-4-fast-non-reasoning`
- **Token counting**: Using `gpt-tokenizer` with `o200k_base` encoding (GPT-5 tokenizer)
- **Temperature**: Not set (models use their defaults)
- **Total evaluations**: 154 questions √ó 6 formats √ó 4 models = 3,696 LLM calls

</details>



================================================
FILE: benchmarks/results/token-efficiency.md
================================================
### Token Efficiency

```
‚≠ê GitHub Repositories       ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë    8,745 tokens
                             vs JSON (-42.3%)           15,145
                             vs JSON compact (-23.7%)   11,455
                             vs YAML (-33.4%)           13,129
                             vs XML (-48.8%)            17,095

üìà Daily Analytics           ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë    4,507 tokens
                             vs JSON (-58.9%)           10,977
                             vs JSON compact (-35.7%)    7,013
                             vs YAML (-48.8%)            8,810
                             vs XML (-65.7%)            13,128

üõí E-Commerce Order          ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë      166 tokens
                             vs JSON (-35.4%)              257
                             vs JSON compact (-2.9%)       171
                             vs YAML (-15.7%)              197
                             vs XML (-38.7%)               271

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Total                        ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë   13,418 tokens
                             vs JSON (-49.1%)           26,379
                             vs JSON compact (-28.0%)   18,639
                             vs YAML (-39.4%)           22,136
                             vs XML (-56.0%)            30,494
```

<details>
<summary><strong>View detailed examples</strong></summary>

#### ‚≠ê GitHub Repositories

**Configuration:** Top 100 GitHub repositories with stars, forks, and metadata

**Savings:** 6,400 tokens (42.3% reduction vs JSON)

**JSON** (15,145 tokens):

```json
{
  "repositories": [
    {
      "id": 28457823,
      "name": "freeCodeCamp",
      "repo": "freeCodeCamp/freeCodeCamp",
      "description": "freeCodeCamp.org's open-source codebase and curriculum. Learn math, programming,‚Ä¶",
      "createdAt": "2014-12-24T17:49:19Z",
      "updatedAt": "2025-10-28T11:58:08Z",
      "pushedAt": "2025-10-28T10:17:16Z",
      "stars": 430886,
      "watchers": 8583,
      "forks": 42146,
      "defaultBranch": "main"
    },
    {
      "id": 132750724,
      "name": "build-your-own-x",
      "repo": "codecrafters-io/build-your-own-x",
      "description": "Master programming by recreating your favorite technologies from scratch.",
      "createdAt": "2018-05-09T12:03:18Z",
      "updatedAt": "2025-10-28T12:37:11Z",
      "pushedAt": "2025-10-10T18:45:01Z",
      "stars": 430877,
      "watchers": 6332,
      "forks": 40453,
      "defaultBranch": "master"
    },
    {
      "id": 21737465,
      "name": "awesome",
      "repo": "sindresorhus/awesome",
      "description": "üòé Awesome lists about all kinds of interesting topics",
      "createdAt": "2014-07-11T13:42:37Z",
      "updatedAt": "2025-10-28T12:40:21Z",
      "pushedAt": "2025-10-27T17:57:31Z",
      "stars": 410052,
      "watchers": 8017,
      "forks": 32029,
      "defaultBranch": "main"
    }
  ]
}
```

**TOON** (8,745 tokens):

```
repositories[3]{id,name,repo,description,createdAt,updatedAt,pushedAt,stars,watchers,forks,defaultBranch}:
  28457823,freeCodeCamp,freeCodeCamp/freeCodeCamp,"freeCodeCamp.org's open-source codebase and curriculum. Learn math, programming,‚Ä¶","2014-12-24T17:49:19Z","2025-10-28T11:58:08Z","2025-10-28T10:17:16Z",430886,8583,42146,main
  132750724,build-your-own-x,codecrafters-io/build-your-own-x,Master programming by recreating your favorite technologies from scratch.,"2018-05-09T12:03:18Z","2025-10-28T12:37:11Z","2025-10-10T18:45:01Z",430877,6332,40453,master
  21737465,awesome,sindresorhus/awesome,üòé Awesome lists about all kinds of interesting topics,"2014-07-11T13:42:37Z","2025-10-28T12:40:21Z","2025-10-27T17:57:31Z",410052,8017,32029,main
```

---

#### üìà Daily Analytics

**Configuration:** 180 days of web metrics (views, clicks, conversions, revenue)

**Savings:** 6,470 tokens (58.9% reduction vs JSON)

**JSON** (10,977 tokens):

```json
{
  "metrics": [
    {
      "date": "2025-01-01",
      "views": 6890,
      "clicks": 401,
      "conversions": 23,
      "revenue": 6015.59,
      "bounceRate": 0.63
    },
    {
      "date": "2025-01-02",
      "views": 6940,
      "clicks": 323,
      "conversions": 37,
      "revenue": 9086.44,
      "bounceRate": 0.36
    },
    {
      "date": "2025-01-03",
      "views": 4390,
      "clicks": 346,
      "conversions": 26,
      "revenue": 6360.75,
      "bounceRate": 0.48
    },
    {
      "date": "2025-01-04",
      "views": 3429,
      "clicks": 231,
      "conversions": 13,
      "revenue": 2360.96,
      "bounceRate": 0.65
    },
    {
      "date": "2025-01-05",
      "views": 5804,
      "clicks": 186,
      "conversions": 22,
      "revenue": 2535.96,
      "bounceRate": 0.37
    }
  ]
}
```

**TOON** (4,507 tokens):

```
metrics[5]{date,views,clicks,conversions,revenue,bounceRate}:
  2025-01-01,6890,401,23,6015.59,0.63
  2025-01-02,6940,323,37,9086.44,0.36
  2025-01-03,4390,346,26,6360.75,0.48
  2025-01-04,3429,231,13,2360.96,0.65
  2025-01-05,5804,186,22,2535.96,0.37
```

</details>



================================================
FILE: benchmarks/scripts/accuracy-benchmark.ts
================================================
import type { Question } from '../src/types'
import * as path from 'node:path'
import process from 'node:process'
import * as prompts from '@clack/prompts'
import PQueue from 'p-queue'
import { DEFAULT_CONCURRENCY, DRY_RUN, DRY_RUN_LIMITS, MODEL_RPM_LIMITS, ROOT_DIR } from '../src/constants'
import { datasets } from '../src/datasets'
import { evaluateQuestion, models } from '../src/evaluate'
import { formatters } from '../src/formatters'
import { generateQuestions } from '../src/questions'
import { calculateFormatResults, calculateTokenCounts, saveResults } from '../src/report'
import { getAllModelResults, hasModelResults, saveModelResults } from '../src/storage'

prompts.intro('Retrieval Accuracy Benchmark')

// Prompt user to select which models to benchmark
const modelChoices = models.map(({ modelId }) => ({
  value: modelId,
  label: modelId,
}))

const selectedModels = await prompts.multiselect({
  message: 'Select models to benchmark (Space to select, Enter to confirm)',
  options: modelChoices,
  required: true,
})

if (prompts.isCancel(selectedModels)) {
  prompts.cancel('Benchmark cancelled')
  process.exit(0)
}

const activeModels = models.filter(m => selectedModels.includes(m.modelId))

prompts.log.info(`Selected ${activeModels.length} model(s): ${activeModels.map(m => m.modelId).join(', ')}`)

// Check which models already have results
const existingModelResults: Record<string, boolean> = {}
for (const model of activeModels) {
  const existingResult = await hasModelResults(model.modelId)
  if (existingResult)
    existingModelResults[model.modelId] = existingResult
}

if (Object.keys(existingModelResults).length > 0) {
  prompts.log.info(`Found existing results for ${Object.values(existingModelResults).length} model(s)`)
}

if (DRY_RUN) {
  prompts.log.info('Limiting questions and models for dry run')
}

let questions = generateQuestions()

// Apply dry run limits if enabled
if (DRY_RUN && DRY_RUN_LIMITS.maxQuestions) {
  questions = questions.slice(0, DRY_RUN_LIMITS.maxQuestions)
}

prompts.log.info(`Evaluating ${questions.length} questions`)
prompts.log.info(`Testing ${Object.keys(formatters).length} formats`)

// Evaluate each model separately and save results incrementally
for (const model of activeModels) {
  const modelId = model.modelId

  // Skip if results already exist
  if (existingModelResults[modelId]) {
    prompts.log.info(`Skipping ${modelId} (results already exist)`)
    continue
  }

  prompts.log.step(`Running benchmark for ${modelId}`)

  // Generate evaluation tasks for this model
  const tasks: { question: Question, formatName: string }[] = []
  for (const question of questions) {
    for (const [formatName] of Object.entries(formatters)) {
      tasks.push({ question, formatName })
    }
  }

  const total = tasks.length
  const rpmLimit = MODEL_RPM_LIMITS[modelId]
  const queue = new PQueue({
    concurrency: DEFAULT_CONCURRENCY,
    intervalCap: rpmLimit ?? Infinity,
    interval: rpmLimit ? 60_000 : 0,
  })

  const evalSpinner = prompts.spinner()
  evalSpinner.start(`Running ${total} evaluations (concurrency: ${DEFAULT_CONCURRENCY}, RPM limit: ${rpmLimit ?? 'unlimited'})`)

  let completed = 0

  // Queue all tasks
  const modelResultPromises = tasks.map(task =>
    queue.add(async () => {
      // Format data on-demand
      const dataset = datasets.find(d => d.name === task.question.dataset)!
      const formatter = formatters[task.formatName]!
      const formattedData = formatter(dataset.data)

      const result = await evaluateQuestion({
        question: task.question,
        formatName: task.formatName,
        formattedData,
        model,
      })

      // Progress update after task completes
      completed++
      if (completed % 10 === 0 || completed === total) {
        const percent = ((completed / total) * 100).toFixed(1)
        evalSpinner.message(`Progress: ${completed}/${total} (${percent}%)`)
      }

      return result
    }),
  )

  // Wait for all tasks to complete
  const modelResults = await Promise.all(modelResultPromises)

  evalSpinner.stop(`Evaluation complete for ${modelId}`)

  // Save results immediately for this model
  await saveModelResults(modelId, modelResults)
  prompts.log.success(`Saved results for ${modelId}`)
}

// Generate/regenerate markdown report from all available model results
const reportSpinner = prompts.spinner()
reportSpinner.start('Generating report from all model results')

// Load all available model results (including any that were skipped)
const allModelResults = await getAllModelResults()
const allResults = Object.values(allModelResults).flat()

if (allResults.length === 0) {
  prompts.log.warn('No results available to generate report')
  process.exit(0)
}

// Calculate token counts freshly (deterministic, no need to persist)
const tokenCounts = calculateTokenCounts(formatters)

// Calculate format statistics and save report
const formatResults = calculateFormatResults(allResults, tokenCounts)
const resultsDir = await saveResults(allResults, formatResults, questions, tokenCounts)

const reportPath = path.join(resultsDir, 'retrieval-accuracy.md')
prompts.log.info(`Report saved to: \`${path.relative(ROOT_DIR, reportPath)}\``)
reportSpinner.stop('Report generation complete!')



================================================
FILE: benchmarks/scripts/fetch-github-repos.ts
================================================
import * as fsp from 'node:fs/promises'
import * as path from 'node:path'
import process from 'node:process'
import * as prompts from '@clack/prompts'
import { ofetch } from 'ofetch'
import pMap from 'p-map'
import { BENCHMARKS_DIR } from '../src/constants'
import { ensureDir } from '../src/utils'

prompts.intro('GitHub Repositories Fetcher')

try {
  // Fetch top 100 repos from GitHub
  const repoList = await searchTop100Repos()
  const repos = await fetchRepoDetails(repoList)

  if (repos.length === 0) {
    prompts.log.error('No repositories fetched. Exiting.')
    process.exit(1)
  }

  // Sort by stars descending
  repos.sort((a, b) => b.stars - a.stars)

  await saveRepos(repos)

  prompts.log.success('Done!')
}
catch (error) {
  prompts.log.error(String(error))
  process.exit(1)
}

async function searchTop100Repos(): Promise<string[]> {
  const s = prompts.spinner()
  s.start('Fetching top 100 starred repositories')

  const response = await ofetch<{ items: { full_name: string }[] }>(
    'https://api.github.com/search/repositories',
    {
      query: {
        q: 'stars:>1',
        sort: 'stars',
        order: 'desc',
        per_page: 100,
      },
      headers: {
        'Accept': 'application/vnd.github+json',
        'X-GitHub-Api-Version': '2022-11-28',
      },
    },
  )

  s.stop('Fetched top 100 repositories')

  return response.items.map(item => item.full_name)
}

async function fetchRepoDetails(repoList: string[]): Promise<Record<string, any>[]> {
  const s = prompts.spinner()
  s.start(`Fetching ${repoList.length} GitHub repositories`)

  const repos = await pMap(
    repoList,
    async (repoPath, index) => {
      s.message(`[${index + 1}/${repoList.length}] Fetching ${repoPath}`)
      const { repo } = await ofetch(`https://ungh.cc/repos/${repoPath}`)
      return repo
    },
    { concurrency: 5 },
  )

  s.stop(`Successfully fetched ${repos.length}/${repoList.length} repositories`)

  return repos
}

async function saveRepos(repos: Record<string, any>[]): Promise<void> {
  const outputDir = path.join(BENCHMARKS_DIR, 'data')
  const outputFile = path.join(outputDir, 'github-repos.json')

  await ensureDir(outputDir)
  const jsonOutput = JSON.stringify(repos, undefined, 2)
  await fsp.writeFile(outputFile, `${jsonOutput}\n`, 'utf-8')

  const relativePath = path.relative(BENCHMARKS_DIR, outputFile)
  prompts.log.info(`Result saved to \`${relativePath}\``)
}



================================================
FILE: benchmarks/scripts/token-efficiency-benchmark.ts
================================================
import * as fsp from 'node:fs/promises'
import * as path from 'node:path'
import * as prompts from '@clack/prompts'
import { encode } from '../../packages/toon/src'
import githubRepos from '../data/github-repos.json' with { type: 'json' }
import { BENCHMARKS_DIR, FORMATTER_DISPLAY_NAMES, ROOT_DIR } from '../src/constants'
import { generateAnalyticsData, generateOrderData } from '../src/datasets'
import { formatters } from '../src/formatters'
import { createProgressBar, ensureDir, tokenize } from '../src/utils'

interface FormatMetrics {
  name: string
  tokens: number
  savings: number
  savingsPercent: string
}

interface BenchmarkResult {
  name: string
  emoji: string
  description: string
  data: Record<string, any>
  formats: FormatMetrics[]
  showDetailed: boolean
}

const BENCHMARK_EXAMPLES = [
  {
    name: 'GitHub Repositories',
    emoji: '‚≠ê',
    description: 'Top 100 GitHub repositories with stars, forks, and metadata',
    getData: () => ({ repositories: githubRepos }),
    showDetailed: true,
  },
  {
    name: 'Daily Analytics',
    emoji: 'üìà',
    description: '180 days of web metrics (views, clicks, conversions, revenue)',
    getData: () => generateAnalyticsData(180),
    showDetailed: true,
  },
  {
    name: 'E-Commerce Order',
    emoji: 'üõí',
    description: 'Single nested order with customer and items',
    getData: generateOrderData,
    showDetailed: false,
  },
] as const

prompts.intro('Token Efficiency Benchmark')

const results: BenchmarkResult[] = []
const totalTokensByFormat: Record<string, number> = {}

for (const example of BENCHMARK_EXAMPLES) {
  const data = example.getData()

  // Calculate tokens for each format
  const formatMetrics: FormatMetrics[] = []
  const tokensByFormat: Record<string, number> = {}

  for (const [formatName, formatter] of Object.entries(formatters)) {
    const formattedString = formatter(data)
    const tokens = tokenize(formattedString)
    tokensByFormat[formatName] = tokens
    totalTokensByFormat[formatName] = (totalTokensByFormat[formatName] || 0) + tokens
  }

  // Calculate savings vs TOON
  const toonTokens = tokensByFormat.toon!
  for (const [formatName, tokens] of Object.entries(tokensByFormat)) {
    const savings = tokens - toonTokens
    formatMetrics.push({
      name: formatName,
      tokens,
      savings,
      savingsPercent: formatName === 'toon' ? '0.0' : ((savings / tokens) * 100).toFixed(1),
    })
  }

  results.push({
    name: example.name,
    emoji: example.emoji,
    description: example.description,
    data,
    formats: formatMetrics,
    showDetailed: example.showDetailed,
  })
}

// Calculate total savings percentages
const totalToonTokens = totalTokensByFormat.toon!
const totalSavingsPercent: Record<string, string> = {}
for (const [formatName, totalTokens] of Object.entries(totalTokensByFormat)) {
  if (formatName === 'toon') {
    totalSavingsPercent[formatName] = '0.0'
  }
  else {
    const savings = totalTokens - totalToonTokens
    totalSavingsPercent[formatName] = ((savings / totalTokens) * 100).toFixed(1)
  }
}

// Generate ASCII bar chart visualization (stacked compact format)
const formatOrder = ['json-pretty', 'json-compact', 'yaml', 'xml']
const datasetRows = results
  .map((result) => {
    const toon = result.formats.find(f => f.name === 'toon')!
    const percentage = Number.parseFloat(result.formats.find(f => f.name === 'json-pretty')!.savingsPercent)
    const bar = createProgressBar(100 - percentage, 100) // Invert to show TOON tokens
    const toonStr = toon.tokens.toLocaleString('en-US')

    const line1 = `${result.emoji} ${result.name.padEnd(25)} ${bar}   ${toonStr.padStart(6)} tokens`

    const comparisonLines = formatOrder.map((formatName) => {
      const format = result.formats.find(f => f.name === formatName)!
      const label = FORMATTER_DISPLAY_NAMES[formatName] || formatName.toUpperCase()
      const labelWithSavings = `vs ${label} (-${format.savingsPercent}%)`.padEnd(27)
      const tokenStr = format.tokens.toLocaleString('en-US').padStart(6)
      return `                             ${labelWithSavings}${tokenStr}`
    })

    return [line1, ...comparisonLines].join('\n')
  })
  .join('\n\n')

// Add separator and totals row
const separator = '‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ'

// Calculate bar for totals (TOON vs average of comparison formats)
const comparisonTokens = formatOrder.map(name => totalTokensByFormat[name]!)
const averageComparisonTokens = comparisonTokens.reduce((a, b) => a + b, 0) / comparisonTokens.length
const totalPercentage = (totalToonTokens / averageComparisonTokens) * 100
const totalBar = createProgressBar(totalPercentage, 100)

const totalLine1 = `Total                        ${totalBar}   ${totalToonTokens.toLocaleString('en-US').padStart(6)} tokens`

const totalComparisonLines = formatOrder.map((formatName) => {
  const label = FORMATTER_DISPLAY_NAMES[formatName] || formatName.toUpperCase()
  const tokens = totalTokensByFormat[formatName]!
  const percent = totalSavingsPercent[formatName]!
  const labelWithSavings = `vs ${label} (-${percent}%)`.padEnd(27)
  const tokenStr = tokens.toLocaleString('en-US').padStart(6)
  return `                             ${labelWithSavings}${tokenStr}`
})

const barChartSection = `${datasetRows}\n\n${separator}\n${totalLine1}\n${totalComparisonLines.join('\n')}`

// Generate detailed examples (only for selected examples)
// Note: Large datasets are truncated for display readability in the report.
// Token counts are calculated from the full datasets, not the truncated versions.
const detailedExamples = results
  .filter(result => result.showDetailed)
  .map((result, i, filtered) => {
    // Truncate large datasets for display
    let displayData = result.data
    if (result.name === 'GitHub Repositories') {
      displayData = {
        repositories: result.data.repositories.slice(0, 3).map((repo: Record<string, any>) => ({
          ...repo,
          description: repo.description?.slice(0, 80) + (repo.description?.length > 80 ? '‚Ä¶' : ''),
        })),
      }
    }
    else if (result.name === 'Daily Analytics') {
      displayData = { metrics: result.data.metrics.slice(0, 5) }
    }

    const separator = i < filtered.length - 1 ? '\n\n---' : ''

    const json = result.formats.find(f => f.name === 'json-pretty')!
    const toon = result.formats.find(f => f.name === 'toon')!

    return `#### ${result.emoji} ${result.name}

**Configuration:** ${result.description}

**Savings:** ${json.savings.toLocaleString('en-US')} tokens (${json.savingsPercent}% reduction vs JSON)

**JSON** (${json.tokens.toLocaleString('en-US')} tokens):

\`\`\`json
${JSON.stringify(displayData, undefined, 2)}
\`\`\`

**TOON** (${toon.tokens.toLocaleString('en-US')} tokens):

\`\`\`
${encode(displayData)}
\`\`\`${separator}`
  })
  .join('\n\n')

const markdown = `### Token Efficiency

\`\`\`
${barChartSection}
\`\`\`

<details>
<summary><strong>View detailed examples</strong></summary>

${detailedExamples}

</details>
`.trimStart()

prompts.log.message(`${barChartSection}\n`)

const resultsDir = path.join(BENCHMARKS_DIR, 'results')
await ensureDir(resultsDir)

const outputFilePath = path.join(resultsDir, 'token-efficiency.md')
await fsp.writeFile(outputFilePath, markdown, 'utf-8')

prompts.log.success(`Result saved to \`${path.relative(ROOT_DIR, outputFilePath)}\``)



================================================
FILE: benchmarks/src/constants.ts
================================================
import process from 'node:process'
import * as url from 'node:url'

export const ROOT_DIR: string = url.fileURLToPath(new URL('../../', import.meta.url))
export const BENCHMARKS_DIR: string = url.fileURLToPath(new URL('../', import.meta.url))

/**
 * Model-specific RPM (requests per minute) limits to handle API quotas
 *
 * @remarks
 * Set `undefined` for models without specific limits
 */
/// keep-sorted
export const MODEL_RPM_LIMITS: Record<string, number | undefined> = {
  'claude-haiku-4-5-20251001': 50,
  'gemini-2.5-flash': 25,
  'gpt-5-nano': 50,
  'grok-4-fast-non-reasoning': 50,
}

/**
 * Default concurrency for parallel evaluations to prevent bursting
 */
export const DEFAULT_CONCURRENCY = 10

/**
 * Display names for data format types
 */
export const FORMATTER_DISPLAY_NAMES: Record<string, string> = {
  'json-pretty': 'JSON',
  'json-compact': 'JSON compact',
  'toon': 'TOON',
  'csv': 'CSV',
  'xml': 'XML',
  'yaml': 'YAML',
} as const

/**
 * Enable dry run mode for quick testing with limited AI requests
 *
 * @remarks
 * Set via environment variable: `DRY_RUN=true`
 */
export const DRY_RUN: boolean = process.env.DRY_RUN === 'true'

/**
 * Limits applied during dry run mode
 */
export const DRY_RUN_LIMITS = {
  /** Maximum number of questions to evaluate */
  maxQuestions: 10,
}

/**
 * Threshold values for filtering and aggregation questions
 */
export const QUESTION_THRESHOLDS = {
  tabular: {
    salaryRanges: [60000, 80000, 100000, 120000],
    experienceYears: [5, 10, 15, 20],
    departmentSalaryThreshold: 80000,
    departmentExperienceThreshold: 10,
  },
  nested: {
    highValueOrders: [200, 400, 600],
    statusValueThreshold: 300,
    itemCountThreshold: 3,
    totalThresholdsForItems: [300, 500],
  },
  analytics: {
    views: [5000, 7000],
    conversions: [10, 30],
    viewsForFiltering: [6000, 7000],
    conversionsForFiltering: 15,
    revenueThresholds: [500, 1000, 1500, 2000, 2500],
    viewsThresholdForRevenue: 6000,
    clicksForFiltering: [250, 400],
    conversionsForClickFiltering: 15,
    revenueForBounceRate: [1000, 1500],
    bounceRateThreshold: 0.5,
  },
  github: {
    stars: [100000, 150000, 200000],
    forks: [20000, 35000, 50000],
    watchers: [5000, 8000],
    starForkCombinations: [
      { stars: 75000, forks: 15000 },
      { stars: 100000, forks: 20000 },
      { stars: 150000, forks: 30000 },
      { stars: 200000, forks: 45000 },
    ],
    starWatcherCombinations: [
      { stars: 100000, watchers: 7000 },
      { stars: 150000, watchers: 9000 },
    ],
  },
} as const

/**
 * Question generation configuration
 */
export const QUESTION_LIMITS = {
  tabular: {
    fieldRetrieval: 20,
    aggregationDepartments: 6,
    filteringMultiConditionDepartments: 6,
    filteringExperience: 4,
    filteringDepartmentExp: 3,
    filteringDepartmentActive: 3,
  },
  nested: {
    fieldRetrievalOrders: 8,
    fieldRetrievalCustomers: 10,
    aggregationStatuses: 5,
    filteringStatusAndValue: 5,
    filteringStatusAndItems: 3,
  },
  analytics: {
    fieldRetrievalDates: 13,
  },
  github: {
    fieldRetrievalRepos: 11,
    aggregationBranches: 2,
    filteringStarsAndForks: 8,
  },
} as const



================================================
FILE: benchmarks/src/datasets.ts
================================================
import type { Dataset } from './types'
import { faker } from '@faker-js/faker'
import githubRepos from '../data/github-repos.json' with { type: 'json' }

// Seed for reproducibility
faker.seed(12345)

/**
 * Employee record structure for tabular dataset
 */
export interface Employee {
  id: number
  name: string
  email: string
  department: string
  salary: number
  yearsExperience: number
  active: boolean
}

/**
 * E-commerce order structure for nested dataset
 */
export interface Order {
  orderId: string
  customer: {
    id: number
    name: string
    email: string
    phone: string
  }
  items: {
    sku: string
    name: string
    quantity: number
    price: number
  }[]
  subtotal: number
  tax: number
  total: number
  status: string
  orderDate?: string
  createdAt?: string
}

/**
 * Analytics metric structure for time-series dataset
 */
export interface AnalyticsMetric {
  date: string
  views: number
  clicks: number
  conversions: number
  revenue: number
  bounceRate: number
}

/**
 * GitHub repository structure for real-world dataset
 */
export interface Repository {
  id: number
  name: string
  owner: string
  repo: string
  description: string
  stars: number
  watchers: number
  forks: number
  defaultBranch: string
  createdAt: string
  updatedAt: string
  pushedAt: string
}

/**
 * Generate analytics time-series data
 */
export function generateAnalyticsData(days: number, startDate = '2025-01-01'): {
  metrics: AnalyticsMetric[]
} {
  const date = new Date(startDate)

  return {
    metrics: Array.from({ length: days }, (_, i) => {
      const currentDate = new Date(date)
      currentDate.setDate(currentDate.getDate() + i)

      // Simulate realistic web traffic with some variation
      const baseViews = 5000
      const weekendMultiplier = currentDate.getDay() === 0 || currentDate.getDay() === 6 ? 0.7 : 1.0
      const views = Math.round(baseViews * weekendMultiplier + faker.number.int({ min: -1000, max: 3000 }))
      const clicks = Math.round(views * faker.number.float({ min: 0.02, max: 0.08 }))
      const conversions = Math.round(clicks * faker.number.float({ min: 0.05, max: 0.15 }))
      const avgOrderValue = faker.number.float({ min: 49.99, max: 299.99 })
      const revenue = Number((conversions * avgOrderValue).toFixed(2))

      return {
        date: currentDate.toISOString().split('T')[0]!,
        views,
        clicks,
        conversions,
        revenue,
        bounceRate: faker.number.float({ min: 0.3, max: 0.7, fractionDigits: 2 }),
      }
    }),
  }
}

/**
 * Tabular dataset: 100 uniform employee records
 *
 * @remarks
 * Tests TOON's tabular array format
 */
const departments: readonly string[] = ['Engineering', 'Sales', 'Marketing', 'HR', 'Operations', 'Finance'] as const
const tabularDataset: Dataset = {
  name: 'tabular',
  description: 'Uniform employee records (TOON optimal format)',
  data: {
    employees: Array.from({ length: 100 }, (_, i): Employee => {
      const yearsExp = faker.number.int({ min: 1, max: 25 })
      return {
        id: i + 1,
        name: faker.person.fullName(),
        email: faker.internet.email().toLowerCase(),
        department: departments[i % departments.length]!,
        salary: faker.number.int({ min: 45000, max: 150000 }),
        yearsExperience: yearsExp,
        active: faker.datatype.boolean(0.8), // 80% active
      }
    }),
  },
}

/**
 * Nested dataset: 50 e-commerce orders with nested structures
 *
 * @remarks
 * Tests TOON's handling of complex nested objects
 */
const productNames: readonly string[] = ['Wireless Mouse', 'USB Cable', 'Laptop Stand', 'Keyboard', 'Webcam', 'Headphones', 'Monitor', 'Desk Lamp'] as const
const statuses: readonly string[] = ['pending', 'processing', 'shipped', 'delivered', 'cancelled'] as const

const nestedDataset: Dataset = {
  name: 'nested',
  description: 'E-commerce orders with nested structures',
  data: {
    orders: Array.from({ length: 50 }, (_, i) => {
      const customerId = (i % 20) + 1
      const itemCount = faker.number.int({ min: 1, max: 4 })

      const items = Array.from({ length: itemCount }, (_, j) => {
        const price = faker.number.float({ min: 9.99, max: 199.99, fractionDigits: 2 })
        const quantity = faker.number.int({ min: 1, max: 5 })
        return {
          sku: `SKU-${faker.string.alphanumeric({ length: 6 }).toUpperCase()}`,
          name: productNames[j % productNames.length]!,
          quantity,
          price,
        }
      })

      const total = Number(items.reduce((sum, item) => sum + (item.price * item.quantity), 0).toFixed(2))

      return {
        orderId: `ORD-${String(i + 1).padStart(4, '0')}`,
        customer: {
          id: customerId,
          name: faker.person.fullName(),
          email: faker.internet.email().toLowerCase(),
        },
        items,
        total,
        status: statuses[i % statuses.length]!,
        orderDate: faker.date.recent({ days: 90 }).toISOString().split('T')[0],
      }
    }),
  },
}

/**
 * Analytics dataset: 60 days of time-series metrics
 *
 * @remarks
 * Tests TOON's handling of numeric data and date fields
 */
const analyticsDataset: Dataset = {
  name: 'analytics',
  description: 'Time-series analytics data',
  data: generateAnalyticsData(60),
}

/**
 * Real-world dataset: Top 100 starred GitHub repositories
 *
 * @remarks
 * Tests TOON's tabular format
 */
const githubDataset: Dataset = {
  name: 'github',
  description: 'Top 100 GitHub repositories',
  data: {
    repositories: githubRepos,
  },
}

/**
 * Generate a single e-commerce order with nested structure
 *
 * @remarks
 * Used for token efficiency benchmarks
 */
export function generateOrderData(): Order {
  return {
    orderId: faker.string.alphanumeric({ length: 12, casing: 'upper' }),
    customer: {
      id: faker.number.int({ min: 1000, max: 9999 }),
      name: faker.person.fullName(),
      email: faker.internet.email(),
      phone: faker.phone.number(),
    },
    items: Array.from({ length: faker.number.int({ min: 2, max: 5 }) }, () => ({
      sku: faker.string.alphanumeric({ length: 8, casing: 'upper' }),
      name: faker.commerce.productName(),
      quantity: faker.number.int({ min: 1, max: 5 }),
      price: Number(faker.commerce.price({ min: 10, max: 200 })),
    })),
    subtotal: Number(faker.commerce.price({ min: 100, max: 500 })),
    tax: Number(faker.commerce.price({ min: 10, max: 50 })),
    total: Number(faker.commerce.price({ min: 110, max: 550 })),
    status: faker.helpers.arrayElement(['pending', 'processing', 'shipped', 'delivered']),
    createdAt: faker.date.recent({ days: 7 }).toISOString(),
  }
}

/**
 * All datasets used in the benchmark
 */
export const datasets: Dataset[] = [
  tabularDataset,
  nestedDataset,
  analyticsDataset,
  githubDataset,
]



================================================
FILE: benchmarks/src/evaluate.ts
================================================
import type { LanguageModelV2 } from '@ai-sdk/provider'
import type { EvaluationResult, Question } from './types'
import { anthropic } from '@ai-sdk/anthropic'
import { google } from '@ai-sdk/google'
import { openai } from '@ai-sdk/openai'
import { xai } from '@ai-sdk/xai'
import * as prompts from '@clack/prompts'
import { generateText } from 'ai'

/**
 * Models used for evaluation
 */
export const models: LanguageModelV2[] = [
  openai('gpt-5-nano'),
  anthropic('claude-haiku-4-5-20251001'),
  google('gemini-2.5-flash'),
  xai('grok-4-fast-non-reasoning'),
]

/**
 * Evaluate a single question with a specific format and model
 */
export async function evaluateQuestion(
  {
    question,
    formatName,
    formattedData,
    model,
  }:
  {
    question: Question
    formatName: string
    formattedData: string
    model: LanguageModelV2
  },
): Promise<EvaluationResult> {
  const prompt = `
Given the following data in ${formatName} format:

\`\`\`
${formattedData}
\`\`\`

Question: ${question.prompt}

Provide only the direct answer, without any additional explanation or formatting.
`.trim()

  const startTime = performance.now()
  const { text, usage } = await generateText({ model, prompt })

  const actual = text.trim()
  const latencyMs = performance.now() - startTime

  const isCorrect = await validateAnswer({
    actual,
    expected: question.groundTruth,
    question: question.prompt,
  })

  return {
    questionId: question.id,
    format: formatName,
    model: model.modelId,
    expected: question.groundTruth,
    actual,
    isCorrect,
    inputTokens: usage.inputTokens,
    outputTokens: usage.outputTokens,
    latencyMs,
  }
}

/**
 * Validate an answer using LLM-as-judge approach
 */
async function validateAnswer(
  {
    actual,
    expected,
    question,
  }:
  {
    actual: string
    expected: string
    question: string
  },
): Promise<boolean> {
  const prompt = `
You are validating answers to questions about structured data.

Question: ${question}
Expected answer: ${expected}
Actual answer: ${actual}

Is the actual answer correct? Consider:
- Exact matches are correct
- Semantically equivalent answers are correct (e.g., "50000" vs "$50,000" vs "50000 dollars")
- Minor formatting differences are acceptable
- Case-insensitive comparison for text

Respond with only "YES" or "NO".
`.trim()

  try {
    const { text } = await generateText({
      model: models.find(m => m.modelId === 'gpt-5-nano')!,
      prompt,
    })

    return text.trim().toUpperCase() === 'YES'
  }
  catch (error) {
    prompts.log.error(`Validation error: ${error}`)
    // Fallback to simple string comparison
    return actual.toLowerCase().trim() === expected.toLowerCase().trim()
  }
}



================================================
FILE: benchmarks/src/formatters.ts
================================================
import { stringify as stringifyCSV } from 'csv-stringify/sync'
import { XMLBuilder } from 'fast-xml-parser'
import { stringify as stringifyYAML } from 'yaml'
import { encode as encodeToon } from '../../packages/toon/src'

/**
 * Format converters registry
 *
 * @remarks
 * All formatters attempt to preserve semantic equivalence with the source data,
 * meaning the converted data should represent the same information. However,
 * CSV has inherent limitations with nested structures (see `toCSV` docs).
 */
export const formatters: Record<string, (data: unknown) => string> = {
  'json-pretty': data => JSON.stringify(data, undefined, 2),
  'json-compact': data => JSON.stringify(data),
  'toon': data => encodeToon(data),
  'csv': data => toCSV(data),
  'xml': data => toXML(data),
  'yaml': data => stringifyYAML(data),
}

/**
 * Convert data to CSV format
 *
 * @remarks
 * Limitations: CSV is designed for flat tabular data only.
 *
 * This formatter:
 *   - Only handles top-level objects with arrays of flat objects
 *   - Cannot properly represent deeply nested structures (nested arrays/objects within rows)
 *   - Loses nested structure information during conversion
 *   - May produce misleading results for datasets with complex nesting (e.g., e-commerce orders with nested items)
 *
 * For datasets with nested structures, CSV comparisons may not be fair or representative
 * of how CSV would typically be used in practice.
 */
function toCSV(data: unknown): string {
  const sections: string[] = []

  // Handle top-level object with arrays
  if (typeof data === 'object' && data !== null && !Array.isArray(data)) {
    for (const [key, value] of Object.entries(data)) {
      if (Array.isArray(value) && value.length > 0) {
        sections.push(`# ${key}`)
        sections.push(stringifyCSV(value, { header: true }))
      }
    }
    return sections.join('\n').trim()
  }

  // Root-level array
  if (Array.isArray(data) && data.length > 0) {
    return stringifyCSV(data, { header: true }).trim()
  }

  return ''
}

/**
 * Convert data to XML format
 *
 * @remarks
 * Uses `fast-xml-parser` to generate well-formatted XML with:
 * - 2-space indentation for readability
 * - Empty nodes suppressed
 * - Proper escaping of special characters
 */
function toXML(data: unknown): string {
  const builder = new XMLBuilder({
    format: true,
    indentBy: '  ',
    suppressEmptyNode: true,
  })

  return builder.build(data)
}



================================================
FILE: benchmarks/src/questions.ts
================================================
/**
 * Question generation for TOON benchmarks
 *
 * Generates ~150-160 questions across different question types and datasets:
 * - Field Retrieval: Direct field access with no computation
 *   Examples: "What is X's salary?", "What is the status of order Y?"
 * - Aggregation: Counts, sums, averages, min/max operations (including single-condition filters)
 *   Examples: "How many X?", "What is the total/average?", "How many X > threshold?"
 * - Filtering: Multi-condition queries requiring complex logical operations
 *   Examples: "How many X WHERE condition1 AND condition2?"
 */

import type { AnalyticsMetric, Employee, Order, Repository } from './datasets'
import type { Question } from './types'
import { QUESTION_LIMITS, QUESTION_THRESHOLDS } from './constants'
import { datasets } from './datasets'

/**
 * Generate all questions from datasets
 */
export function generateQuestions(): Question[] {
  const questions: Question[] = []
  let idCounter = 1

  // Get datasets with proper typing
  const tabular = (datasets.find(d => d.name === 'tabular')?.data.employees as Employee[]) ?? []
  const nested = (datasets.find(d => d.name === 'nested')?.data.orders as Order[]) ?? []
  const analytics = (datasets.find(d => d.name === 'analytics')?.data.metrics as AnalyticsMetric[]) ?? []
  const github = (datasets.find(d => d.name === 'github')?.data.repositories as Repository[]) ?? []

  if (tabular.length > 0) {
    // Field retrieval: specific employees
    for (let i = 0; i < Math.min(QUESTION_LIMITS.tabular.fieldRetrieval, tabular.length); i++) {
      const emp = tabular[i * 2] || tabular[i]
      if (!emp)
        continue

      // Rotate through all field types
      if (i % 5 === 0) {
        questions.push({
          id: `q${idCounter++}`,
          prompt: `What is the salary of ${emp.name}?`,
          groundTruth: String(emp.salary),
          type: 'field-retrieval',
          dataset: 'tabular',
        })
      }
      else if (i % 5 === 1) {
        questions.push({
          id: `q${idCounter++}`,
          prompt: `What department does ${emp.name} work in?`,
          groundTruth: emp.department,
          type: 'field-retrieval',
          dataset: 'tabular',
        })
      }
      else if (i % 5 === 2) {
        questions.push({
          id: `q${idCounter++}`,
          prompt: `What is the email address of ${emp.name}?`,
          groundTruth: emp.email,
          type: 'field-retrieval',
          dataset: 'tabular',
        })
      }
      else if (i % 5 === 3) {
        questions.push({
          id: `q${idCounter++}`,
          prompt: `How many years of experience does ${emp.name} have?`,
          groundTruth: String(emp.yearsExperience),
          type: 'field-retrieval',
          dataset: 'tabular',
        })
      }
      else {
        questions.push({
          id: `q${idCounter++}`,
          prompt: `Is ${emp.name} an active employee?`,
          groundTruth: emp.active ? 'yes' : 'no',
          type: 'field-retrieval',
          dataset: 'tabular',
        })
      }
    }

    // Aggregation: count by department
    const departments = [...new Set(tabular.map(e => e.department))]
    for (const dept of departments.slice(0, QUESTION_LIMITS.tabular.aggregationDepartments)) {
      const count = tabular.filter(e => e.department === dept).length
      questions.push({
        id: `q${idCounter++}`,
        prompt: `How many employees work in ${dept}?`,
        groundTruth: String(count),
        type: 'aggregation',
        dataset: 'tabular',
      })
    }

    // Aggregation: salary ranges (single-condition filters)
    for (const threshold of QUESTION_THRESHOLDS.tabular.salaryRanges) {
      const count = tabular.filter(e => e.salary > threshold).length
      questions.push({
        id: `q${idCounter++}`,
        prompt: `How many employees have a salary greater than ${threshold}?`,
        groundTruth: String(count),
        type: 'aggregation',
        dataset: 'tabular',
      })
    }

    // Aggregation: totals and averages
    const totalEmployees = tabular.length
    const avgSalary = Math.round(tabular.reduce((sum, e) => sum + e.salary, 0) / totalEmployees)
    const activeCount = tabular.filter(e => e.active).length
    const inactiveCount = tabular.filter(e => !e.active).length

    questions.push(
      {
        id: `q${idCounter++}`,
        prompt: 'How many employees are in the dataset?',
        groundTruth: String(totalEmployees),
        type: 'aggregation',
        dataset: 'tabular',
      },
      {
        id: `q${idCounter++}`,
        prompt: 'What is the average salary across all employees?',
        groundTruth: String(avgSalary),
        type: 'aggregation',
        dataset: 'tabular',
      },
      {
        id: `q${idCounter++}`,
        prompt: 'How many employees are active?',
        groundTruth: String(activeCount),
        type: 'aggregation',
        dataset: 'tabular',
      },
      {
        id: `q${idCounter++}`,
        prompt: 'How many employees are inactive?',
        groundTruth: String(inactiveCount),
        type: 'aggregation',
        dataset: 'tabular',
      },
    )

    // Filtering: count by department with salary filter (multi-condition)
    for (const dept of departments.slice(0, QUESTION_LIMITS.tabular.filteringMultiConditionDepartments)) {
      const count = tabular.filter(e => e.department === dept && e.salary > QUESTION_THRESHOLDS.tabular.departmentSalaryThreshold).length
      questions.push({
        id: `q${idCounter++}`,
        prompt: `How many employees in ${dept} have a salary greater than ${QUESTION_THRESHOLDS.tabular.departmentSalaryThreshold}?`,
        groundTruth: String(count),
        type: 'filtering',
        dataset: 'tabular',
      })
    }

    // Filtering: active employees by experience (multi-condition)
    for (const exp of QUESTION_THRESHOLDS.tabular.experienceYears.slice(0, QUESTION_LIMITS.tabular.filteringExperience)) {
      const count = tabular.filter(e => e.yearsExperience > exp && e.active).length
      questions.push({
        id: `q${idCounter++}`,
        prompt: `How many active employees have more than ${exp} years of experience?`,
        groundTruth: String(count),
        type: 'filtering',
        dataset: 'tabular',
      })
    }

    // Filtering: department by experience (multi-condition)
    for (const dept of departments.slice(0, QUESTION_LIMITS.tabular.filteringDepartmentExp)) {
      const count = tabular.filter(e => e.department === dept && e.yearsExperience > QUESTION_THRESHOLDS.tabular.departmentExperienceThreshold).length
      questions.push({
        id: `q${idCounter++}`,
        prompt: `How many employees in ${dept} have more than ${QUESTION_THRESHOLDS.tabular.departmentExperienceThreshold} years of experience?`,
        groundTruth: String(count),
        type: 'filtering',
        dataset: 'tabular',
      })
    }

    // Filtering: department by active status (multi-condition)
    for (const dept of departments.slice(0, QUESTION_LIMITS.tabular.filteringDepartmentActive)) {
      const count = tabular.filter(e => e.department === dept && e.active).length
      questions.push({
        id: `q${idCounter++}`,
        prompt: `How many active employees work in ${dept}?`,
        groundTruth: String(count),
        type: 'filtering',
        dataset: 'tabular',
      })
    }
  }

  if (nested.length > 0) {
    // Field retrieval: order totals and statuses
    for (let i = 0; i < Math.min(QUESTION_LIMITS.nested.fieldRetrievalOrders, nested.length); i++) {
      const order = nested[i * 2] || nested[i]
      if (!order)
        continue

      if (i % 2 === 0) {
        questions.push({
          id: `q${idCounter++}`,
          prompt: `What is the total for order ${order.orderId}?`,
          groundTruth: String(order.total),
          type: 'field-retrieval',
          dataset: 'nested',
        })
      }
      else {
        questions.push({
          id: `q${idCounter++}`,
          prompt: `What is the status of order ${order.orderId}?`,
          groundTruth: order.status,
          type: 'field-retrieval',
          dataset: 'nested',
        })
      }
    }

    // Field retrieval: customer info and order dates (expanded)
    for (let i = 0; i < Math.min(QUESTION_LIMITS.nested.fieldRetrievalCustomers, nested.length); i++) {
      const order = nested[i * 2 + 1] || nested[i]
      if (!order)
        continue

      if (i % 4 === 0) {
        questions.push({
          id: `q${idCounter++}`,
          prompt: `What is the customer name for order ${order.orderId}?`,
          groundTruth: order.customer.name,
          type: 'field-retrieval',
          dataset: 'nested',
        })
      }
      else if (i % 4 === 1) {
        questions.push({
          id: `q${idCounter++}`,
          prompt: `What is the customer email for order ${order.orderId}?`,
          groundTruth: order.customer.email,
          type: 'field-retrieval',
          dataset: 'nested',
        })
      }
      else if (i % 4 === 2) {
        questions.push({
          id: `q${idCounter++}`,
          prompt: `What is the order date for order ${order.orderId}?`,
          groundTruth: order.orderDate || '',
          type: 'field-retrieval',
          dataset: 'nested',
        })
      }
      else {
        questions.push({
          id: `q${idCounter++}`,
          prompt: `How many items are in order ${order.orderId}?`,
          groundTruth: String(order.items.length),
          type: 'field-retrieval',
          dataset: 'nested',
        })
      }
    }

    // Aggregation: totals and averages
    const totalRevenue = nested.reduce((sum, o) => sum + o.total, 0)
    const avgOrderValue = totalRevenue / nested.length
    const totalOrders = nested.length
    const maxOrderValue = Math.max(...nested.map(o => o.total))

    // Count by status
    const statuses = [...new Set(nested.map(o => o.status))]
    for (const status of statuses.slice(0, QUESTION_LIMITS.nested.aggregationStatuses)) {
      const count = nested.filter(o => o.status === status).length
      questions.push({
        id: `q${idCounter++}`,
        prompt: `How many orders have status "${status}"?`,
        groundTruth: String(count),
        type: 'aggregation',
        dataset: 'nested',
      })
    }

    questions.push(
      {
        id: `q${idCounter++}`,
        prompt: 'What is the total revenue across all orders?',
        groundTruth: String(totalRevenue.toFixed(2)),
        type: 'aggregation',
        dataset: 'nested',
      },
      {
        id: `q${idCounter++}`,
        prompt: 'What is the average order value?',
        groundTruth: String(avgOrderValue.toFixed(2)),
        type: 'aggregation',
        dataset: 'nested',
      },
      {
        id: `q${idCounter++}`,
        prompt: 'How many orders are in the dataset?',
        groundTruth: String(totalOrders),
        type: 'aggregation',
        dataset: 'nested',
      },
      {
        id: `q${idCounter++}`,
        prompt: 'What is the highest order total?',
        groundTruth: String(maxOrderValue.toFixed(2)),
        type: 'aggregation',
        dataset: 'nested',
      },
    )

    // Aggregation: high-value orders (single-condition filter)
    for (const threshold of QUESTION_THRESHOLDS.nested.highValueOrders) {
      const count = nested.filter(o => o.total > threshold).length
      questions.push({
        id: `q${idCounter++}`,
        prompt: `How many orders have a total greater than ${threshold}?`,
        groundTruth: String(count),
        type: 'aggregation',
        dataset: 'nested',
      })
    }

    // Filtering: multi-condition queries (status AND value)
    const orderStatuses = [...new Set(nested.map(o => o.status))]
    for (const status of orderStatuses.slice(0, QUESTION_LIMITS.nested.filteringStatusAndValue)) {
      const count = nested.filter(o => o.status === status && o.total > QUESTION_THRESHOLDS.nested.statusValueThreshold).length
      questions.push({
        id: `q${idCounter++}`,
        prompt: `How many orders have status "${status}" and total greater than ${QUESTION_THRESHOLDS.nested.statusValueThreshold}?`,
        groundTruth: String(count),
        type: 'filtering',
        dataset: 'nested',
      })
    }

    // Filtering: status AND items count (multi-condition)
    for (const status of orderStatuses.slice(0, QUESTION_LIMITS.nested.filteringStatusAndItems)) {
      const count = nested.filter(o => o.status === status && o.items.length >= QUESTION_THRESHOLDS.nested.itemCountThreshold).length
      questions.push({
        id: `q${idCounter++}`,
        prompt: `How many orders have status "${status}" and at least ${QUESTION_THRESHOLDS.nested.itemCountThreshold} items?`,
        groundTruth: String(count),
        type: 'filtering',
        dataset: 'nested',
      })
    }

    // Filtering: total AND items count (multi-condition)
    for (const threshold of QUESTION_THRESHOLDS.nested.totalThresholdsForItems) {
      const count = nested.filter(o => o.total > threshold && o.items.length >= QUESTION_THRESHOLDS.nested.itemCountThreshold).length
      questions.push({
        id: `q${idCounter++}`,
        prompt: `How many orders have a total greater than ${threshold} and at least ${QUESTION_THRESHOLDS.nested.itemCountThreshold} items?`,
        groundTruth: String(count),
        type: 'filtering',
        dataset: 'nested',
      })
    }
  }

  if (analytics.length > 0) {
    // Field retrieval: specific dates (expanded with all metrics)
    for (let i = 0; i < Math.min(QUESTION_LIMITS.analytics.fieldRetrievalDates, analytics.length); i++) {
      const metric = analytics[i * 3] || analytics[i]
      if (!metric)
        continue

      if (i % 5 === 0) {
        questions.push({
          id: `q${idCounter++}`,
          prompt: `How many views were recorded on ${metric.date}?`,
          groundTruth: String(metric.views),
          type: 'field-retrieval',
          dataset: 'analytics',
        })
      }
      else if (i % 5 === 1) {
        questions.push({
          id: `q${idCounter++}`,
          prompt: `What was the revenue on ${metric.date}?`,
          groundTruth: String(metric.revenue),
          type: 'field-retrieval',
          dataset: 'analytics',
        })
      }
      else if (i % 5 === 2) {
        questions.push({
          id: `q${idCounter++}`,
          prompt: `What was the conversion count on ${metric.date}?`,
          groundTruth: String(metric.conversions),
          type: 'field-retrieval',
          dataset: 'analytics',
        })
      }
      else if (i % 5 === 3) {
        questions.push({
          id: `q${idCounter++}`,
          prompt: `How many clicks were recorded on ${metric.date}?`,
          groundTruth: String(metric.clicks),
          type: 'field-retrieval',
          dataset: 'analytics',
        })
      }
      else {
        questions.push({
          id: `q${idCounter++}`,
          prompt: `What was the bounce rate on ${metric.date}?`,
          groundTruth: String(metric.bounceRate),
          type: 'field-retrieval',
          dataset: 'analytics',
        })
      }
    }

    // Aggregation: totals and averages
    const totalViews = analytics.reduce((sum, m) => sum + m.views, 0)
    const totalRevenue = analytics.reduce((sum, m) => sum + m.revenue, 0)
    const totalConversions = analytics.reduce((sum, m) => sum + m.conversions, 0)
    const avgViews = Math.round(totalViews / analytics.length)
    const avgRevenue = totalRevenue / analytics.length
    const avgConversions = Math.round(totalConversions / analytics.length)

    questions.push(
      {
        id: `q${idCounter++}`,
        prompt: 'What is the total number of views across all dates?',
        groundTruth: String(totalViews),
        type: 'aggregation',
        dataset: 'analytics',
      },
      {
        id: `q${idCounter++}`,
        prompt: 'What is the total revenue across all dates?',
        groundTruth: String(totalRevenue.toFixed(2)),
        type: 'aggregation',
        dataset: 'analytics',
      },
      {
        id: `q${idCounter++}`,
        prompt: 'What is the total number of conversions across all dates?',
        groundTruth: String(totalConversions),
        type: 'aggregation',
        dataset: 'analytics',
      },
      {
        id: `q${idCounter++}`,
        prompt: 'What is the average number of views per day?',
        groundTruth: String(avgViews),
        type: 'aggregation',
        dataset: 'analytics',
      },
      {
        id: `q${idCounter++}`,
        prompt: 'What is the average revenue per day?',
        groundTruth: String(avgRevenue.toFixed(2)),
        type: 'aggregation',
        dataset: 'analytics',
      },
      {
        id: `q${idCounter++}`,
        prompt: 'What is the average number of conversions per day?',
        groundTruth: String(avgConversions),
        type: 'aggregation',
        dataset: 'analytics',
      },
      {
        id: `q${idCounter++}`,
        prompt: 'How many days are included in the analytics data?',
        groundTruth: String(analytics.length),
        type: 'aggregation',
        dataset: 'analytics',
      },
      {
        id: `q${idCounter++}`,
        prompt: 'What is the highest number of views recorded in a single day?',
        groundTruth: String(Math.max(...analytics.map(m => m.views))),
        type: 'aggregation',
        dataset: 'analytics',
      },
    )

    // Aggregation: high-performing days (single-condition filters)
    for (const threshold of QUESTION_THRESHOLDS.analytics.views) {
      const count = analytics.filter(m => m.views > threshold).length
      questions.push({
        id: `q${idCounter++}`,
        prompt: `How many days had more than ${threshold} views?`,
        groundTruth: String(count),
        type: 'aggregation',
        dataset: 'analytics',
      })
    }

    // Filtering: multi-condition queries (views AND conversions)
    for (const viewThreshold of QUESTION_THRESHOLDS.analytics.viewsForFiltering) {
      const count = analytics.filter(m => m.views > viewThreshold && m.conversions > QUESTION_THRESHOLDS.analytics.conversionsForFiltering).length
      questions.push({
        id: `q${idCounter++}`,
        prompt: `How many days had more than ${viewThreshold} views and more than ${QUESTION_THRESHOLDS.analytics.conversionsForFiltering} conversions?`,
        groundTruth: String(count),
        type: 'filtering',
        dataset: 'analytics',
      })
    }

    // Filtering: views AND revenue (expanded)
    for (const revenueThreshold of QUESTION_THRESHOLDS.analytics.revenueThresholds.slice(0, 5)) {
      const count = analytics.filter(m => m.views > QUESTION_THRESHOLDS.analytics.viewsThresholdForRevenue && m.revenue > revenueThreshold).length
      questions.push({
        id: `q${idCounter++}`,
        prompt: `How many days had more than ${QUESTION_THRESHOLDS.analytics.viewsThresholdForRevenue} views and revenue greater than ${revenueThreshold}?`,
        groundTruth: String(count),
        type: 'filtering',
        dataset: 'analytics',
      })
    }

    // Filtering: clicks AND conversions (multi-condition)
    for (const clickThreshold of QUESTION_THRESHOLDS.analytics.clicksForFiltering) {
      const count = analytics.filter(m => m.clicks > clickThreshold && m.conversions > QUESTION_THRESHOLDS.analytics.conversionsForClickFiltering).length
      questions.push({
        id: `q${idCounter++}`,
        prompt: `How many days had more than ${clickThreshold} clicks and more than ${QUESTION_THRESHOLDS.analytics.conversionsForClickFiltering} conversions?`,
        groundTruth: String(count),
        type: 'filtering',
        dataset: 'analytics',
      })
    }

    // Filtering: revenue AND bounce rate (multi-condition)
    for (const revenueThreshold of QUESTION_THRESHOLDS.analytics.revenueForBounceRate) {
      const count = analytics.filter(m => m.revenue > revenueThreshold && m.bounceRate < QUESTION_THRESHOLDS.analytics.bounceRateThreshold).length
      questions.push({
        id: `q${idCounter++}`,
        prompt: `How many days had revenue greater than ${revenueThreshold} and bounce rate less than ${QUESTION_THRESHOLDS.analytics.bounceRateThreshold}?`,
        groundTruth: String(count),
        type: 'filtering',
        dataset: 'analytics',
      })
    }
  }

  if (github.length > 0) {
    // Helper to extract owner from repo field
    const getOwner = (repoFullName: string) => repoFullName.split('/')[0]!

    // Field retrieval: specific repos (diverse fields)
    for (let i = 0; i < Math.min(QUESTION_LIMITS.github.fieldRetrievalRepos, github.length); i++) {
      const repo = github[i * 7]
      if (!repo)
        continue

      if (i % 5 === 0) {
        questions.push({
          id: `q${idCounter++}`,
          prompt: `How many stars does ${repo.repo} have?`,
          groundTruth: String(repo.stars),
          type: 'field-retrieval',
          dataset: 'github',
        })
      }
      else if (i % 5 === 1) {
        questions.push({
          id: `q${idCounter++}`,
          prompt: `How many forks does ${repo.repo} have?`,
          groundTruth: String(repo.forks),
          type: 'field-retrieval',
          dataset: 'github',
        })
      }
      else if (i % 5 === 2) {
        questions.push({
          id: `q${idCounter++}`,
          prompt: `Who is the owner of ${repo.repo}?`,
          groundTruth: getOwner(repo.repo),
          type: 'field-retrieval',
          dataset: 'github',
        })
      }
      else if (i % 5 === 3) {
        questions.push({
          id: `q${idCounter++}`,
          prompt: `What is the default branch of ${repo.repo}?`,
          groundTruth: repo.defaultBranch,
          type: 'field-retrieval',
          dataset: 'github',
        })
      }
      else {
        questions.push({
          id: `q${idCounter++}`,
          prompt: `How many watchers does ${repo.repo} have?`,
          groundTruth: String(repo.watchers),
          type: 'field-retrieval',
          dataset: 'github',
        })
      }
    }

    // Aggregation: popular repositories
    const totalStars = github.reduce((sum, r) => sum + r.stars, 0)
    const totalRepos = github.length
    const avgStars = Math.round(totalStars / totalRepos)

    questions.push(
      {
        id: `q${idCounter++}`,
        prompt: 'What is the total number of stars across all repositories?',
        groundTruth: String(totalStars),
        type: 'aggregation',
        dataset: 'github',
      },
      {
        id: `q${idCounter++}`,
        prompt: 'How many repositories are in the dataset?',
        groundTruth: String(totalRepos),
        type: 'aggregation',
        dataset: 'github',
      },
      {
        id: `q${idCounter++}`,
        prompt: 'What is the average number of stars per repository?',
        groundTruth: String(avgStars),
        type: 'aggregation',
        dataset: 'github',
      },
    )

    // Aggregation: star thresholds (single-condition filters)
    for (const threshold of QUESTION_THRESHOLDS.github.stars) {
      const count = github.filter(r => r.stars > threshold).length
      questions.push({
        id: `q${idCounter++}`,
        prompt: `How many repositories have more than ${threshold} stars?`,
        groundTruth: String(count),
        type: 'aggregation',
        dataset: 'github',
      })
    }

    // Aggregation: fork thresholds (single-condition filters)
    for (const threshold of QUESTION_THRESHOLDS.github.forks) {
      const count = github.filter(r => r.forks > threshold).length
      questions.push({
        id: `q${idCounter++}`,
        prompt: `How many repositories have more than ${threshold} forks?`,
        groundTruth: String(count),
        type: 'aggregation',
        dataset: 'github',
      })
    }

    // Aggregation: watcher thresholds (single-condition filters)
    for (const threshold of QUESTION_THRESHOLDS.github.watchers) {
      const count = github.filter(r => r.watchers > threshold).length
      questions.push({
        id: `q${idCounter++}`,
        prompt: `How many repositories have more than ${threshold} watchers?`,
        groundTruth: String(count),
        type: 'aggregation',
        dataset: 'github',
      })
    }

    // Aggregation: default branch counts
    const branches = [...new Set(github.map(r => r.defaultBranch))]
    for (const branch of branches.slice(0, QUESTION_LIMITS.github.aggregationBranches)) {
      const count = github.filter(r => r.defaultBranch === branch).length
      questions.push({
        id: `q${idCounter++}`,
        prompt: `How many repositories use "${branch}" as their default branch?`,
        groundTruth: String(count),
        type: 'aggregation',
        dataset: 'github',
      })
    }

    // Filtering: multi-condition queries (stars AND forks)
    for (const combo of QUESTION_THRESHOLDS.github.starForkCombinations.slice(0, QUESTION_LIMITS.github.filteringStarsAndForks)) {
      const count = github.filter(r => r.stars > combo.stars && r.forks > combo.forks).length
      questions.push({
        id: `q${idCounter++}`,
        prompt: `How many repositories have more than ${combo.stars} stars and more than ${combo.forks} forks?`,
        groundTruth: String(count),
        type: 'filtering',
        dataset: 'github',
      })
    }

    // Filtering: stars AND watchers (multi-condition)
    for (const combo of QUESTION_THRESHOLDS.github.starWatcherCombinations) {
      const count = github.filter(r => r.stars > combo.stars && r.watchers > combo.watchers).length
      questions.push({
        id: `q${idCounter++}`,
        prompt: `How many repositories have more than ${combo.stars} stars and more than ${combo.watchers} watchers?`,
        groundTruth: String(count),
        type: 'filtering',
        dataset: 'github',
      })
    }
  }

  return questions
}



================================================
FILE: benchmarks/src/report.ts
================================================
import type { EvaluationResult, FormatResult, Question } from './types'
import * as fsp from 'node:fs/promises'
import * as path from 'node:path'
import { BENCHMARKS_DIR, FORMATTER_DISPLAY_NAMES } from './constants'
import { datasets } from './datasets'
import { models } from './evaluate'
import { createProgressBar, ensureDir, tokenize } from './utils'

/**
 * Calculate per-format statistics from evaluation results
 */
export function calculateFormatResults(
  results: EvaluationResult[],
  tokenCounts: Record<string, number>,
): FormatResult[] {
  const formatNames = [...new Set(results.map(r => r.format))]

  return formatNames.map((formatName) => {
    const formatResults = results.filter(r => r.format === formatName)
    const correctCount = formatResults.filter(r => r.isCorrect).length
    const totalCount = formatResults.length
    const accuracy = correctCount / totalCount

    // Calculate average tokens across all datasets for this format
    const avgTokens = Object.entries(tokenCounts)
      .filter(([key]) => key.startsWith(`${formatName}-`))
      .reduce((sum, [, tokens]) => sum + tokens, 0) / datasets.length

    const averageLatency = formatResults.reduce((sum, r) => sum + r.latencyMs, 0) / totalCount

    return {
      format: formatName,
      accuracy,
      totalTokens: Math.round(avgTokens),
      averageLatency: Math.round(averageLatency),
      correctCount,
      totalCount,
    }
  }).sort((a, b) => b.accuracy - a.accuracy)
}

/**
 * Generate embeddable markdown report from results
 */
export function generateMarkdownReport(
  formatResults: FormatResult[],
  results: EvaluationResult[],
  questions: Question[],
  tokenCounts: Record<string, number>,
): string {
  const toon = formatResults.find(r => r.format === 'toon')
  const json = formatResults.find(r => r.format === 'json-pretty')

  const modelIds = models.map(m => m.modelId)
  const modelNames = modelIds.filter(id => results.some(r => r.model === id))

  const maxDisplayNameWidth = Math.max(
    ...Object.values(FORMATTER_DISPLAY_NAMES).map(name => name.length),
  )
  const progressBarWidth = 20

  const modelBreakdown = modelNames.map((modelName, i) => {
    const modelResults = formatResults.map((fr) => {
      const modelFormatResults = results.filter(r => r.model === modelName && r.format === fr.format)
      const correctCount = modelFormatResults.filter(r => r.isCorrect).length
      const totalCount = modelFormatResults.length
      const accuracy = totalCount > 0 ? correctCount / totalCount : 0

      return {
        format: fr.format,
        accuracy,
        correctCount,
        totalCount,
      }
    }).sort((a, b) => b.accuracy - a.accuracy)

    const formatLines = modelResults.map((result) => {
      const bar = createProgressBar(result.accuracy, 1, progressBarWidth)
      const accuracyString = `${(result.accuracy * 100).toFixed(1)}%`.padStart(6)
      const countString = `(${result.correctCount}/${result.totalCount})`
      const prefix = result.format === 'toon' ? '‚Üí ' : '  '
      const displayName = FORMATTER_DISPLAY_NAMES[result.format] || result.format
      return `${prefix}${displayName.padEnd(maxDisplayNameWidth)}   ${bar}   ${accuracyString} ${countString}`
    }).join('\n')

    // Add blank line before model name, except for first model
    return `${i > 0 ? '\n' : ''}${modelName}\n${formatLines}`
  }).join('\n')

  // Build summary comparison
  const summaryComparison = toon && json
    ? `**Key tradeoff:** TOON achieves **${(toon.accuracy * 100).toFixed(1)}% accuracy** (vs JSON's ${(json.accuracy * 100).toFixed(1)}%) while using **${((1 - toon.totalTokens / json.totalTokens) * 100).toFixed(1)}% fewer tokens** on these datasets.`
    : ''

  // Build performance by dataset
  const datasetBreakdown = datasets.map((dataset) => {
    const datasetResults = formatResults.map((fr) => {
      const datasetFormatResults = results.filter(r => r.questionId.includes(dataset.name) || questions.find(q => q.id === r.questionId)?.dataset === dataset.name)
      if (datasetFormatResults.length === 0)
        return undefined

      const formatDatasetResults = datasetFormatResults.filter(r => r.format === fr.format)
      if (formatDatasetResults.length === 0)
        return undefined

      const correctCount = formatDatasetResults.filter(r => r.isCorrect).length
      const totalCount = formatDatasetResults.length
      const accuracy = totalCount > 0 ? correctCount / totalCount : 0

      // Get token count for this dataset+format
      const tokenKey = `${fr.format}-${dataset.name}`
      const tokens = tokenCounts[tokenKey] || fr.totalTokens

      return {
        format: fr.format,
        accuracy,
        tokens,
        correctCount,
        totalCount,
      }
    }).filter(Boolean) as { format: string, accuracy: number, tokens: number, correctCount: number, totalCount: number }[]

    if (datasetResults.length === 0)
      return ''

    // Sort by efficiency
    datasetResults.sort((a, b) => {
      const effA = (a.accuracy ** 2) / (a.tokens / 1000)
      const effB = (b.accuracy ** 2) / (b.tokens / 1000)
      return effB - effA
    })

    const tableRows = datasetResults.slice(0, 6).map(result =>
      `| \`${result.format}\` | ${(result.accuracy * 100).toFixed(1)}% | ${result.tokens.toLocaleString('en-US')} | ${result.correctCount}/${result.totalCount} |`,
    ).join('\n')

    return `
##### ${dataset.description}

| Format | Accuracy | Tokens | Correct/Total |
| ------ | -------- | ------ | ------------- |
${tableRows}
`.trimStart()
  }).filter(Boolean).join('\n').trim()

  // Build performance by model
  const modelPerformance = modelNames.map((modelName) => {
    const modelResults = formatResults.map((fr) => {
      const modelFormatResults = results.filter(r => r.model === modelName && r.format === fr.format)
      const correctCount = modelFormatResults.filter(r => r.isCorrect).length
      const totalCount = modelFormatResults.length
      const accuracy = correctCount / totalCount

      return {
        format: fr.format,
        accuracy,
        correctCount,
        totalCount,
      }
    }).sort((a, b) => b.accuracy - a.accuracy)

    const tableRows = modelResults.map(result =>
      `| \`${result.format}\` | ${(result.accuracy * 100).toFixed(1)}% | ${result.correctCount}/${result.totalCount} |`,
    ).join('\n')

    return `
##### ${modelName}

| Format | Accuracy | Correct/Total |
| ------ | -------- | ------------- |
${tableRows}
`.trimStart()
  }).join('\n').trim()

  // Calculate total unique questions
  const totalQuestions = [...new Set(results.map(r => r.questionId))].length

  // Calculate question type distribution
  const fieldRetrievalCount = questions.filter(q => q.type === 'field-retrieval').length
  const aggregationCount = questions.filter(q => q.type === 'aggregation').length
  const filteringCount = questions.filter(q => q.type === 'filtering').length

  const fieldRetrievalPercent = ((fieldRetrievalCount / totalQuestions) * 100).toFixed(0)
  const aggregationPercent = ((aggregationCount / totalQuestions) * 100).toFixed(0)
  const filteringPercent = ((filteringCount / totalQuestions) * 100).toFixed(0)

  // Calculate dataset sizes
  const tabularSize = datasets.find(d => d.name === 'tabular')?.data.employees?.length || 0
  const nestedSize = datasets.find(d => d.name === 'nested')?.data.orders?.length || 0
  const analyticsSize = datasets.find(d => d.name === 'analytics')?.data.metrics?.length || 0
  const githubSize = datasets.find(d => d.name === 'github')?.data.repositories?.length || 0

  // Calculate number of formats and evaluations
  const formatCount = formatResults.length
  const totalEvaluations = totalQuestions * formatCount * modelNames.length

  return `
### Retrieval Accuracy

Accuracy across **${modelNames.length} ${modelNames.length === 1 ? 'LLM' : 'LLMs'}** on ${totalQuestions} data retrieval questions:

\`\`\`
${modelBreakdown}
\`\`\`

${summaryComparison}

<details>
<summary><strong>Performance by dataset and model</strong></summary>

#### Performance by Dataset

${datasetBreakdown}

#### Performance by Model

${modelPerformance}

</details>

<details>
<summary><strong>How the benchmark works</strong></summary>

#### What's Being Measured

This benchmark tests **LLM comprehension and data retrieval accuracy** across different input formats. Each LLM receives formatted data and must answer questions about it (this does **not** test model's ability to generate TOON output).

#### Datasets Tested

Four datasets designed to test different structural patterns (all contain arrays of uniform objects, TOON's optimal format):

1. **Tabular** (${tabularSize} employee records): Uniform objects with identical fields ‚Äì optimal for TOON's tabular format.
2. **Nested** (${nestedSize} e-commerce orders): Complex structures with nested customer objects and item arrays.
3. **Analytics** (${analyticsSize} days of metrics): Time-series data with dates and numeric values.
4. **GitHub** (${githubSize} repositories): Real-world data from top GitHub repos by stars.

#### Question Types

${totalQuestions} questions are generated dynamically across three categories:

\- **Field retrieval (${fieldRetrievalPercent}%)**: Direct value lookups or values that can be read straight off a record (including booleans and simple counts such as array lengths)
  - Example: "What is Alice's salary?" ‚Üí \`75000\`
  - Example: "How many items are in order ORD-0042?" ‚Üí \`3\`
  - Example: "What is the customer name for order ORD-0042?" ‚Üí \`John Doe\`

- **Aggregation (${aggregationPercent}%)**: Dataset-level totals and averages plus single-condition filters (counts, sums, min/max comparisons)
  - Example: "How many employees work in Engineering?" ‚Üí \`17\`
  - Example: "What is the total revenue across all orders?" ‚Üí \`45123.50\`
  - Example: "How many employees have salary > 80000?" ‚Üí \`23\`

- **Filtering (${filteringPercent}%)**: Multi-condition queries requiring compound logic (AND constraints across fields)
  - Example: "How many employees in Sales have salary > 80000?" ‚Üí \`5\`
  - Example: "How many active employees have more than 10 years of experience?" ‚Üí \`8\`

#### Evaluation Process

1. **Format conversion**: Each dataset is converted to all ${formatCount} formats (${formatResults.map(f => FORMATTER_DISPLAY_NAMES[f.format] || f.format).join(', ')}).
2. **Query LLM**: Each model receives formatted data + question in a prompt and extracts the answer.
3. **Validate with LLM-as-judge**: \`gpt-5-nano\` validates if the answer is semantically correct (e.g., \`50000\` = \`$50,000\`, \`Engineering\` = \`engineering\`, \`2025-01-01\` = \`January 1, 2025\`).

#### Models & Configuration

- **Models tested**: ${modelNames.map(m => `\`${m}\``).join(', ')}
- **Token counting**: Using \`gpt-tokenizer\` with \`o200k_base\` encoding (GPT-5 tokenizer)
- **Temperature**: Not set (models use their defaults)
- **Total evaluations**: ${totalQuestions} questions √ó ${formatCount} formats √ó ${modelNames.length} models = ${totalEvaluations.toLocaleString('en-US')} LLM calls

</details>
`.trimStart()
}

/**
 * Calculate token counts for all format+dataset combinations
 */
export function calculateTokenCounts(
  formatters: Record<string, (data: unknown) => string>,
): Record<string, number> {
  const tokenCounts: Record<string, number> = {}

  for (const [formatName, formatter] of Object.entries(formatters)) {
    for (const dataset of datasets) {
      const formatted = formatter(dataset.data)
      const key = `${formatName}-${dataset.name}`
      tokenCounts[key] = tokenize(formatted)
    }
  }

  return tokenCounts
}

/**
 * Save results to disk
 *
 * @remarks
 * Per-model results are managed separately via storage.ts
 * This function only generates the aggregated markdown report
 */
export async function saveResults(
  results: EvaluationResult[],
  formatResults: FormatResult[],
  questions: Question[],
  tokenCounts: Record<string, number>,
): Promise<string> {
  const resultsDir = path.join(BENCHMARKS_DIR, 'results')
  await ensureDir(resultsDir)

  // Generate markdown report from all available model results
  const report = generateMarkdownReport(formatResults, results, questions, tokenCounts)
  await fsp.writeFile(path.join(resultsDir, 'retrieval-accuracy.md'), report)

  return resultsDir
}



================================================
FILE: benchmarks/src/storage.ts
================================================
import type { Storage, StorageValue } from 'unstorage'
import type { EvaluationResult } from './types'
import * as path from 'node:path'
import { createStorage } from 'unstorage'
// @ts-expect-error: No types available
import fsDriver from 'unstorage/drivers/fs'
import { BENCHMARKS_DIR } from './constants'

/**
 * Storage instance for model results
 *
 * @remarks
 * Stores results in: `benchmarks/results/accuracy/models/`
 */
export const resultsStorage: Storage<StorageValue> = createStorage({
  driver: fsDriver({
    base: path.join(BENCHMARKS_DIR, 'results', 'accuracy', 'models'),
  }),
})

export async function loadModelResults(modelId: string): Promise<EvaluationResult[] | undefined> {
  const data = await resultsStorage.getItem<EvaluationResult[]>(modelId)
  return data ?? undefined
}

export async function saveModelResults(modelId: string, results: EvaluationResult[]): Promise<void> {
  await resultsStorage.setItem(modelId, results)
}

export async function getAllModelResults(): Promise<Record<string, EvaluationResult[]>> {
  const keys = await resultsStorage.getKeys()
  const results: Record<string, EvaluationResult[]> = {}

  await Promise.all(
    keys.map(async (modelId) => {
      const data = await resultsStorage.getItem<EvaluationResult[]>(modelId)
      if (data)
        results[modelId] = data
    }),
  )

  return results
}

export async function hasModelResults(modelId: string): Promise<boolean> {
  return await resultsStorage.hasItem(modelId)
}



================================================
FILE: benchmarks/src/types.ts
================================================
export interface Dataset {
  name: string
  description: string
  data: Record<string, any>
}

export interface Question {
  id: string
  prompt: string
  groundTruth: string
  type: 'field-retrieval' | 'aggregation' | 'filtering' | 'comparison'
  dataset: string
}

export interface EvaluationResult {
  questionId: string
  format: string
  model: string
  expected: string
  actual: string
  isCorrect: boolean
  inputTokens?: number
  outputTokens?: number
  latencyMs: number
}

export interface FormatResult {
  format: string
  accuracy: number
  totalTokens: number
  averageLatency: number
  correctCount: number
  totalCount: number
}



================================================
FILE: benchmarks/src/utils.ts
================================================
import * as fsp from 'node:fs/promises'
import { encode } from 'gpt-tokenizer'

/**
 * Generate visual progress bar using ASCII characters
 *
 * @param value - Current value
 * @param max - Maximum value
 * @param width - Width of the bar in characters (default: 25)
 * @returns ASCII progress bar string (`‚ñà` for filled, `‚ñë` for empty)
 *
 * @example
 * createProgressBar(75, 100, 20) // "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë"
 * createProgressBar(0.5, 1, 10)  // "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë"
 */
export function createProgressBar(value: number, max: number, width = 25): string {
  const filled = Math.round((value / max) * width)
  const empty = width - filled
  return '‚ñà'.repeat(filled) + '‚ñë'.repeat(empty)
}

/**
 * Count tokens in text using gpt-tokenizer (o200k_base encoding)
 *
 * @param text - Text to tokenize
 * @returns Number of tokens
 *
 * @example
 * tokenize("Hello, world!") // 4
 */
export function tokenize(text: string): number {
  return encode(text).length
}

/**
 * Ensure a directory exists, creating it recursively if needed
 *
 * @param dirPath - Directory path to ensure exists
 */
export async function ensureDir(dirPath: string): Promise<void> {
  await fsp.mkdir(dirPath, { recursive: true })
}



================================================
FILE: packages/cli/package.json
================================================
{
  "name": "@toon-format/cli",
  "type": "module",
  "version": "0.7.0",
  "packageManager": "pnpm@10.20.0",
  "description": "CLI for JSON ‚Üî TOON conversion using @toon-format/toon",
  "author": "Johann Schopplich <hello@johannschopplich.com>",
  "license": "MIT",
  "homepage": "https://toonformat.dev",
  "repository": {
    "type": "git",
    "url": "git+https://github.com/toon-format/toon.git"
  },
  "bugs": {
    "url": "https://github.com/toon-format/toon/issues"
  },
  "sideEffects": false,
  "exports": {
    ".": {
      "types": "./dist/index.d.ts",
      "default": "./dist/index.js"
    }
  },
  "types": "./dist/index.d.ts",
  "bin": {
    "toon": "bin/toon.mjs"
  },
  "files": [
    "bin",
    "dist"
  ],
  "scripts": {
    "dev": "tsx ./src/index.ts",
    "build": "tsdown"
  },
  "dependencies": {
    "citty": "^0.1.6",
    "consola": "^3.4.2",
    "tokenx": "^1.2.0"
  }
}



================================================
FILE: packages/cli/tsdown.config.ts
================================================
import type { UserConfig, UserConfigFn } from 'tsdown/config'
import { defineConfig } from 'tsdown/config'

const config: UserConfig | UserConfigFn = defineConfig({
  entry: 'src/index.ts',
  dts: true,
})

export default config



================================================
FILE: packages/cli/src/index.ts
================================================
import type { DecodeOptions, Delimiter, EncodeOptions } from '../../toon/src'
import * as fsp from 'node:fs/promises'
import * as path from 'node:path'
import process from 'node:process'
import { defineCommand, runMain } from 'citty'
import { consola } from 'consola'
import { estimateTokenCount } from 'tokenx'
import { name, version } from '../../toon/package.json' with { type: 'json' }
import { decode, DEFAULT_DELIMITER, DELIMITERS, encode } from '../../toon/src'

const main = defineCommand({
  meta: {
    name,
    description: 'TOON CLI ‚Äî Convert between JSON and TOON formats',
    version,
  },
  args: {
    input: {
      type: 'positional',
      description: 'Input file path',
      required: true,
    },
    output: {
      type: 'string',
      description: 'Output file path',
      alias: 'o',
    },
    encode: {
      type: 'boolean',
      description: 'Encode JSON to TOON (auto-detected by default)',
      alias: 'e',
    },
    decode: {
      type: 'boolean',
      description: 'Decode TOON to JSON (auto-detected by default)',
      alias: 'd',
    },
    delimiter: {
      type: 'string',
      description: 'Delimiter for arrays: comma (,), tab (\\t), or pipe (|)',
      default: ',',
    },
    indent: {
      type: 'string',
      description: 'Indentation size',
      default: '2',
    },
    lengthMarker: {
      type: 'boolean',
      description: 'Use length marker (#) for arrays',
      default: false,
    },
    strict: {
      type: 'boolean',
      description: 'Enable strict mode for decoding',
      default: true,
    },
    stats: {
      type: 'boolean',
      description: 'Show token statistics',
      default: false,
    },
  },
  async run({ args }) {
    const input = args.input || args._[0]
    if (!input) {
      throw new Error('Input file path is required')
    }

    const inputPath = path.resolve(input)
    const outputPath = args.output ? path.resolve(args.output) : undefined

    // Parse and validate indent
    const indent = Number.parseInt(args.indent || '2', 10)
    if (Number.isNaN(indent) || indent < 0) {
      throw new Error(`Invalid indent value: ${args.indent}`)
    }

    // Validate delimiter
    const delimiter = args.delimiter || DEFAULT_DELIMITER
    if (!(Object.values(DELIMITERS)).includes(delimiter as Delimiter)) {
      throw new Error(`Invalid delimiter "${delimiter}". Valid delimiters are: comma (,), tab (\\t), pipe (|)`)
    }

    const mode = detectMode(inputPath, args.encode, args.decode)

    try {
      if (mode === 'encode') {
        await encodeToToon({
          input: inputPath,
          output: outputPath,
          delimiter: delimiter as Delimiter,
          indent,
          lengthMarker: args.lengthMarker === true ? '#' : false,
          printStats: args.stats === true,
        })
      }
      else {
        await decodeToJson({
          input: inputPath,
          output: outputPath,
          indent,
          strict: args.strict !== false,
        })
      }
    }
    catch (error) {
      consola.error(error)
      process.exit(1)
    }
  },
})

function detectMode(
  inputFile: string,
  encodeFlag?: boolean,
  decodeFlag?: boolean,
): 'encode' | 'decode' {
  // Explicit flags take precedence
  if (encodeFlag)
    return 'encode'
  if (decodeFlag)
    return 'decode'

  // Auto-detect based on file extension
  if (inputFile.endsWith('.json'))
    return 'encode'
  if (inputFile.endsWith('.toon'))
    return 'decode'

  // Default to encode
  return 'encode'
}

async function encodeToToon(config: {
  input: string
  output?: string
  delimiter: Delimiter
  indent: number
  lengthMarker: NonNullable<EncodeOptions['lengthMarker']>
  printStats: boolean
}) {
  const jsonContent = await fsp.readFile(config.input, 'utf-8')

  let data: unknown
  try {
    data = JSON.parse(jsonContent)
  }
  catch (error) {
    throw new Error(`Failed to parse JSON: ${error instanceof Error ? error.message : String(error)}`)
  }

  const encodeOptions: EncodeOptions = {
    delimiter: config.delimiter,
    indent: config.indent,
    lengthMarker: config.lengthMarker,
  }

  const toonOutput = encode(data, encodeOptions)

  if (config.output) {
    await fsp.writeFile(config.output, toonOutput, 'utf-8')
    const relativeInputPath = path.relative(process.cwd(), config.input)
    const relativeOutputPath = path.relative(process.cwd(), config.output)
    consola.success(`Encoded \`${relativeInputPath}\` ‚Üí \`${relativeOutputPath}\``)
  }
  else {
    console.log(toonOutput)
  }

  if (config.printStats) {
    const jsonTokens = estimateTokenCount(jsonContent)
    const toonTokens = estimateTokenCount(toonOutput)
    const diff = jsonTokens - toonTokens
    const percent = ((diff / jsonTokens) * 100).toFixed(1)

    console.log()
    consola.info(`Token estimates: ~${jsonTokens} (JSON) ‚Üí ~${toonTokens} (TOON)`)
    consola.success(`Saved ~${diff} tokens (-${percent}%)`)
  }
}

async function decodeToJson(config: {
  input: string
  output?: string
  indent: number
  strict: boolean
}) {
  const toonContent = await fsp.readFile(config.input, 'utf-8')

  let data: unknown
  try {
    const decodeOptions: DecodeOptions = {
      indent: config.indent,
      strict: config.strict,
    }
    data = decode(toonContent, decodeOptions)
  }
  catch (error) {
    throw new Error(`Failed to decode TOON: ${error instanceof Error ? error.message : String(error)}`)
  }

  const jsonOutput = JSON.stringify(data, undefined, config.indent)

  if (config.output) {
    await fsp.writeFile(config.output, jsonOutput, 'utf-8')
    const relativeInputPath = path.relative(process.cwd(), config.input)
    const relativeOutputPath = path.relative(process.cwd(), config.output)
    consola.success(`Decoded \`${relativeInputPath}\` ‚Üí \`${relativeOutputPath}\``)
  }
  else {
    console.log(jsonOutput)
  }
}

runMain(main)



================================================
FILE: packages/toon/package.json
================================================
{
  "name": "@toon-format/toon",
  "type": "module",
  "version": "0.7.0",
  "packageManager": "pnpm@10.20.0",
  "description": "Token-Oriented Object Notation (TOON) ‚Äì a token-efficient JSON alternative for LLM prompts",
  "author": "Johann Schopplich <hello@johannschopplich.com>",
  "license": "MIT",
  "homepage": "https://toonformat.dev",
  "repository": {
    "type": "git",
    "url": "git+https://github.com/toon-format/toon.git"
  },
  "bugs": {
    "url": "https://github.com/toon-format/toon/issues"
  },
  "keywords": [
    "toon",
    "format",
    "specification",
    "llm",
    "token-efficiency",
    "data-format"
  ],
  "sideEffects": false,
  "exports": {
    ".": {
      "types": "./dist/index.d.ts",
      "default": "./dist/index.js"
    }
  },
  "types": "./dist/index.d.ts",
  "files": [
    "dist"
  ],
  "scripts": {
    "build": "tsdown",
    "test": "vitest"
  },
  "devDependencies": {
    "@toon-format/spec": "^1.3.0"
  }
}



================================================
FILE: packages/toon/tsdown.config.ts
================================================
import type { UserConfig, UserConfigFn } from 'tsdown/config'
import { defineConfig } from 'tsdown/config'

const config: UserConfig | UserConfigFn = defineConfig({
  entry: 'src/index.ts',
  dts: true,
})

export default config



================================================
FILE: packages/toon/src/constants.ts
================================================
// #region List markers

export const LIST_ITEM_MARKER = '-'
export const LIST_ITEM_PREFIX = '- '

// #endregion

// #region Structural characters

export const COMMA = ','
export const COLON = ':'
export const SPACE = ' '
export const PIPE = '|'
export const HASH = '#'

// #endregion

// #region Brackets and braces

export const OPEN_BRACKET = '['
export const CLOSE_BRACKET = ']'
export const OPEN_BRACE = '{'
export const CLOSE_BRACE = '}'

// #endregion

// #region Literals

export const NULL_LITERAL = 'null'
export const TRUE_LITERAL = 'true'
export const FALSE_LITERAL = 'false'

// #endregion

// #region Escape characters

export const BACKSLASH = '\\'
export const DOUBLE_QUOTE = '"'
export const NEWLINE = '\n'
export const CARRIAGE_RETURN = '\r'
export const TAB = '\t'

// #endregion

// #region Delimiters

export const DELIMITERS = {
  comma: COMMA as ',',
  tab: TAB as '\t',
  pipe: PIPE as '|',
} as const

export type DelimiterKey = keyof typeof DELIMITERS
export type Delimiter = typeof DELIMITERS[DelimiterKey]

export const DEFAULT_DELIMITER: Delimiter = DELIMITERS.comma

// #endregion



================================================
FILE: packages/toon/src/index.ts
================================================
import type { DecodeOptions, EncodeOptions, JsonValue, ResolvedDecodeOptions, ResolvedEncodeOptions } from './types'
import { DEFAULT_DELIMITER } from './constants'
import { decodeValueFromLines } from './decode/decoders'
import { LineCursor, toParsedLines } from './decode/scanner'
import { encodeValue } from './encode/encoders'
import { normalizeValue } from './encode/normalize'

export { DEFAULT_DELIMITER, DELIMITERS } from './constants'
export type {
  DecodeOptions,
  Delimiter,
  DelimiterKey,
  EncodeOptions,
  JsonArray,
  JsonObject,
  JsonPrimitive,
  JsonValue,
  ResolvedDecodeOptions,
  ResolvedEncodeOptions,
} from './types'

export function encode(input: unknown, options?: EncodeOptions): string {
  const normalizedValue = normalizeValue(input)
  const resolvedOptions = resolveOptions(options)
  return encodeValue(normalizedValue, resolvedOptions)
}

export function decode(input: string, options?: DecodeOptions): JsonValue {
  const resolvedOptions = resolveDecodeOptions(options)
  const scanResult = toParsedLines(input, resolvedOptions.indent, resolvedOptions.strict)

  if (scanResult.lines.length === 0) {
    throw new TypeError('Cannot decode empty input: input must be a non-empty string')
  }

  const cursor = new LineCursor(scanResult.lines, scanResult.blankLines)
  return decodeValueFromLines(cursor, resolvedOptions)
}

function resolveOptions(options?: EncodeOptions): ResolvedEncodeOptions {
  return {
    indent: options?.indent ?? 2,
    delimiter: options?.delimiter ?? DEFAULT_DELIMITER,
    lengthMarker: options?.lengthMarker ?? false,
  }
}

function resolveDecodeOptions(options?: DecodeOptions): ResolvedDecodeOptions {
  return {
    indent: options?.indent ?? 2,
    strict: options?.strict ?? true,
  }
}



================================================
FILE: packages/toon/src/types.ts
================================================
// #region JSON types

import type { Delimiter, DelimiterKey } from './constants'

export type JsonPrimitive = string | number | boolean | null
export type JsonObject = { [Key in string]: JsonValue } & { [Key in string]?: JsonValue | undefined }
export type JsonArray = JsonValue[] | readonly JsonValue[]
export type JsonValue = JsonPrimitive | JsonObject | JsonArray

// #endregion

// #region Encoder options

export type { Delimiter, DelimiterKey }

export interface EncodeOptions {
  /**
   * Number of spaces per indentation level.
   * @default 2
   */
  indent?: number
  /**
   * Delimiter to use for tabular array rows and inline primitive arrays.
   * @default DELIMITERS.comma
   */
  delimiter?: Delimiter
  /**
   * Optional marker to prefix array lengths in headers.
   * When set to `#`, arrays render as [#N] instead of [N].
   * @default false
   */
  lengthMarker?: '#' | false
}

export type ResolvedEncodeOptions = Readonly<Required<EncodeOptions>>

// #endregion

// #region Decoder options

export interface DecodeOptions {
  /**
   * Number of spaces per indentation level.
   * @default 2
   */
  indent?: number
  /**
   * When true, enforce strict validation of array lengths and tabular row counts.
   * @default true
   */
  strict?: boolean
}

export type ResolvedDecodeOptions = Readonly<Required<DecodeOptions>>

// #endregion

// #region Decoder parsing types

export interface ArrayHeaderInfo {
  key?: string
  length: number
  delimiter: Delimiter
  fields?: string[]
  hasLengthMarker: boolean
}

export interface ParsedLine {
  raw: string
  depth: Depth
  indent: number
  content: string
  lineNumber: number
}

export interface BlankLineInfo {
  lineNumber: number
  indent: number
  depth: Depth
}

// #endregion

export type Depth = number



================================================
FILE: packages/toon/src/decode/decoders.ts
================================================
import type { ArrayHeaderInfo, Delimiter, Depth, JsonArray, JsonObject, JsonPrimitive, JsonValue, ParsedLine, ResolvedDecodeOptions } from '../types'
import type { LineCursor } from './scanner'
import { COLON, DEFAULT_DELIMITER, LIST_ITEM_PREFIX } from '../constants'
import { findClosingQuote } from '../shared/string-utils'
import { isArrayHeaderAfterHyphen, isObjectFirstFieldAfterHyphen, mapRowValuesToPrimitives, parseArrayHeaderLine, parseDelimitedValues, parseKeyToken, parsePrimitiveToken } from './parser'
import { assertExpectedCount, validateNoBlankLinesInRange, validateNoExtraListItems, validateNoExtraTabularRows } from './validation'

// #region Entry decoding

export function decodeValueFromLines(cursor: LineCursor, options: ResolvedDecodeOptions): JsonValue {
  const first = cursor.peek()
  if (!first) {
    throw new ReferenceError('No content to decode')
  }

  // Check for root array
  if (isArrayHeaderAfterHyphen(first.content)) {
    const headerInfo = parseArrayHeaderLine(first.content, DEFAULT_DELIMITER)
    if (headerInfo) {
      cursor.advance() // Move past the header line
      return decodeArrayFromHeader(headerInfo.header, headerInfo.inlineValues, cursor, 0, options)
    }
  }

  // Check for single primitive value
  if (cursor.length === 1 && !isKeyValueLine(first)) {
    return parsePrimitiveToken(first.content.trim())
  }

  // Default to object
  return decodeObject(cursor, 0, options)
}

function isKeyValueLine(line: ParsedLine): boolean {
  const content = line.content
  // Look for unquoted colon or quoted key followed by colon
  if (content.startsWith('"')) {
    // Quoted key - find the closing quote
    const closingQuoteIndex = findClosingQuote(content, 0)
    if (closingQuoteIndex === -1) {
      return false
    }
    // Check if there's a colon after the quoted key
    return closingQuoteIndex + 1 < content.length && content[closingQuoteIndex + 1] === COLON
  }
  else {
    // Unquoted key - look for first colon not inside quotes
    return content.includes(COLON)
  }
}

// #endregion

// #region Object decoding

function decodeObject(cursor: LineCursor, baseDepth: Depth, options: ResolvedDecodeOptions): JsonObject {
  const obj: JsonObject = {}

  while (!cursor.atEnd()) {
    const line = cursor.peek()
    if (!line || line.depth < baseDepth) {
      break
    }

    if (line.depth === baseDepth) {
      const [key, value] = decodeKeyValuePair(line, cursor, baseDepth, options)
      obj[key] = value
    }
    else {
      break
    }
  }

  return obj
}

function decodeKeyValue(
  content: string,
  cursor: LineCursor,
  baseDepth: Depth,
  options: ResolvedDecodeOptions,
): { key: string, value: JsonValue, followDepth: Depth } {
  // Check for array header first (before parsing key)
  const arrayHeader = parseArrayHeaderLine(content, DEFAULT_DELIMITER)
  if (arrayHeader && arrayHeader.header.key) {
    const value = decodeArrayFromHeader(arrayHeader.header, arrayHeader.inlineValues, cursor, baseDepth, options)
    // After an array, subsequent fields are at baseDepth + 1 (where array content is)
    return {
      key: arrayHeader.header.key,
      value,
      followDepth: baseDepth + 1,
    }
  }

  // Regular key-value pair
  const { key, end } = parseKeyToken(content, 0)
  const rest = content.slice(end).trim()

  // No value after colon - expect nested object or empty
  if (!rest) {
    const nextLine = cursor.peek()
    if (nextLine && nextLine.depth > baseDepth) {
      const nested = decodeObject(cursor, baseDepth + 1, options)
      return { key, value: nested, followDepth: baseDepth + 1 }
    }
    // Empty object
    return { key, value: {}, followDepth: baseDepth + 1 }
  }

  // Inline primitive value
  const value = parsePrimitiveToken(rest)
  return { key, value, followDepth: baseDepth + 1 }
}

function decodeKeyValuePair(
  line: ParsedLine,
  cursor: LineCursor,
  baseDepth: Depth,
  options: ResolvedDecodeOptions,
): [key: string, value: JsonValue] {
  cursor.advance()
  const { key, value } = decodeKeyValue(line.content, cursor, baseDepth, options)
  return [key, value]
}

// #endregion

// #region Array decoding

function decodeArrayFromHeader(
  header: ArrayHeaderInfo,
  inlineValues: string | undefined,
  cursor: LineCursor,
  baseDepth: Depth,
  options: ResolvedDecodeOptions,
): JsonArray {
  // Inline primitive array
  if (inlineValues) {
    // For inline arrays, cursor should already be advanced or will be by caller
    return decodeInlinePrimitiveArray(header, inlineValues, options)
  }

  // For multi-line arrays (tabular or list), the cursor should already be positioned
  // at the array header line, but we haven't advanced past it yet

  // Tabular array
  if (header.fields && header.fields.length > 0) {
    return decodeTabularArray(header, cursor, baseDepth, options)
  }

  // List array
  return decodeListArray(header, cursor, baseDepth, options)
}

function decodeInlinePrimitiveArray(
  header: ArrayHeaderInfo,
  inlineValues: string,
  options: ResolvedDecodeOptions,
): JsonPrimitive[] {
  if (!inlineValues.trim()) {
    assertExpectedCount(0, header.length, 'inline array items', options)
    return []
  }

  const values = parseDelimitedValues(inlineValues, header.delimiter)
  const primitives = mapRowValuesToPrimitives(values)

  assertExpectedCount(primitives.length, header.length, 'inline array items', options)

  return primitives
}

function decodeListArray(
  header: ArrayHeaderInfo,
  cursor: LineCursor,
  baseDepth: Depth,
  options: ResolvedDecodeOptions,
): JsonValue[] {
  const items: JsonValue[] = []
  const itemDepth = baseDepth + 1

  // Track line range for blank line validation
  let startLine: number | undefined
  let endLine: number | undefined

  while (!cursor.atEnd() && items.length < header.length) {
    const line = cursor.peek()
    if (!line || line.depth < itemDepth) {
      break
    }

    if (line.depth === itemDepth && line.content.startsWith(LIST_ITEM_PREFIX)) {
      // Track first and last item line numbers
      if (startLine === undefined) {
        startLine = line.lineNumber
      }
      endLine = line.lineNumber

      const item = decodeListItem(cursor, itemDepth, header.delimiter, options)
      items.push(item)

      // Update endLine to the current cursor position (after item was decoded)
      const currentLine = cursor.current()
      if (currentLine) {
        endLine = currentLine.lineNumber
      }
    }
    else {
      break
    }
  }

  assertExpectedCount(items.length, header.length, 'list array items', options)

  // In strict mode, check for blank lines inside the array
  if (options.strict && startLine !== undefined && endLine !== undefined) {
    validateNoBlankLinesInRange(
      startLine, // From first item line
      endLine, // To last item line
      cursor.getBlankLines(),
      options.strict,
      'list array',
    )
  }

  // In strict mode, check for extra items
  if (options.strict) {
    validateNoExtraListItems(cursor, itemDepth, header.length)
  }

  return items
}

function decodeTabularArray(
  header: ArrayHeaderInfo,
  cursor: LineCursor,
  baseDepth: Depth,
  options: ResolvedDecodeOptions,
): JsonObject[] {
  const objects: JsonObject[] = []
  const rowDepth = baseDepth + 1

  // Track line range for blank line validation
  let startLine: number | undefined
  let endLine: number | undefined

  while (!cursor.atEnd() && objects.length < header.length) {
    const line = cursor.peek()
    if (!line || line.depth < rowDepth) {
      break
    }

    if (line.depth === rowDepth) {
      // Track first and last row line numbers
      if (startLine === undefined) {
        startLine = line.lineNumber
      }
      endLine = line.lineNumber

      cursor.advance()
      const values = parseDelimitedValues(line.content, header.delimiter)
      assertExpectedCount(values.length, header.fields!.length, 'tabular row values', options)

      const primitives = mapRowValuesToPrimitives(values)
      const obj: JsonObject = {}

      for (let i = 0; i < header.fields!.length; i++) {
        obj[header.fields![i]!] = primitives[i]!
      }

      objects.push(obj)
    }
    else {
      break
    }
  }

  assertExpectedCount(objects.length, header.length, 'tabular rows', options)

  // In strict mode, check for blank lines inside the array
  if (options.strict && startLine !== undefined && endLine !== undefined) {
    validateNoBlankLinesInRange(
      startLine, // From first row line
      endLine, // To last row line
      cursor.getBlankLines(),
      options.strict,
      'tabular array',
    )
  }

  // In strict mode, check for extra rows
  if (options.strict) {
    validateNoExtraTabularRows(cursor, rowDepth, header)
  }

  return objects
}

// #endregion

// #region List item decoding

function decodeListItem(
  cursor: LineCursor,
  baseDepth: Depth,
  activeDelimiter: Delimiter,
  options: ResolvedDecodeOptions,
): JsonValue {
  const line = cursor.next()
  if (!line) {
    throw new ReferenceError('Expected list item')
  }

  const afterHyphen = line.content.slice(LIST_ITEM_PREFIX.length)

  // Check for array header after hyphen
  if (isArrayHeaderAfterHyphen(afterHyphen)) {
    const arrayHeader = parseArrayHeaderLine(afterHyphen, DEFAULT_DELIMITER)
    if (arrayHeader) {
      return decodeArrayFromHeader(arrayHeader.header, arrayHeader.inlineValues, cursor, baseDepth, options)
    }
  }

  // Check for object first field after hyphen
  if (isObjectFirstFieldAfterHyphen(afterHyphen)) {
    return decodeObjectFromListItem(line, cursor, baseDepth, options)
  }

  // Primitive value
  return parsePrimitiveToken(afterHyphen)
}

function decodeObjectFromListItem(
  firstLine: ParsedLine,
  cursor: LineCursor,
  baseDepth: Depth,
  options: ResolvedDecodeOptions,
): JsonObject {
  const afterHyphen = firstLine.content.slice(LIST_ITEM_PREFIX.length)
  const { key, value, followDepth } = decodeKeyValue(afterHyphen, cursor, baseDepth, options)

  const obj: JsonObject = { [key]: value }

  // Read subsequent fields
  while (!cursor.atEnd()) {
    const line = cursor.peek()
    if (!line || line.depth < followDepth) {
      break
    }

    if (line.depth === followDepth && !line.content.startsWith(LIST_ITEM_PREFIX)) {
      const [k, v] = decodeKeyValuePair(line, cursor, followDepth, options)
      obj[k] = v
    }
    else {
      break
    }
  }

  return obj
}

// #endregion



================================================
FILE: packages/toon/src/decode/parser.ts
================================================
import type { ArrayHeaderInfo, Delimiter, JsonPrimitive } from '../types'
import { BACKSLASH, CLOSE_BRACE, CLOSE_BRACKET, COLON, DELIMITERS, DOUBLE_QUOTE, FALSE_LITERAL, HASH, NULL_LITERAL, OPEN_BRACE, OPEN_BRACKET, PIPE, TAB, TRUE_LITERAL } from '../constants'
import { isBooleanOrNullLiteral, isNumericLiteral } from '../shared/literal-utils'
import { findClosingQuote, findUnquotedChar, unescapeString } from '../shared/string-utils'

// #region Array header parsing

export function parseArrayHeaderLine(
  content: string,
  defaultDelimiter: Delimiter,
): { header: ArrayHeaderInfo, inlineValues?: string } | undefined {
  // Don't match if the line starts with a quote (it's a quoted key, not an array)
  if (content.trimStart().startsWith(DOUBLE_QUOTE)) {
    return
  }

  // Find the bracket segment first
  const bracketStart = content.indexOf(OPEN_BRACKET)
  if (bracketStart === -1) {
    return
  }

  const bracketEnd = content.indexOf(CLOSE_BRACKET, bracketStart)
  if (bracketEnd === -1) {
    return
  }

  // Find the colon that comes after all brackets and braces
  let colonIndex = bracketEnd + 1
  let braceEnd = colonIndex

  // Check for fields segment (braces come after bracket)
  const braceStart = content.indexOf(OPEN_BRACE, bracketEnd)
  if (braceStart !== -1 && braceStart < content.indexOf(COLON, bracketEnd)) {
    const foundBraceEnd = content.indexOf(CLOSE_BRACE, braceStart)
    if (foundBraceEnd !== -1) {
      braceEnd = foundBraceEnd + 1
    }
  }

  // Now find colon after brackets and braces
  colonIndex = content.indexOf(COLON, Math.max(bracketEnd, braceEnd))
  if (colonIndex === -1) {
    return
  }

  const key = bracketStart > 0 ? content.slice(0, bracketStart) : undefined
  const afterColon = content.slice(colonIndex + 1).trim()

  const bracketContent = content.slice(bracketStart + 1, bracketEnd)

  // Try to parse bracket segment
  let parsedBracket: ReturnType<typeof parseBracketSegment>
  try {
    parsedBracket = parseBracketSegment(bracketContent, defaultDelimiter)
  }
  catch {
    return
  }

  const { length, delimiter, hasLengthMarker } = parsedBracket

  // Check for fields segment
  let fields: string[] | undefined
  if (braceStart !== -1 && braceStart < colonIndex) {
    const foundBraceEnd = content.indexOf(CLOSE_BRACE, braceStart)
    if (foundBraceEnd !== -1 && foundBraceEnd < colonIndex) {
      const fieldsContent = content.slice(braceStart + 1, foundBraceEnd)
      fields = parseDelimitedValues(fieldsContent, delimiter).map(field => parseStringLiteral(field.trim()))
    }
  }

  return {
    header: {
      key,
      length,
      delimiter,
      fields,
      hasLengthMarker,
    },
    inlineValues: afterColon || undefined,
  }
}

export function parseBracketSegment(
  seg: string,
  defaultDelimiter: Delimiter,
): { length: number, delimiter: Delimiter, hasLengthMarker: boolean } {
  let hasLengthMarker = false
  let content = seg

  // Check for length marker
  if (content.startsWith(HASH)) {
    hasLengthMarker = true
    content = content.slice(1)
  }

  // Check for delimiter suffix
  let delimiter = defaultDelimiter
  if (content.endsWith(TAB)) {
    delimiter = DELIMITERS.tab
    content = content.slice(0, -1)
  }
  else if (content.endsWith(PIPE)) {
    delimiter = DELIMITERS.pipe
    content = content.slice(0, -1)
  }

  const length = Number.parseInt(content, 10)
  if (Number.isNaN(length)) {
    throw new TypeError(`Invalid array length: ${seg}`)
  }

  return { length, delimiter, hasLengthMarker }
}

// #endregion

// #region Delimited value parsing

export function parseDelimitedValues(input: string, delimiter: Delimiter): string[] {
  const values: string[] = []
  let current = ''
  let inQuotes = false
  let i = 0

  while (i < input.length) {
    const char = input[i]

    if (char === BACKSLASH && i + 1 < input.length && inQuotes) {
      // Escape sequence in quoted string
      current += char + input[i + 1]
      i += 2
      continue
    }

    if (char === DOUBLE_QUOTE) {
      inQuotes = !inQuotes
      current += char
      i++
      continue
    }

    if (char === delimiter && !inQuotes) {
      values.push(current.trim())
      current = ''
      i++
      continue
    }

    current += char
    i++
  }

  // Add last value
  if (current || values.length > 0) {
    values.push(current.trim())
  }

  return values
}

export function mapRowValuesToPrimitives(values: string[]): JsonPrimitive[] {
  return values.map(v => parsePrimitiveToken(v))
}

// #endregion

// #region Primitive and key parsing

export function parsePrimitiveToken(token: string): JsonPrimitive {
  const trimmed = token.trim()

  // Empty token
  if (!trimmed) {
    return ''
  }

  // Quoted string (if starts with quote, it MUST be properly quoted)
  if (trimmed.startsWith(DOUBLE_QUOTE)) {
    return parseStringLiteral(trimmed)
  }

  // Boolean or null literals
  if (isBooleanOrNullLiteral(trimmed)) {
    if (trimmed === TRUE_LITERAL)
      return true
    if (trimmed === FALSE_LITERAL)
      return false
    if (trimmed === NULL_LITERAL)
      return null
  }

  // Numeric literal
  if (isNumericLiteral(trimmed)) {
    return Number.parseFloat(trimmed)
  }

  // Unquoted string
  return trimmed
}

export function parseStringLiteral(token: string): string {
  const trimmed = token.trim()

  if (trimmed.startsWith(DOUBLE_QUOTE)) {
    // Find the closing quote, accounting for escaped quotes
    const closingQuoteIndex = findClosingQuote(trimmed, 0)

    if (closingQuoteIndex === -1) {
      // No closing quote was found
      throw new SyntaxError('Unterminated string: missing closing quote')
    }

    if (closingQuoteIndex !== trimmed.length - 1) {
      throw new SyntaxError('Unexpected characters after closing quote')
    }

    const content = trimmed.slice(1, closingQuoteIndex)
    return unescapeString(content)
  }

  return trimmed
}

export function parseUnquotedKey(content: string, start: number): { key: string, end: number } {
  let end = start
  while (end < content.length && content[end] !== COLON) {
    end++
  }

  // Validate that a colon was found
  if (end >= content.length || content[end] !== COLON) {
    throw new SyntaxError('Missing colon after key')
  }

  const key = content.slice(start, end).trim()

  // Skip the colon
  end++

  return { key, end }
}

export function parseQuotedKey(content: string, start: number): { key: string, end: number } {
  // Find the closing quote, accounting for escaped quotes
  const closingQuoteIndex = findClosingQuote(content, start)

  if (closingQuoteIndex === -1) {
    throw new SyntaxError('Unterminated quoted key')
  }

  // Extract and unescape the key content
  const keyContent = content.slice(start + 1, closingQuoteIndex)
  const key = unescapeString(keyContent)
  let end = closingQuoteIndex + 1

  // Validate and skip colon after quoted key
  if (end >= content.length || content[end] !== COLON) {
    throw new SyntaxError('Missing colon after key')
  }
  end++

  return { key, end }
}

export function parseKeyToken(content: string, start: number): { key: string, end: number } {
  if (content[start] === DOUBLE_QUOTE) {
    return parseQuotedKey(content, start)
  }
  else {
    return parseUnquotedKey(content, start)
  }
}

// #endregion

// #region Array content detection helpers

export function isArrayHeaderAfterHyphen(content: string): boolean {
  return content.trim().startsWith(OPEN_BRACKET) && findUnquotedChar(content, COLON) !== -1
}

export function isObjectFirstFieldAfterHyphen(content: string): boolean {
  return findUnquotedChar(content, COLON) !== -1
}

// #endregion



================================================
FILE: packages/toon/src/decode/scanner.ts
================================================
import type { BlankLineInfo, Depth, ParsedLine } from '../types'
import { SPACE, TAB } from '../constants'

export interface ScanResult {
  lines: ParsedLine[]
  blankLines: BlankLineInfo[]
}

export class LineCursor {
  private lines: ParsedLine[]
  private index: number
  private blankLines: BlankLineInfo[]

  constructor(lines: ParsedLine[], blankLines: BlankLineInfo[] = []) {
    this.lines = lines
    this.index = 0
    this.blankLines = blankLines
  }

  getBlankLines(): BlankLineInfo[] {
    return this.blankLines
  }

  peek(): ParsedLine | undefined {
    return this.lines[this.index]
  }

  next(): ParsedLine | undefined {
    return this.lines[this.index++]
  }

  current(): ParsedLine | undefined {
    return this.index > 0 ? this.lines[this.index - 1] : undefined
  }

  advance(): void {
    this.index++
  }

  atEnd(): boolean {
    return this.index >= this.lines.length
  }

  get length(): number {
    return this.lines.length
  }

  peekAtDepth(targetDepth: Depth): ParsedLine | undefined {
    const line = this.peek()
    if (!line || line.depth < targetDepth) {
      return undefined
    }
    if (line.depth === targetDepth) {
      return line
    }
    return undefined
  }

  hasMoreAtDepth(targetDepth: Depth): boolean {
    return this.peekAtDepth(targetDepth) !== undefined
  }
}

export function toParsedLines(source: string, indentSize: number, strict: boolean): ScanResult {
  if (!source.trim()) {
    return { lines: [], blankLines: [] }
  }

  const lines = source.split('\n')
  const parsed: ParsedLine[] = []
  const blankLines: BlankLineInfo[] = []

  for (let i = 0; i < lines.length; i++) {
    const raw = lines[i]!
    const lineNumber = i + 1
    let indent = 0
    while (indent < raw.length && raw[indent] === SPACE) {
      indent++
    }

    const content = raw.slice(indent)

    // Track blank lines
    if (!content.trim()) {
      const depth = computeDepthFromIndent(indent, indentSize)
      blankLines.push({ lineNumber, indent, depth })
      continue
    }

    const depth = computeDepthFromIndent(indent, indentSize)

    // Strict mode validation
    if (strict) {
      // Find the full leading whitespace region (spaces and tabs)
      let wsEnd = 0
      while (wsEnd < raw.length && (raw[wsEnd] === SPACE || raw[wsEnd] === TAB)) {
        wsEnd++
      }

      // Check for tabs in leading whitespace (before actual content)
      if (raw.slice(0, wsEnd).includes(TAB)) {
        throw new SyntaxError(`Line ${lineNumber}: Tabs are not allowed in indentation in strict mode`)
      }

      // Check for exact multiples of indentSize
      if (indent > 0 && indent % indentSize !== 0) {
        throw new SyntaxError(`Line ${lineNumber}: Indentation must be exact multiple of ${indentSize}, but found ${indent} spaces`)
      }
    }

    parsed.push({ raw, indent, content, depth, lineNumber })
  }

  return { lines: parsed, blankLines }
}

function computeDepthFromIndent(indentSpaces: number, indentSize: number): Depth {
  return Math.floor(indentSpaces / indentSize)
}



================================================
FILE: packages/toon/src/decode/validation.ts
================================================
import type { ArrayHeaderInfo, BlankLineInfo, Delimiter, Depth, ResolvedDecodeOptions } from '../types'
import type { LineCursor } from './scanner'
import { COLON, LIST_ITEM_PREFIX } from '../constants'

/**
 * Asserts that the actual count matches the expected count in strict mode.
 *
 * @param actual The actual count
 * @param expected The expected count
 * @param itemType The type of items being counted (e.g., `list array items`, `tabular rows`)
 * @param options Decode options
 * @throws RangeError if counts don't match in strict mode
 */
export function assertExpectedCount(
  actual: number,
  expected: number,
  itemType: string,
  options: ResolvedDecodeOptions,
): void {
  if (options.strict && actual !== expected) {
    throw new RangeError(`Expected ${expected} ${itemType}, but got ${actual}`)
  }
}

/**
 * Validates that there are no extra list items beyond the expected count.
 *
 * @param cursor The line cursor
 * @param itemDepth The expected depth of items
 * @param expectedCount The expected number of items
 * @throws RangeError if extra items are found
 */
export function validateNoExtraListItems(
  cursor: LineCursor,
  itemDepth: Depth,
  expectedCount: number,
): void {
  if (cursor.atEnd())
    return

  const nextLine = cursor.peek()
  if (nextLine && nextLine.depth === itemDepth && nextLine.content.startsWith(LIST_ITEM_PREFIX)) {
    throw new RangeError(`Expected ${expectedCount} list array items, but found more`)
  }
}

/**
 * Validates that there are no extra tabular rows beyond the expected count.
 *
 * @param cursor The line cursor
 * @param rowDepth The expected depth of rows
 * @param header The array header info containing length and delimiter
 * @throws RangeError if extra rows are found
 */
export function validateNoExtraTabularRows(
  cursor: LineCursor,
  rowDepth: Depth,
  header: ArrayHeaderInfo,
): void {
  if (cursor.atEnd())
    return

  const nextLine = cursor.peek()
  if (
    nextLine
    && nextLine.depth === rowDepth
    && !nextLine.content.startsWith(LIST_ITEM_PREFIX)
    && isDataRow(nextLine.content, header.delimiter)
  ) {
    throw new RangeError(`Expected ${header.length} tabular rows, but found more`)
  }
}

/**
 * Validates that there are no blank lines within a specific line range and depth.
 *
 * @remarks
 * In strict mode, blank lines inside arrays/tabular rows are not allowed.
 *
 * @param startLine The starting line number (inclusive)
 * @param endLine The ending line number (inclusive)
 * @param blankLines Array of blank line information
 * @param strict Whether strict mode is enabled
 * @param context Description of the context (e.g., "list array", "tabular array")
 * @throws SyntaxError if blank lines are found in strict mode
 */
export function validateNoBlankLinesInRange(
  startLine: number,
  endLine: number,
  blankLines: BlankLineInfo[],
  strict: boolean,
  context: string,
): void {
  if (!strict)
    return

  // Find blank lines within the range
  // Note: We don't filter by depth because ANY blank line between array items is an error,
  // regardless of its indentation level
  const blanksInRange = blankLines.filter(
    blank => blank.lineNumber > startLine
      && blank.lineNumber < endLine,
  )

  if (blanksInRange.length > 0) {
    throw new SyntaxError(
      `Line ${blanksInRange[0]!.lineNumber}: Blank lines inside ${context} are not allowed in strict mode`,
    )
  }
}

/**
 * Checks if a line represents a data row (as opposed to a key-value pair) in a tabular array.
 *
 * @param content The line content
 * @param delimiter The delimiter used in the table
 * @returns true if the line is a data row, false if it's a key-value pair
 */
function isDataRow(content: string, delimiter: Delimiter): boolean {
  const colonPos = content.indexOf(COLON)
  const delimiterPos = content.indexOf(delimiter)

  // No colon = definitely a data row
  if (colonPos === -1) {
    return true
  }

  // Has delimiter and it comes before colon = data row
  if (delimiterPos !== -1 && delimiterPos < colonPos) {
    return true
  }

  // Colon before delimiter or no delimiter = key-value pair
  return false
}



================================================
FILE: packages/toon/src/encode/encoders.ts
================================================
import type { Depth, JsonArray, JsonObject, JsonPrimitive, JsonValue, ResolvedEncodeOptions } from '../types'
import { LIST_ITEM_MARKER } from '../constants'
import { isArrayOfArrays, isArrayOfObjects, isArrayOfPrimitives, isJsonArray, isJsonObject, isJsonPrimitive } from './normalize'
import { encodeAndJoinPrimitives, encodeKey, encodePrimitive, formatHeader } from './primitives'
import { LineWriter } from './writer'

// #region Encode normalized JsonValue

export function encodeValue(value: JsonValue, options: ResolvedEncodeOptions): string {
  if (isJsonPrimitive(value)) {
    return encodePrimitive(value, options.delimiter)
  }

  const writer = new LineWriter(options.indent)

  if (isJsonArray(value)) {
    encodeArray(undefined, value, writer, 0, options)
  }
  else if (isJsonObject(value)) {
    encodeObject(value, writer, 0, options)
  }

  return writer.toString()
}

// #endregion

// #region Object encoding

export function encodeObject(value: JsonObject, writer: LineWriter, depth: Depth, options: ResolvedEncodeOptions): void {
  const keys = Object.keys(value)

  for (const key of keys) {
    encodeKeyValuePair(key, value[key]!, writer, depth, options)
  }
}

export function encodeKeyValuePair(key: string, value: JsonValue, writer: LineWriter, depth: Depth, options: ResolvedEncodeOptions): void {
  const encodedKey = encodeKey(key)

  if (isJsonPrimitive(value)) {
    writer.push(depth, `${encodedKey}: ${encodePrimitive(value, options.delimiter)}`)
  }
  else if (isJsonArray(value)) {
    encodeArray(key, value, writer, depth, options)
  }
  else if (isJsonObject(value)) {
    const nestedKeys = Object.keys(value)
    if (nestedKeys.length === 0) {
      // Empty object
      writer.push(depth, `${encodedKey}:`)
    }
    else {
      writer.push(depth, `${encodedKey}:`)
      encodeObject(value, writer, depth + 1, options)
    }
  }
}

// #endregion

// #region Array encoding

export function encodeArray(
  key: string | undefined,
  value: JsonArray,
  writer: LineWriter,
  depth: Depth,
  options: ResolvedEncodeOptions,
): void {
  if (value.length === 0) {
    const header = formatHeader(0, { key, delimiter: options.delimiter, lengthMarker: options.lengthMarker })
    writer.push(depth, header)
    return
  }

  // Primitive array
  if (isArrayOfPrimitives(value)) {
    const formatted = encodeInlineArrayLine(value, options.delimiter, key, options.lengthMarker)
    writer.push(depth, formatted)
    return
  }

  // Array of arrays (all primitives)
  if (isArrayOfArrays(value)) {
    const allPrimitiveArrays = value.every(arr => isArrayOfPrimitives(arr))
    if (allPrimitiveArrays) {
      encodeArrayOfArraysAsListItems(key, value, writer, depth, options)
      return
    }
  }

  // Array of objects
  if (isArrayOfObjects(value)) {
    const header = extractTabularHeader(value)
    if (header) {
      encodeArrayOfObjectsAsTabular(key, value, header, writer, depth, options)
    }
    else {
      encodeMixedArrayAsListItems(key, value, writer, depth, options)
    }
    return
  }

  // Mixed array: fallback to expanded format
  encodeMixedArrayAsListItems(key, value, writer, depth, options)
}

// #endregion

// #region Array of arrays (expanded format)

export function encodeArrayOfArraysAsListItems(
  prefix: string | undefined,
  values: readonly JsonArray[],
  writer: LineWriter,
  depth: Depth,
  options: ResolvedEncodeOptions,
): void {
  const header = formatHeader(values.length, { key: prefix, delimiter: options.delimiter, lengthMarker: options.lengthMarker })
  writer.push(depth, header)

  for (const arr of values) {
    if (isArrayOfPrimitives(arr)) {
      const inline = encodeInlineArrayLine(arr, options.delimiter, undefined, options.lengthMarker)
      writer.pushListItem(depth + 1, inline)
    }
  }
}

export function encodeInlineArrayLine(values: readonly JsonPrimitive[], delimiter: string, prefix?: string, lengthMarker?: '#' | false): string {
  const header = formatHeader(values.length, { key: prefix, delimiter, lengthMarker })
  const joinedValue = encodeAndJoinPrimitives(values, delimiter)
  // Only add space if there are values
  if (values.length === 0) {
    return header
  }
  return `${header} ${joinedValue}`
}

// #endregion

// #region Array of objects (tabular format)

export function encodeArrayOfObjectsAsTabular(
  prefix: string | undefined,
  rows: readonly JsonObject[],
  header: readonly string[],
  writer: LineWriter,
  depth: Depth,
  options: ResolvedEncodeOptions,
): void {
  const formattedHeader = formatHeader(rows.length, { key: prefix, fields: header, delimiter: options.delimiter, lengthMarker: options.lengthMarker })
  writer.push(depth, `${formattedHeader}`)

  writeTabularRows(rows, header, writer, depth + 1, options)
}

export function extractTabularHeader(rows: readonly JsonObject[]): string[] | undefined {
  if (rows.length === 0)
    return

  const firstRow = rows[0]!
  const firstKeys = Object.keys(firstRow)
  if (firstKeys.length === 0)
    return

  if (isTabularArray(rows, firstKeys)) {
    return firstKeys
  }
}

export function isTabularArray(
  rows: readonly JsonObject[],
  header: readonly string[],
): boolean {
  for (const row of rows) {
    const keys = Object.keys(row)

    // All objects must have the same keys (but order can differ)
    if (keys.length !== header.length) {
      return false
    }

    // Check that all header keys exist in the row and all values are primitives
    for (const key of header) {
      if (!(key in row)) {
        return false
      }
      if (!isJsonPrimitive(row[key])) {
        return false
      }
    }
  }

  return true
}

function writeTabularRows(
  rows: readonly JsonObject[],
  header: readonly string[],
  writer: LineWriter,
  depth: Depth,
  options: ResolvedEncodeOptions,
): void {
  for (const row of rows) {
    const values = header.map(key => row[key])
    const joinedValue = encodeAndJoinPrimitives(values as JsonPrimitive[], options.delimiter)
    writer.push(depth, joinedValue)
  }
}

// #endregion

// #region Array of objects (expanded format)

export function encodeMixedArrayAsListItems(
  prefix: string | undefined,
  items: readonly JsonValue[],
  writer: LineWriter,
  depth: Depth,
  options: ResolvedEncodeOptions,
): void {
  const header = formatHeader(items.length, { key: prefix, delimiter: options.delimiter, lengthMarker: options.lengthMarker })
  writer.push(depth, header)

  for (const item of items) {
    encodeListItemValue(item, writer, depth + 1, options)
  }
}

export function encodeObjectAsListItem(obj: JsonObject, writer: LineWriter, depth: Depth, options: ResolvedEncodeOptions): void {
  const keys = Object.keys(obj)
  if (keys.length === 0) {
    writer.push(depth, LIST_ITEM_MARKER)
    return
  }

  // First key-value on the same line as "- "
  const firstKey = keys[0]!
  const encodedKey = encodeKey(firstKey)
  const firstValue = obj[firstKey]!

  if (isJsonPrimitive(firstValue)) {
    writer.pushListItem(depth, `${encodedKey}: ${encodePrimitive(firstValue, options.delimiter)}`)
  }
  else if (isJsonArray(firstValue)) {
    if (isArrayOfPrimitives(firstValue)) {
      // Inline format for primitive arrays
      const formatted = encodeInlineArrayLine(firstValue, options.delimiter, firstKey, options.lengthMarker)
      writer.pushListItem(depth, formatted)
    }
    else if (isArrayOfObjects(firstValue)) {
      // Check if array of objects can use tabular format
      const header = extractTabularHeader(firstValue)
      if (header) {
        // Tabular format for uniform arrays of objects
        const formattedHeader = formatHeader(firstValue.length, { key: firstKey, fields: header, delimiter: options.delimiter, lengthMarker: options.lengthMarker })
        writer.pushListItem(depth, formattedHeader)
        writeTabularRows(firstValue, header, writer, depth + 1, options)
      }
      else {
        // Fall back to list format for non-uniform arrays of objects
        writer.pushListItem(depth, `${encodedKey}[${firstValue.length}]:`)
        for (const item of firstValue) {
          encodeObjectAsListItem(item, writer, depth + 1, options)
        }
      }
    }
    else {
      // Complex arrays on separate lines (array of arrays, etc.)
      writer.pushListItem(depth, `${encodedKey}[${firstValue.length}]:`)

      // Encode array contents at depth + 1
      for (const item of firstValue) {
        encodeListItemValue(item, writer, depth + 1, options)
      }
    }
  }
  else if (isJsonObject(firstValue)) {
    const nestedKeys = Object.keys(firstValue)
    if (nestedKeys.length === 0) {
      writer.pushListItem(depth, `${encodedKey}:`)
    }
    else {
      writer.pushListItem(depth, `${encodedKey}:`)
      encodeObject(firstValue, writer, depth + 2, options)
    }
  }

  // Remaining keys on indented lines
  for (let i = 1; i < keys.length; i++) {
    const key = keys[i]!
    encodeKeyValuePair(key, obj[key]!, writer, depth + 1, options)
  }
}

// #endregion

// #region List item encoding helpers

function encodeListItemValue(
  value: JsonValue,
  writer: LineWriter,
  depth: Depth,
  options: ResolvedEncodeOptions,
): void {
  if (isJsonPrimitive(value)) {
    writer.pushListItem(depth, encodePrimitive(value, options.delimiter))
  }
  else if (isJsonArray(value) && isArrayOfPrimitives(value)) {
    const inline = encodeInlineArrayLine(value, options.delimiter, undefined, options.lengthMarker)
    writer.pushListItem(depth, inline)
  }
  else if (isJsonObject(value)) {
    encodeObjectAsListItem(value, writer, depth, options)
  }
}

// #endregion



================================================
FILE: packages/toon/src/encode/normalize.ts
================================================
import type { JsonArray, JsonObject, JsonPrimitive, JsonValue } from '../types'

// #region Normalization (unknown ‚Üí JsonValue)

export function normalizeValue(value: unknown): JsonValue {
  // null
  if (value === null) {
    return null
  }

  // Primitives
  if (typeof value === 'string' || typeof value === 'boolean') {
    return value
  }

  // Numbers: canonicalize -0 to 0, handle NaN and Infinity
  if (typeof value === 'number') {
    if (Object.is(value, -0)) {
      return 0
    }
    if (!Number.isFinite(value)) {
      return null
    }
    return value
  }

  // BigInt ‚Üí number (if safe) or string
  if (typeof value === 'bigint') {
    // Try to convert to number if within safe integer range
    if (value >= Number.MIN_SAFE_INTEGER && value <= Number.MAX_SAFE_INTEGER) {
      return Number(value)
    }
    // Otherwise convert to string (will be unquoted as it looks numeric)
    return value.toString()
  }

  // Date ‚Üí ISO string
  if (value instanceof Date) {
    return value.toISOString()
  }

  // Array
  if (Array.isArray(value)) {
    return value.map(normalizeValue)
  }

  // Set ‚Üí array
  if (value instanceof Set) {
    return Array.from(value).map(normalizeValue)
  }

  // Map ‚Üí object
  if (value instanceof Map) {
    return Object.fromEntries(
      Array.from(value, ([k, v]) => [String(k), normalizeValue(v)]),
    )
  }

  // Plain object
  if (isPlainObject(value)) {
    const result: Record<string, JsonValue> = {}

    for (const key in value) {
      if (Object.prototype.hasOwnProperty.call(value, key)) {
        result[key] = normalizeValue(value[key])
      }
    }

    return result
  }

  // Fallback: function, symbol, undefined, or other ‚Üí null
  return null
}

// #endregion

// #region Type guards

export function isJsonPrimitive(value: unknown): value is JsonPrimitive {
  return (
    value === null
    || typeof value === 'string'
    || typeof value === 'number'
    || typeof value === 'boolean'
  )
}

export function isJsonArray(value: unknown): value is JsonArray {
  return Array.isArray(value)
}

export function isJsonObject(value: unknown): value is JsonObject {
  return value !== null && typeof value === 'object' && !Array.isArray(value)
}

export function isPlainObject(value: unknown): value is Record<string, unknown> {
  if (value === null || typeof value !== 'object') {
    return false
  }

  const prototype = Object.getPrototypeOf(value)
  return prototype === null || prototype === Object.prototype
}

// #endregion

// #region Array type detection

export function isArrayOfPrimitives(value: JsonArray): value is readonly JsonPrimitive[] {
  return value.every(item => isJsonPrimitive(item))
}

export function isArrayOfArrays(value: JsonArray): value is readonly JsonArray[] {
  return value.every(item => isJsonArray(item))
}

export function isArrayOfObjects(value: JsonArray): value is readonly JsonObject[] {
  return value.every(item => isJsonObject(item))
}

// #endregion



================================================
FILE: packages/toon/src/encode/primitives.ts
================================================
import type { JsonPrimitive } from '../types'
import { COMMA, DEFAULT_DELIMITER, DOUBLE_QUOTE, NULL_LITERAL } from '../constants'
import { escapeString } from '../shared/string-utils'
import { isSafeUnquoted, isValidUnquotedKey } from '../shared/validation'

// #region Primitive encoding

export function encodePrimitive(value: JsonPrimitive, delimiter?: string): string {
  if (value === null) {
    return NULL_LITERAL
  }

  if (typeof value === 'boolean') {
    return String(value)
  }

  if (typeof value === 'number') {
    return String(value)
  }

  return encodeStringLiteral(value, delimiter)
}

export function encodeStringLiteral(value: string, delimiter: string = COMMA): string {
  if (isSafeUnquoted(value, delimiter)) {
    return value
  }

  return `${DOUBLE_QUOTE}${escapeString(value)}${DOUBLE_QUOTE}`
}

// #endregion

// #region Key encoding

export function encodeKey(key: string): string {
  if (isValidUnquotedKey(key)) {
    return key
  }

  return `${DOUBLE_QUOTE}${escapeString(key)}${DOUBLE_QUOTE}`
}

// #endregion

// #region Value joining

export function encodeAndJoinPrimitives(values: readonly JsonPrimitive[], delimiter: string = COMMA): string {
  return values.map(v => encodePrimitive(v, delimiter)).join(delimiter)
}

// #endregion

// #region Header formatters

export function formatHeader(
  length: number,
  options?: {
    key?: string
    fields?: readonly string[]
    delimiter?: string
    lengthMarker?: '#' | false
  },
): string {
  const key = options?.key
  const fields = options?.fields
  const delimiter = options?.delimiter ?? COMMA
  const lengthMarker = options?.lengthMarker ?? false

  let header = ''

  if (key) {
    header += encodeKey(key)
  }

  // Only include delimiter if it's not the default (comma)
  header += `[${lengthMarker || ''}${length}${delimiter !== DEFAULT_DELIMITER ? delimiter : ''}]`

  if (fields) {
    const quotedFields = fields.map(f => encodeKey(f))
    header += `{${quotedFields.join(delimiter)}}`
  }

  header += ':'

  return header
}

// #endregion



================================================
FILE: packages/toon/src/encode/writer.ts
================================================
import type { Depth } from '../types'
import { LIST_ITEM_PREFIX } from '../constants'

export class LineWriter {
  private readonly lines: string[] = []
  private readonly indentationString: string

  constructor(indentSize: number) {
    this.indentationString = ' '.repeat(indentSize)
  }

  push(depth: Depth, content: string): void {
    const indent = this.indentationString.repeat(depth)
    this.lines.push(indent + content)
  }

  pushListItem(depth: Depth, content: string): void {
    this.push(depth, `${LIST_ITEM_PREFIX}${content}`)
  }

  toString(): string {
    return this.lines.join('\n')
  }
}



================================================
FILE: packages/toon/src/shared/literal-utils.ts
================================================
import { FALSE_LITERAL, NULL_LITERAL, TRUE_LITERAL } from '../constants'

/**
 * Checks if a token is a boolean or null literal (`true`, `false`, `null`).
 */
export function isBooleanOrNullLiteral(token: string): boolean {
  return token === TRUE_LITERAL || token === FALSE_LITERAL || token === NULL_LITERAL
}

/**
 * Checks if a token represents a valid numeric literal.
 *
 * @remarks
 * Rejects numbers with leading zeros (except `"0"` itself or decimals like `"0.5"`).
 */
export function isNumericLiteral(token: string): boolean {
  if (!token)
    return false

  // Must not have leading zeros (except for `"0"` itself or decimals like `"0.5"`)
  if (token.length > 1 && token[0] === '0' && token[1] !== '.') {
    return false
  }

  // Check if it's a valid number
  const num = Number(token)
  return !Number.isNaN(num) && Number.isFinite(num)
}



================================================
FILE: packages/toon/src/shared/string-utils.ts
================================================
import { BACKSLASH, CARRIAGE_RETURN, DOUBLE_QUOTE, NEWLINE, TAB } from '../constants'

/**
 * Escapes special characters in a string for encoding.
 *
 * @remarks
 * Handles backslashes, quotes, newlines, carriage returns, and tabs.
 */
export function escapeString(value: string): string {
  return value
    .replace(/\\/g, `${BACKSLASH}${BACKSLASH}`)
    .replace(/"/g, `${BACKSLASH}${DOUBLE_QUOTE}`)
    .replace(/\n/g, `${BACKSLASH}n`)
    .replace(/\r/g, `${BACKSLASH}r`)
    .replace(/\t/g, `${BACKSLASH}t`)
}

/**
 * Unescapes a string by processing escape sequences.
 *
 * @remarks
 * Handles `\n`, `\t`, `\r`, `\\`, and `\"` escape sequences.
 */
export function unescapeString(value: string): string {
  let result = ''
  let i = 0

  while (i < value.length) {
    if (value[i] === BACKSLASH) {
      if (i + 1 >= value.length) {
        throw new SyntaxError('Invalid escape sequence: backslash at end of string')
      }

      const next = value[i + 1]
      if (next === 'n') {
        result += NEWLINE
        i += 2
        continue
      }
      if (next === 't') {
        result += TAB
        i += 2
        continue
      }
      if (next === 'r') {
        result += CARRIAGE_RETURN
        i += 2
        continue
      }
      if (next === BACKSLASH) {
        result += BACKSLASH
        i += 2
        continue
      }
      if (next === DOUBLE_QUOTE) {
        result += DOUBLE_QUOTE
        i += 2
        continue
      }

      throw new SyntaxError(`Invalid escape sequence: \\${next}`)
    }

    result += value[i]
    i++
  }

  return result
}

/**
 * Finds the index of the closing double quote in a string, accounting for escape sequences.
 *
 * @param content The string to search in
 * @param start The index of the opening quote
 * @returns The index of the closing quote, or -1 if not found
 */
export function findClosingQuote(content: string, start: number): number {
  let i = start + 1
  while (i < content.length) {
    if (content[i] === BACKSLASH && i + 1 < content.length) {
      // Skip escaped character
      i += 2
      continue
    }
    if (content[i] === DOUBLE_QUOTE) {
      return i
    }
    i++
  }
  return -1 // Not found
}

/**
 * Finds the index of a specific character outside of quoted sections.
 *
 * @param content The string to search in
 * @param char The character to look for
 * @param start Optional starting index (defaults to 0)
 * @returns The index of the character, or -1 if not found outside quotes
 */
export function findUnquotedChar(content: string, char: string, start = 0): number {
  let inQuotes = false
  let i = start

  while (i < content.length) {
    if (content[i] === BACKSLASH && i + 1 < content.length && inQuotes) {
      // Skip escaped character
      i += 2
      continue
    }

    if (content[i] === DOUBLE_QUOTE) {
      inQuotes = !inQuotes
      i++
      continue
    }

    if (content[i] === char && !inQuotes) {
      return i
    }

    i++
  }

  return -1
}



================================================
FILE: packages/toon/src/shared/validation.ts
================================================
import { COMMA, LIST_ITEM_MARKER } from '../constants'
import { isBooleanOrNullLiteral } from './literal-utils'

/**
 * Checks if a key can be used without quotes.
 *
 * @remarks
 * Valid unquoted keys must start with a letter or underscore,
 * followed by letters, digits, underscores, or dots.
 */
export function isValidUnquotedKey(key: string): boolean {
  return /^[A-Z_][\w.]*$/i.test(key)
}

/**
 * Determines if a string value can be safely encoded without quotes.
 *
 * @remarks
 * A string needs quoting if it:
 * - Is empty
 * - Has leading or trailing whitespace
 * - Could be confused with a literal (boolean, null, number)
 * - Contains structural characters (colons, brackets, braces)
 * - Contains quotes or backslashes (need escaping)
 * - Contains control characters (newlines, tabs, etc.)
 * - Contains the active delimiter
 * - Starts with a list marker (hyphen)
 */
export function isSafeUnquoted(value: string, delimiter: string = COMMA): boolean {
  if (!value) {
    return false
  }

  if (value !== value.trim()) {
    return false
  }

  // Check if it looks like any literal value (boolean, null, or numeric)
  if (isBooleanOrNullLiteral(value) || isNumericLike(value)) {
    return false
  }

  // Check for colon (always structural)
  if (value.includes(':')) {
    return false
  }

  // Check for quotes and backslash (always need escaping)
  if (value.includes('"') || value.includes('\\')) {
    return false
  }

  // Check for brackets and braces (always structural)
  if (/[[\]{}]/.test(value)) {
    return false
  }

  // Check for control characters (newline, carriage return, tab - always need quoting/escaping)
  if (/[\n\r\t]/.test(value)) {
    return false
  }

  // Check for the active delimiter
  if (value.includes(delimiter)) {
    return false
  }

  // Check for hyphen at start (list marker)
  if (value.startsWith(LIST_ITEM_MARKER)) {
    return false
  }

  return true
}

/**
 * Checks if a string looks like a number.
 *
 * @remarks
 * Match numbers like `42`, `-3.14`, `1e-6`, `05`, etc.
 */
function isNumericLike(value: string): boolean {
  return /^-?\d+(?:\.\d+)?(?:e[+-]?\d+)?$/i.test(value) || /^0\d+$/.test(value)
}



================================================
FILE: packages/toon/test/decode.test.ts
================================================
import type { Fixtures } from './types'
import arraysNested from '@toon-format/spec/tests/fixtures/decode/arrays-nested.json'
import arraysPrimitive from '@toon-format/spec/tests/fixtures/decode/arrays-primitive.json'
import arraysTabular from '@toon-format/spec/tests/fixtures/decode/arrays-tabular.json'
import blankLines from '@toon-format/spec/tests/fixtures/decode/blank-lines.json'
import delimiters from '@toon-format/spec/tests/fixtures/decode/delimiters.json'
import indentationErrors from '@toon-format/spec/tests/fixtures/decode/indentation-errors.json'
import objects from '@toon-format/spec/tests/fixtures/decode/objects.json'
import primitives from '@toon-format/spec/tests/fixtures/decode/primitives.json'
import validationErrors from '@toon-format/spec/tests/fixtures/decode/validation-errors.json'
import { describe, expect, it } from 'vitest'
import { decode } from '../src/index'

const fixtureFiles = [
  primitives,
  objects,
  arraysPrimitive,
  arraysTabular,
  arraysNested,
  delimiters,
  validationErrors,
  indentationErrors,
  blankLines,
] as Fixtures[]

// Run all fixture-based tests
for (const fixtures of fixtureFiles) {
  describe(fixtures.description, () => {
    for (const test of fixtures.tests) {
      it(test.name, () => {
        if (test.shouldError) {
          expect(() => decode(test.input as string, test.options))
            .toThrow()
        }
        else {
          const result = decode(test.input as string, test.options)
          expect(result).toEqual(test.expected)
        }
      })
    }
  })
}



================================================
FILE: packages/toon/test/encode.test.ts
================================================
import type { ResolvedEncodeOptions } from '../src/types'
import type { Fixtures, TestCase } from './types'
import arraysNested from '@toon-format/spec/tests/fixtures/encode/arrays-nested.json'
import arraysObjects from '@toon-format/spec/tests/fixtures/encode/arrays-objects.json'
import arraysPrimitive from '@toon-format/spec/tests/fixtures/encode/arrays-primitive.json'
import arraysTabular from '@toon-format/spec/tests/fixtures/encode/arrays-tabular.json'
import delimiters from '@toon-format/spec/tests/fixtures/encode/delimiters.json'
import normalization from '@toon-format/spec/tests/fixtures/encode/normalization.json'
import objects from '@toon-format/spec/tests/fixtures/encode/objects.json'
import options from '@toon-format/spec/tests/fixtures/encode/options.json'
import primitives from '@toon-format/spec/tests/fixtures/encode/primitives.json'
import whitespace from '@toon-format/spec/tests/fixtures/encode/whitespace.json'
import { describe, expect, it } from 'vitest'
import { decode, DEFAULT_DELIMITER, encode } from '../src/index'

const fixtureFiles = [
  primitives,
  objects,
  arraysPrimitive,
  arraysTabular,
  arraysNested,
  arraysObjects,
  delimiters,
  normalization,
  whitespace,
  options,
] as Fixtures[]

// Special test for round-trip fidelity (not in JSON fixtures)
describe('round-trip fidelity', () => {
  it('preserves precision for repeating decimals', () => {
    const value = 1 / 3
    const encodedValue = encode({ value })
    const decodedValue = decode(encodedValue)
    expect((decodedValue as Record<string, unknown>)?.value).toBe(value) // Round-trip fidelity
    expect(encodedValue).toContain('0.3333333333333333') // Default JS precision
  })
})

// Run all fixture-based tests
for (const fixtures of fixtureFiles) {
  describe(fixtures.description, () => {
    for (const test of fixtures.tests) {
      it(test.name, () => {
        const resolvedOptions = resolveEncodeOptions(test.options)

        if (test.shouldError) {
          expect(() => encode(test.input, resolvedOptions))
            .toThrow()
        }
        else {
          const result = encode(test.input, resolvedOptions)
          expect(result).toBe(test.expected)
        }
      })
    }
  })
}

function resolveEncodeOptions(options?: TestCase['options']): ResolvedEncodeOptions {
  return {
    indent: options?.indent ?? 2,
    delimiter: options?.delimiter ?? DEFAULT_DELIMITER,
    lengthMarker: options?.lengthMarker === '#' ? '#' : false,
  }
}



================================================
FILE: packages/toon/test/types.ts
================================================
/**
 * Type definitions for TOON test fixtures
 *
 * @remarks
 * Matches the JSON schema at https://github.com/toon-format/spec/blob/main/tests/fixtures.schema.json.
 */

export interface TestCase {
  name: string
  input: unknown
  expected: unknown
  shouldError?: boolean
  options?: {
    delimiter?: ',' | '\t' | '|'
    indent?: number
    lengthMarker?: '#' | ''
    strict?: boolean
  }
  specSection?: string
  note?: string
  minSpecVersion?: string
}

export interface Fixtures {
  version: string
  category: 'encode' | 'decode'
  description: string
  tests: TestCase[]
}



================================================
FILE: .github/workflows/ci.yml
================================================
name: CI

on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

permissions:
  contents: read

jobs:
  lint:
    runs-on: ubuntu-latest
    timeout-minutes: 10
    steps:
      - uses: actions/checkout@v5
        with:
          fetch-depth: 1
      - uses: pnpm/action-setup@v4
      - uses: actions/setup-node@v6
        with:
          node-version: 24
      - name: Get pnpm store directory
        id: pnpm-cache
        run: echo "pnpm_cache_dir=$(pnpm store path)" >> $GITHUB_OUTPUT
      - uses: actions/cache@v4
        with:
          path: ${{ steps.pnpm-cache.outputs.pnpm_cache_dir }}
          key: ${{ runner.os }}-pnpm-store-${{ hashFiles('**/pnpm-lock.yaml') }}
          restore-keys: |
            ${{ runner.os }}-pnpm-store-
      - run: pnpm install --frozen-lockfile
      - run: pnpm run lint

  typecheck:
    runs-on: ubuntu-latest
    timeout-minutes: 10
    steps:
      - uses: actions/checkout@v5
        with:
          fetch-depth: 1
      - uses: pnpm/action-setup@v4
      - uses: actions/setup-node@v6
        with:
          node-version: 24
      - name: Get pnpm store directory
        id: pnpm-cache
        run: echo "pnpm_cache_dir=$(pnpm store path)" >> $GITHUB_OUTPUT
      - uses: actions/cache@v4
        with:
          path: ${{ steps.pnpm-cache.outputs.pnpm_cache_dir }}
          key: ${{ runner.os }}-pnpm-store-${{ hashFiles('**/pnpm-lock.yaml') }}
          restore-keys: |
            ${{ runner.os }}-pnpm-store-
      - run: pnpm install --frozen-lockfile
      - run: pnpm run test:types



================================================
FILE: .github/workflows/release.yml
================================================
name: Release

on:
  push:
    tags:
      - 'v*'

permissions:
  id-token: write
  contents: write

jobs:
  release:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v5
      - uses: pnpm/action-setup@v4
      - uses: actions/setup-node@v6
        with:
          node-version: 24
          registry-url: https://registry.npmjs.org/
          cache: pnpm

      - name: Publish changelog
        run: npx changelogithub
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - run: pnpm install
      - run: pnpm run build

      - name: Publish to npm
        run: npm install -g npm@latest && pnpm -r publish --access public --no-git-checks
        env:
          NODE_AUTH_TOKEN: ${{ secrets.NPM_TOKEN }}


